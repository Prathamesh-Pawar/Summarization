[
    {
        "topic": "P versus NP problem",
        "summary": "The P versus NP problem is a major unsolved problem in theoretical computer science. In informal terms, it asks whether every problem whose solution can be quickly verified can also be quickly solved.\nThe informal term quickly, used above, means the existence of an algorithm solving the task that runs in polynomial time, such that the time to complete the task varies as a polynomial function on the size of the input to the algorithm (as opposed to, say, exponential time). The general class of questions for which some algorithm can provide an answer in polynomial time is \"P\" or \"class P\". For some questions, there is no known way to find an answer quickly, but if one is provided with information showing what the answer is, it is possible to verify the answer quickly. The class of questions for which an answer can be verified in polynomial time is NP, which stands for \"nondeterministic polynomial time\".An answer to the P versus NP question would determine whether problems that can be verified in polynomial time can also be solved in polynomial time. If it turns out that P \u2260 NP, which is widely believed, it would mean that there are problems in NP that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time.\nThe problem has been called the most important open problem in computer science. Aside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, economics and many other fields.It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute, each of which carries a US$1,000,000 prize for the first correct solution.",
        "content": "\n\n\n== Example ==\nConsider Sudoku, a game where the player is given a partially filled-in grid of numbers and attempts to complete the grid following certain rules. Given an incomplete Sudoku grid, of any size, is there at least one legal solution? Any proposed solution is easily verified, and the time to check a solution grows slowly (polynomially) as the grid gets bigger. However, all known algorithms for finding solutions take, for difficult examples, time that grows exponentially as the grid gets bigger. So, Sudoku is in NP (quickly checkable) but does not seem to be in P (quickly solvable). Thousands of other problems seem similar, in that they are fast to check but slow to solve. Researchers have shown that many of the problems in NP have the extra property that a fast solution to any one of them could be used to build a quick solution to any other problem in NP, a property called NP-completeness. Decades of searching have not yielded a fast solution to any of these problems, so most scientists suspect that none of these problems can be solved quickly. This, however, has never been proven.\n\n\n== History ==\nThe precise statement of the P versus NP problem was introduced in 1971 by Stephen Cook in his seminal paper \"The complexity of theorem proving procedures\" (and independently by Leonid Levin in 1973).\nAlthough the P versus NP problem was formally defined in 1971, there were previous inklings of the problems involved, the difficulty of proof, and the potential consequences. In 1955, mathematician John Nash wrote a letter to the NSA, in which he speculated that cracking a sufficiently complex code would require time exponential in the length of the key. If proved (and Nash was suitably skeptical), this would imply what is now called P \u2260 NP, since a proposed key can easily be verified in polynomial time. Another mention of the underlying problem occurred in a 1956 letter written by Kurt G\u00f6del to John von Neumann. G\u00f6del asked whether theorem-proving (now known to be co-NP-complete) could be solved in quadratic or linear time, and pointed out one of the most important consequences \u2013 that if so, then the discovery of mathematical proofs could be automated.\n\n\n== Context ==\nThe relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem).\nIn such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is deterministic (given the computer's present state and any inputs, there is only one possible action that the computer might take) and sequential (it performs actions one after the other).\nIn this theory, the class P consists of all those decision problems (defined below) that can be solved on a deterministic sequential machine in an amount of time that is polynomial in the size of the input; the class NP consists of all those decision problems whose positive solutions can be verified in polynomial time given the right information, or equivalently, whose solution can be found in polynomial time on a non-deterministic machine. Clearly, P \u2286 NP. Arguably, the biggest open question in theoretical computer science concerns the relationship between those two classes:\n\nIs P equal to NP?Since 2002, William Gasarch has conducted three polls of researchers concerning this and related questions. Confidence that P \u2260 NP has been increasing \u2013 in 2019, 88% believed P \u2260 NP, as opposed to 83% in 2012 and 61% in 2002. When restricted to experts, the 2019 answers became 99% believed P \u2260 NP. These polls do not imply anything about whether P = NP is true, as stated by Gasarch himself: \"This does not bring us any closer to solving P=?NP or to knowing when it will be solved, but it attempts to be an objective report on the subjective opinion of this era.\"\n\n\n== NP-completeness ==\n\nTo attack the P = NP question, the concept of NP-completeness is very useful. NP-complete problems are a set of problems to each of which any other NP problem can be reduced in polynomial time and whose solution may still be verified in polynomial time. That is, any NP problem can be transformed into any of the NP-complete problems. Informally, an NP-complete problem is an NP problem that is at least as \"tough\" as any other problem in NP.\nNP-hard problems are those at least as hard as NP problems; i.e., all NP problems can be reduced (in polynomial time) to them. NP-hard problems need not be in NP; i.e., they need not have solutions verifiable in polynomial time.\nFor instance, the Boolean satisfiability problem is NP-complete by the Cook\u2013Levin theorem, so any instance of any problem in NP can be transformed mechanically into an instance of the Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many such NP-complete problems. If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems have been shown to be NP-complete, and no fast algorithm for any of them is known.\nBased on the definition alone it is not obvious that NP-complete problems exist; however, a trivial and contrived NP-complete problem can be formulated as follows: given a description of a Turing machine M guaranteed to halt in polynomial time, does there exist a polynomial-size input that M will accept? It is in NP because (given an input) it is simple to check whether M accepts the input by simulating M; it is NP-complete because the verifier for any particular instance of a problem in NP can be encoded as a polynomial-time machine M that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists.\nThe first natural problem proven to be NP-complete was the Boolean satisfiability problem, also known as SAT. As noted above, this is the Cook\u2013Levin theorem; its proof that satisfiability is NP-complete contains technical details about Turing machines as they relate to the definition of NP. However, after this problem was proved to be NP-complete, proof by reduction provided a simpler way to show that many other problems are also NP-complete, including the game Sudoku discussed earlier. In this case, the proof shows that a solution of Sudoku in polynomial time could also be used to complete Latin squares in polynomial time. This in turn gives a solution to the problem of partitioning tri-partite graphs into triangles, which could then be used to find solutions for the special case of SAT known as 3-SAT, which then provides a solution for general Boolean satisfiability. So a polynomial-time solution to Sudoku leads, by a series of mechanical transformations, to a polynomial time solution of satisfiability, which in turn can be used to solve any other NP-problem in polynomial time. Using transformations like this, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense \"the same problem\".\n\n\n== Harder problems ==\n\nAlthough it is unknown whether P = NP, problems outside of P are known. Just as the class P is defined in terms of polynomial running time, the class EXPTIME is the set of all decision problems that have exponential running time. In other words, any problem in EXPTIME is solvable by a deterministic Turing machine in O(2p(n)) time, where p(n) is a polynomial function of n. A decision problem is EXPTIME-complete if it is in EXPTIME, and every problem in EXPTIME has a polynomial-time many-one reduction to it. A number of problems are known to be EXPTIME-complete. Because it can be shown that P \u2260 EXPTIME, these problems are outside P, and so require more than polynomial time. In fact, by the time hierarchy theorem, they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for chess positions on an N \u00d7 N board and similar problems for other board games.The problem of deciding the truth of a statement in Presburger arithmetic requires even more time. Fischer and Rabin proved in 1974 that every algorithm that decides the truth of Presburger statements of length n has a runtime of at least \n  \n    \n      \n        \n          2\n          \n            \n              2\n              \n                c\n                n\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 2^{2^{cn}}}\n   for some constant c. Hence, the problem is known to need more than exponential run time. Even more difficult are the undecidable problems, such as the halting problem. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all.\nIt is also possible to consider questions other than decision problems.  One such class, consisting of counting problems, is called #P: whereas an NP problem asks \"Are there any solutions?\", the corresponding #P problem asks \"How many solutions are there?\". Clearly, a #P problem must be at least as hard as the corresponding NP problem, since a count of solutions immediately tells if at least one solution exists, if the count is greater than zero. Surprisingly, some #P problems that are believed to be difficult correspond to easy (for example linear-time) P problems. For these problems, it is very easy to tell whether solutions exist, but thought to be very hard to tell how many. Many of these problems are #P-complete, and hence among the hardest problems in #P, since a polynomial time solution to any of them would allow a polynomial time solution to all other #P problems.\n\n\n== Problems in NP not known to be in P or NP-complete ==\n\nIn 1975, Richard E. Ladner showed that if P \u2260 NP, then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem, and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete.\nThe graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to L\u00e1szl\u00f3 Babai, runs in quasi-polynomial time.The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than k. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP = co-NP). The most efficient known algorithm for integer factorization is the general number field sieve, which takes expected time\n\n  \n    \n      \n        O\n        \n          (\n          \n            exp\n            \u2061\n            \n              (\n              \n                \n                  \n                    (\n                    \n                      \n                        \n                          \n                            \n                              64\n                              n\n                            \n                            9\n                          \n                        \n                      \n                      log\n                      \u2061\n                      (\n                      2\n                      )\n                    \n                    )\n                  \n                  \n                    \n                      1\n                      3\n                    \n                  \n                \n                \n                  \n                    (\n                    \n                      log\n                      \u2061\n                      (\n                      n\n                      log\n                      \u2061\n                      (\n                      2\n                      )\n                      )\n                    \n                    )\n                  \n                  \n                    \n                      2\n                      3\n                    \n                  \n                \n              \n              )\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle O\\left(\\exp \\left(\\left({\\tfrac {64n}{9}}\\log(2)\\right)^{\\frac {1}{3}}\\left(\\log(n\\log(2))\\right)^{\\frac {2}{3}}\\right)\\right)}\n  to factor an n-bit integer. The best known quantum algorithm for this problem, Shor's algorithm, runs in polynomial time, although this does not indicate where the problem lies with respect to non-quantum complexity classes.\n\n\n== Does P mean \"easy\"? ==\n\nAll of the above discussion has assumed that P means \"easy\" and \"not in P\" means \"difficult\", an assumption known as Cobham's thesis. It is a common and reasonably accurate assumption in complexity theory; however, it has some caveats.\nFirst, it is not always true in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents, thus rendering it impractical. For example, the problem of deciding whether a graph G contains H as a minor, where H is fixed, can be solved in a running time of O(n2), where n is the number of vertices in G.  However, the big O notation hides a constant that depends superexponentially on H.  The constant is greater than \n  \n    \n      \n        2\n        \u2191\u2191\n        (\n        2\n        \u2191\u2191\n        (\n        2\n        \u2191\u2191\n        (\n        h\n        \n          /\n        \n        2\n        )\n        )\n        )\n      \n    \n    {\\displaystyle 2\\uparrow \\uparrow (2\\uparrow \\uparrow (2\\uparrow \\uparrow (h/2)))}\n   (using Knuth's up-arrow notation), and where h is the number of vertices in H.On the other hand, even if a problem is shown to be NP-complete, and even if P \u2260 NP, there may still be effective approaches to tackling the problem in practice. There are algorithms for many NP-complete problems, such as the knapsack problem, the traveling salesman problem, and the Boolean satisfiability problem, that can solve to optimality many real-world instances in reasonable time. The empirical average-case complexity (time vs. problem size) of such algorithms can be surprisingly low.  An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity, it runs on par with the best known polynomial-time algorithms.Finally, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms.\n\n\n== Reasons to believe P \u2260 NP or P = NP ==\nCook provides a restatement of the problem in The P Versus NP Problem as \"Does P = NP?\" According to polls, most computer scientists believe that P \u2260 NP. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems (see List of NP-complete problems). These algorithms were sought long before the concept of NP-completeness was even defined (Karp's 21 NP-complete problems, among the first found, were all well-known existing problems at the time they were shown to be NP-complete). Furthermore, the result P = NP would imply many other startling results that are currently believed to be false, such as NP = co-NP and P = PH.\nIt is also intuitively argued that the existence of problems that are hard to solve but for which the solutions are easy to verify matches real-world experience.\nIf P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in \"creative leaps\", no fundamental gap between solving a problem and recognizing the solution once it's found.\nOn the other hand, some researchers believe that there is overconfidence in believing P \u2260 NP and that researchers should explore proofs of P = NP as well. For example, in 2002 these statements were made:\nThe main argument in favor of P \u2260 NP is the total lack of fundamental progress in the area of exhaustive search. This is, in my opinion, a very weak argument. The space of algorithms is very large and we are only at the beginning of its exploration. [...] The resolution of Fermat's Last Theorem also shows that very simple questions may be settled only by very deep theories.\nBeing attached to a speculation is not a good guide to research planning. One should always try both directions of every problem. Prejudice has caused famous mathematicians to fail to solve famous problems whose solution was opposite to their expectations, even though they had developed all the methods required.\n\n\n== Consequences of solution ==\nOne of the reasons the problem attracts so much attention is the consequences of the possible answers. Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well.\n\n\n=== P = NP ===\nA proof that P = NP could have stunning practical consequences if the proof leads to efficient methods for solving some of the important problems in NP. The potential consequences, both positive and negative, arise since various NP-complete problems are fundamental in many fields.\nIt is also very possible that a proof would not lead to practical algorithms for NP-complete problems.  The formulation of the problem does not require that the bounding polynomial be small or even specifically known. A non-constructive proof might show a solution exists without specifying either an algorithm to obtain it or a specific bound. Even if the proof is constructive, showing an explicit bounding polynomial and algorithmic details, if the polynomial is not very low-order the algorithm might not be sufficiently efficient in practice. In this case the initial proof would be mainly of interest to theoreticians, but the knowledge that polynomial time solutions are possible would surely spur research into better (and possibly practical) methods to achieve them.\nAn example of a field that could be upended by a solution showing P = NP is cryptography, which relies on certain problems being difficult. A constructive and efficient solution to an NP-complete problem such as 3-SAT would break most existing cryptosystems including:\n\nExisting implementations of public-key cryptography, a foundation for many modern security applications such as secure financial transactions over the Internet.\nSymmetric ciphers such as AES or 3DES, used for the encryption of communications data.\nCryptographic hashing, which underlies blockchain cryptocurrencies such as Bitcoin, and is used to authenticate software updates.  For these applications, the problem of finding a pre-image that hashes to a given value must be difficult in order to be useful, and ideally should require exponential time. However, if P = NP, then finding a pre-image M can be done in polynomial time, through reduction to SAT.These would need to be modified or replaced by information-theoretically secure solutions not inherently based on P\u2013NP inequivalence.\nOn the other hand, there are enormous positive consequences that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in operations research are NP-complete, such as some types of integer programming and the travelling salesman problem. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in protein structure prediction, are also NP-complete; if these problems were efficiently solvable, it could spur considerable advances in life sciences and biotechnology.\nBut such changes may pale in significance compared to the revolution an efficient method for solving NP-complete problems would cause in mathematics itself. G\u00f6del, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics:\nIf there really were a machine with \u03c6(n) \u223c k\u22c5n (or even \u223c k\u22c5n2), this would have consequences of the greatest importance. Namely, it would obviously mean that in spite of the undecidability of the Entscheidungsproblem, the mental work of a mathematician concerning Yes-or-No questions could be completely replaced by a machine. After all, one would simply have to choose the natural number n so large that when the machine does not deliver a result, it makes no sense to think more about the problem.\nSimilarly, Stephen Cook (assuming not only a proof, but a practically efficient algorithm) says:\n... it would transform mathematics by allowing a computer to find a formal proof of any theorem which has a proof of a reasonable length, since formal proofs can easily be recognized in polynomial time. Example problems may well include all of the CMI prize problems.\nResearch mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated\u2014for instance, Fermat's Last Theorem took over three centuries to prove. A method that is guaranteed to find proofs to theorems, should one exist of a \"reasonable\" size, would essentially end this struggle.\nDonald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof:\n[...] if you imagine a number M that's finite but incredibly large\u2014like say the number 10\u2191\u2191\u2191\u21913 discussed in my paper on \"coping with finiteness\"\u2014then there's a humongous number of possible algorithms that do nM bitwise or addition or shift operations on n given bits, and it's really hard to believe that all of those algorithms fail.\nMy main point, however, is that I don't believe that the equality P = NP will turn out to be helpful even if it is proved, because such a proof will almost surely be nonconstructive.\n\n\n=== P \u2260 NP ===\nA proof showing that P \u2260 NP would lack the practical computational benefits of a proof that P = NP, but would nevertheless represent a very significant advance in computational complexity theory and provide guidance for future research. It would allow one to show in a formal way that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in P \u2260 NP, much of this focusing of research has already taken place.Also, P \u2260 NP still leaves open the average-case complexity of hard problems in NP. For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. Russell Impagliazzo has described five hypothetical \"worlds\" that could result from different possible resolutions to the average-case complexity question. These range from \"Algorithmica\", where P = NP and problems like SAT can be solved efficiently in all instances, to \"Cryptomania\", where P \u2260 NP and generating hard instances of problems outside P is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of NP-hard problems. The \"world\" where P \u2260 NP but all problems in NP are tractable in the average case is called \"Heuristica\" in the paper. A Princeton University workshop in 2009 studied the status of the five worlds.\n\n\n== Results about difficulty of proof ==\nAlthough the P = NP problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques. In particular, some of the most fruitful research related to the P = NP problem has been in showing that existing proof techniques are not powerful enough to answer the question, thus suggesting that novel technical approaches are required.\nAs additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, each of which is known to be insufficient to prove that P \u2260 NP:\n\nThese barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results.\nThese barriers have also led some computer scientists to suggest that the P versus NP problem may be independent of standard axiom systems like ZFC (cannot be proved or disproved within them). The interpretation of an independence result could be that either no polynomial-time algorithm exists for any NP-complete problem, and such a proof cannot be constructed in (e.g.) ZFC, or that polynomial-time algorithms for NP-complete problems may exist, but it is impossible to prove in ZFC that such algorithms are correct. However, if it can be shown, using techniques of the sort that are currently known to be applicable, that the problem cannot be decided even with much weaker assumptions extending the Peano axioms (PA) for integer arithmetic, then there would necessarily exist nearly polynomial-time algorithms for every problem in NP. Therefore, if one believes (as most complexity theorists do) that not all problems in NP have efficient algorithms, it would follow that proofs of independence using those techniques cannot be possible. Additionally, this result implies that proving independence from PA or ZFC using currently known techniques is no easier than proving the existence of efficient algorithms for all problems in NP.\n\n\n== Claimed solutions ==\nWhile the P versus NP problem is generally considered unsolved, many amateur and some professional researchers have claimed solutions. Gerhard J. Woeginger compiled a list of 62 purported proofs of P = NP from 1986 to 2016, of which 50 were proofs of P \u2260 NP, 2 were proofs the problem is unprovable, and one was a proof that it is undecidable. Some attempts at resolving P versus NP have received brief media attention, though these attempts have since been refuted.\n\n\n== Logical characterizations ==\nThe P = NP problem can be restated in terms of expressible certain classes of logical statements, as a result of work in descriptive complexity.\nConsider all languages of finite structures with a fixed signature including a linear order relation. Then, all such languages in P can be expressed in first-order logic with the addition of a suitable least fixed-point combinator. Effectively, this, in combination with the order, allows the definition of recursive functions. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P.\nSimilarly, NP is the set of languages expressible in existential second-order logic\u2014that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets. The languages in the polynomial hierarchy, PH, correspond to all of second-order logic. Thus, the question \"is P a proper subset of NP\" can be reformulated as \"is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?\". The word \"existential\" can even be dropped from the previous characterization, since P = NP if and only if P = PH (as the former would establish that NP = co-NP, which in turn implies that NP = PH).\n\n\n== Polynomial-time algorithms ==\nNo algorithm for any NP-complete problem is known to run in polynomial time. However, there are algorithms known for NP-complete problems with the property that if P = NP, then the algorithm runs in polynomial time on accepting instances (although with enormous constants, making the algorithm impractical). However, these algorithms do not qualify as polynomial time because their running time on rejecting instances are not polynomial. The following algorithm, due to Levin (without any citation), is such an example below. It correctly accepts the NP-complete language SUBSET-SUM. It runs in polynomial time on inputs that are in SUBSET-SUM if and only if P = NP:\n\n// Algorithm that accepts the NP-complete language SUBSET-SUM.\n//\n// this is a polynomial-time algorithm if and only if P = NP.\n//\n// \"Polynomial-time\" means it returns \"yes\" in polynomial time when\n// the answer should be \"yes\", and runs forever when it is \"no\".\n//\n// Input: S = a finite set of integers\n// Output: \"yes\" if any subset of S adds up to 0.\n// Runs forever with no output otherwise.\n// Note: \"Program number M\" is the program obtained by\n// writing the integer M in binary, then\n// considering that string of bits to be a\n// program. Every possible program can be\n// generated this way, though most do nothing\n// because of syntax errors.\nFOR K = 1...\u221e\n  FOR M = 1...K\n    Run program number M for K steps with input S\n    IF the program outputs a list of distinct integers\n      AND the integers are all in S\n      AND the integers sum to 0\n    THEN\n      OUTPUT \"yes\" and HALT\n\nIf, and only if, P = NP, then this is a polynomial-time algorithm accepting an NP-complete language. \"Accepting\" means it gives \"yes\" answers in polynomial time, but is allowed to run forever when the answer is \"no\" (also known as a semi-algorithm).\nThis algorithm is enormously impractical, even if P = NP. If the shortest program that can solve SUBSET-SUM in polynomial time is b bits long, the above algorithm will try at least 2b \u2212 1 other programs first.\n\n\n== Formal definitions ==\n\n\n=== P and NP ===\nConceptually speaking, a decision problem is a problem that takes as input some string w over an alphabet \u03a3, and outputs \"yes\" or \"no\". If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that can produce the correct answer for any input string of length n in at most cnk steps, where k and c are constants independent of the input string, then we say that the problem can be solved in polynomial time and we place it in the class P. Formally, P is defined as the set of all languages that can be decided by a deterministic polynomial-time Turing machine. That is,\n\n  \n    \n      \n        \n          P\n        \n        =\n        {\n        L\n        :\n        L\n        =\n        L\n        (\n        M\n        )\n        \n           for some deterministic polynomial-time Turing machine \n        \n        M\n        }\n      \n    \n    {\\displaystyle \\mathbf {P} =\\{L:L=L(M){\\text{ for some deterministic polynomial-time Turing machine }}M\\}}\n  where\n\n  \n    \n      \n        L\n        (\n        M\n        )\n        =\n        {\n        w\n        \u2208\n        \n          \u03a3\n          \n            \u2217\n          \n        \n        :\n        M\n        \n           accepts \n        \n        w\n        }\n      \n    \n    {\\displaystyle L(M)=\\{w\\in \\Sigma ^{*}:M{\\text{ accepts }}w\\}}\n  and a deterministic polynomial-time Turing machine is a deterministic Turing machine M that satisfies the following two conditions:\n\nM halts on all inputs w and\nthere exists \n  \n    \n      \n        k\n        \u2208\n        N\n      \n    \n    {\\displaystyle k\\in N}\n   such that \n  \n    \n      \n        \n          T\n          \n            M\n          \n        \n        (\n        n\n        )\n        \u2208\n        O\n        (\n        \n          n\n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle T_{M}(n)\\in O(n^{k})}\n  , where O refers to the big O notation and\n  \n    \n      \n        \n          T\n          \n            M\n          \n        \n        (\n        n\n        )\n        =\n        max\n        {\n        \n          t\n          \n            M\n          \n        \n        (\n        w\n        )\n        :\n        w\n        \u2208\n        \n          \u03a3\n          \n            \u2217\n          \n        \n        ,\n        \n          |\n        \n        w\n        \n          |\n        \n        =\n        n\n        }\n      \n    \n    {\\displaystyle T_{M}(n)=\\max\\{t_{M}(w):w\\in \\Sigma ^{*},|w|=n\\}}\n  \n\n  \n    \n      \n        \n          t\n          \n            M\n          \n        \n        (\n        w\n        )\n        =\n        \n           number of steps \n        \n        M\n        \n           takes to halt on input \n        \n        w\n        .\n      \n    \n    {\\displaystyle t_{M}(w)={\\text{ number of steps }}M{\\text{ takes to halt on input }}w.}\n  NP can be defined similarly using nondeterministic Turing machines (the traditional way). However, a modern approach to define NP is to use the concept of certificate and verifier. Formally, NP is defined as the set of languages over a finite alphabet that have a verifier that runs in polynomial time, where the notion of \"verifier\" is defined as follows.\nLet L be a language over a finite alphabet, \u03a3.\nL \u2208 NP if, and only if, there exists a binary relation \n  \n    \n      \n        R\n        \u2282\n        \n          \u03a3\n          \n            \u2217\n          \n        \n        \u00d7\n        \n          \u03a3\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle R\\subset \\Sigma ^{*}\\times \\Sigma ^{*}}\n   and a positive integer k such that the following two conditions are satisfied:\n\nFor all \n  \n    \n      \n        x\n        \u2208\n        \n          \u03a3\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle x\\in \\Sigma ^{*}}\n  , \n  \n    \n      \n        x\n        \u2208\n        L\n        \u21d4\n        \u2203\n        y\n        \u2208\n        \n          \u03a3\n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle x\\in L\\Leftrightarrow \\exists y\\in \\Sigma ^{*}}\n   such that (x, y) \u2208 R and \n  \n    \n      \n        \n          |\n        \n        y\n        \n          |\n        \n        \u2208\n        O\n        (\n        \n          |\n        \n        x\n        \n          \n            |\n          \n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle |y|\\in O(|x|^{k})}\n  ; and\nthe language \n  \n    \n      \n        \n          L\n          \n            R\n          \n        \n        =\n        {\n        x\n        #\n        y\n        :\n        (\n        x\n        ,\n        y\n        )\n        \u2208\n        R\n        }\n      \n    \n    {\\displaystyle L_{R}=\\{x\\#y:(x,y)\\in R\\}}\n   over \n  \n    \n      \n        \u03a3\n        \u222a\n        {\n        #\n        }\n      \n    \n    {\\displaystyle \\Sigma \\cup \\{\\#\\}}\n   is decidable by a deterministic Turing machine in polynomial time.A Turing machine that decides LR is called a verifier for L and a y such that (x, y) \u2208 R is called a certificate of membership of x in L.\nIn general, a verifier does not have to be polynomial-time. However, for L to be in NP, there must be a verifier that runs in polynomial time.\n\n\n==== Example ====\nLet\n\n  \n    \n      \n        \n          C\n          O\n          M\n          P\n          O\n          S\n          I\n          T\n          E\n        \n        =\n        \n          {\n          \n            x\n            \u2208\n            \n              N\n            \n            \u2223\n            x\n            =\n            p\n            q\n            \n               for integers \n            \n            p\n            ,\n            q\n            >\n            1\n          \n          }\n        \n      \n    \n    {\\displaystyle \\mathrm {COMPOSITE} =\\left\\{x\\in \\mathbb {N} \\mid x=pq{\\text{ for integers }}p,q>1\\right\\}}\n  \n\n  \n    \n      \n        R\n        =\n        \n          {\n          \n            (\n            x\n            ,\n            y\n            )\n            \u2208\n            \n              N\n            \n            \u00d7\n            \n              N\n            \n            \u2223\n            1\n            <\n            y\n            \u2264\n            \n              \n                x\n              \n            \n            \n               and \n            \n            y\n            \n               divides \n            \n            x\n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle R=\\left\\{(x,y)\\in \\mathbb {N} \\times \\mathbb {N} \\mid 1<y\\leq {\\sqrt {x}}{\\text{ and }}y{\\text{ divides }}x\\right\\}.}\n  Clearly, the question of whether a given x is a composite is equivalent to the question of whether x is a member of COMPOSITE. It can be shown that COMPOSITE \u2208 NP by verifying that it satisfies the above definition (if we identify natural numbers with their binary representations).\nCOMPOSITE also happens to be in P, a fact demonstrated by the invention of the AKS primality test.\n\n\n=== NP-completeness ===\n\nThere are many equivalent ways of describing NP-completeness.\nLet L be a language over a finite alphabet \u03a3.\nL is NP-complete if, and only if, the following two conditions are satisfied:\n\nL \u2208 NP; and\nany L' in NP is polynomial-time-reducible to L (written as \n  \n    \n      \n        \n          L\n          \u2032\n        \n        \n          \u2264\n          \n            p\n          \n        \n        L\n      \n    \n    {\\displaystyle L'\\leq _{p}L}\n  ), where \n  \n    \n      \n        \n          L\n          \u2032\n        \n        \n          \u2264\n          \n            p\n          \n        \n        L\n      \n    \n    {\\displaystyle L'\\leq _{p}L}\n   if, and only if, the following two conditions are satisfied:\nThere exists f : \u03a3* \u2192 \u03a3* such that for all w in \u03a3* we have: \n  \n    \n      \n        (\n        w\n        \u2208\n        \n          L\n          \u2032\n        \n        \u21d4\n        f\n        (\n        w\n        )\n        \u2208\n        L\n        )\n      \n    \n    {\\displaystyle (w\\in L'\\Leftrightarrow f(w)\\in L)}\n  ; and\nthere exists a polynomial-time Turing machine that halts with f(w) on its tape on any input w.Alternatively, if L \u2208 NP, and there is another NP-complete problem that can be polynomial-time reduced to L, then L is NP-complete. This is a common way of proving some new problem is NP-complete.\n\n\n== Popular culture ==\nThe film Travelling Salesman, by director Timothy Lanzone, is the story of four mathematicians hired by the US government to solve the P versus NP problem.In the sixth episode of The Simpsons' seventh season \"Treehouse of Horror VI\", the equation P = NP is seen shortly after Homer accidentally stumbles into the \"third dimension\".In the second episode of season 2 of Elementary, \"Solve for X\" revolves around Sherlock and Watson investigating the murders of mathematicians who were attempting to solve P versus NP.\n\n\n== See also ==\nGame complexity\nList of unsolved problems in mathematics\nUnique games conjecture\nUnsolved problems in computer science\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Sources ==\nRachel Crowell (28 May 2021). \"The Top Unsolved Questions in Mathematics Remain Mostly Mysterious Just one of the seven Millennium Prize Problems named 21 years ago has been solved\". www.scientificamerican.com. Retrieved 21 June 2021. This problem concerns the issue of whether questions that are easy to verify (a class of queries called NP) also have solutions that are easy to find (a class called P).\nHosch, William L (11 August 2009). \"P versus NP problem mathematics\". Encyclop\u00e6dia Britannica. Retrieved 20 June 2021.\n\"P vs NP Problem\". www.claymath.org (Cook, Levin). Retrieved 20 June 2021. Suppose that you are organizing housing accommodations for a group of four hundred university students. Space is limited and only one hundred of the students will receive places in the dormitory. To complicate matters, the Dean has provided you with a list of pairs of incompatible students, and requested that no pair from this list appear in your final choice. This is an example of what computer scientists call an NP-problem...\n\n\n== Further reading ==\nCormen, Thomas (2001). Introduction to Algorithms. Cambridge: MIT Press. ISBN 978-0-262-03293-3.\nGarey, Michael; Johnson, David (1979). Computers and Intractability: A Guide to the Theory of NP-Completeness. San Francisco: W. H. Freeman and Company. ISBN 978-0-7167-1045-5.\nGoldreich, Oded (2010). P, NP, and NP-Completeness. Cambridge: Cambridge University Press. ISBN 978-0-521-12254-2. Online drafts\nImmerman, N. (1987). \"Languages that Capture Complexity Classes\". SIAM Journal on Computing. 16 (4): 760\u2013778. CiteSeerX 10.1.1.75.3035. doi:10.1137/0216051.\nPapadimitriou, Christos (1994). Computational Complexity. Boston: Addison-Wesley. ISBN 978-0-201-53082-7.\n\n\n== External links ==\n\nFortnow, L.; Gasarch, W. \"Computational complexity\".\nAviad Rubinstein's Hardness of Approximation Between P and NP, winner of the ACM's 2017 Doctoral Dissertation Award.\n\"P vs. NP and the Computational Complexity Zoo\". 26 August 2014. Archived from the original on 24 November 2021 \u2013 via YouTube.",
        "content_traditional": "additional evidence difficulty problem essentially known proof techniques computational complexity theory fall one following classifications known insufficient prove p \u2260 np barriers another reason npcomplete problems useful polynomialtime algorithm demonstrated npcomplete problem would solve p np problem way excluded results. donald knuth stated come believe p np reserved impact possible proof imagine number finite incredibly large \u2014 like say number 10\u2191\u2191\u2191\u21913 discussed paper coping finiteness \u2014 humongous number possible algorithms nm bitwise addition shift operations n given bits really hard believe algorithms fail. popular culture film travelling salesman director timothy lanzone story four mathematicians hired us government solve p versus np problemin sixth episode simpsons seventh season treehouse horror vi equation p np seen shortly homer accidentally stumbles third dimensionin second episode season 2 elementary solve x revolves around sherlock watson investigating murders mathematicians attempting solve p versus np. algorithm say turing machine computer program unbounded memory produce correct answer input string length n cnk steps k c constants independent input string say problem solved polynomial time place class p formally p defined set languages decided deterministic polynomialtime turing machine. long signature contains least one predicate function addition distinguished order relation amount space taken store finite structures actually polynomial number elements structure precisely characterizes p similarly np set languages expressible existential secondorder logic \u2014 secondorder logic restricted exclude universal quantification relations functions subsets. example simplex algorithm linear programming works surprisingly well practice despite exponential worstcase time complexity runs par best known polynomialtime algorithmsfinally types computations conform turing machine model p np defined quantum computation randomized algorithms. let l language finite alphabet \u03c3 l npcomplete following two conditions satisfied l \u2208 np l np polynomialtimereducible l written l \u2032 \u2264 p l displaystyle lleq pl l \u2032 \u2264 p l displaystyle lleq pl following two conditions satisfied exists f \u03c3 \u2192 \u03c3 w \u03c3 w \u2208 l \u2032 \u21d4 f w \u2208 l displaystyle win lleftrightarrow fwin l exists polynomialtime turing machine halts fw tape input walternatively l \u2208 np another npcomplete problem polynomialtime reduced l l npcomplete. however shown using techniques sort currently known applicable problem decided even much weaker assumptions extending peano axioms pa integer arithmetic would necessarily exist nearly polynomialtime algorithms every problem np. polls imply anything whether p np true stated gasarch bring us closer solving pnp knowing solved attempts objective report subjective opinion era. example problem deciding whether graph g contains h minor h fixed solved running time on2 n number vertices g however big notation hides constant depends superexponentially h constant greater 2 \u2191\u2191 2 \u2191\u2191 2 \u2191\u2191 h 2 displaystyle 2uparrow uparrow 2uparrow uparrow 2uparrow uparrow h2 using knuths uparrow notation h number vertices hon hand even problem shown npcomplete even p \u2260 np may still effective approaches tackling problem practice. let l language finite alphabet \u03c3 l \u2208 np exists binary relation r \u2282 \u03c3 \u2217 \u00d7 \u03c3 \u2217 displaystyle rsubset sigma times sigma positive integer k following two conditions satisfied x \u2208 \u03c3 \u2217 displaystyle xin sigma x \u2208 l \u21d4 \u2203 \u2208 \u03c3 \u2217 displaystyle xin lleftrightarrow exists yin sigma x \u2208 r \u2208 x k displaystyle yin oxk language l r x x \u2208 r displaystyle lrxyxyin r \u03c3 \u222a displaystyle sigma cup decidable deterministic turing machine polynomial timea turing machine decides lr called verifier l x \u2208 r called certificate membership x l general verifier polynomialtime. based definition alone obvious npcomplete problems exist however trivial contrived npcomplete problem formulated follows given description turing machine guaranteed halt polynomial time exist polynomialsize input accept. theory class p consists decision problems defined solved deterministic sequential machine amount time polynomial size input class np consists decision problems whose positive solutions verified polynomial time given right information equivalently whose solution found polynomial time nondeterministic machine. fischer rabin proved 1974 every algorithm decides truth presburger statements length n runtime least 2 2 c n displaystyle 22cn constant c hence problem known need exponential run time. similarly stephen cook assuming proof practically efficient algorithm says would transform mathematics allowing computer find formal proof theorem proof reasonable length since formal proofs easily recognized polynomial time. g\u00f6del asked whether theoremproving known conpcomplete could solved quadratic linear time pointed one important consequences \u2013 discovery mathematical proofs could automated.",
        "custom_approach": "However, for L to be in NP, there must be a verifier that runs in polynomial time.The film Travelling Salesman, by director Timothy Lanzone, is the story of four mathematicians hired by the US government to solve the P versus NP problem.In the sixth episode of The Simpsons' seventh season \"Treehouse of Horror VI\", the equation P = NP is seen shortly after Homer accidentally stumbles into the \"third dimension\".In the second episode of season 2 of Elementary, \"Solve for X\" revolves around Sherlock and Watson investigating the murders of mathematicians who were attempting to solve P versus NP. An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity, it runs on par with the best known polynomial-time algorithms.Finally, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms.Cook provides a restatement of the problem in The P Versus NP Problem as \"Does P = NP?\" As additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, each of which is known to be insufficient to prove that P \u2260 NP: These barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results. Donald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof: [...] if you imagine a number M that's finite but incredibly large\u2014like say the number 10\u2191\u2191\u2191\u21913 discussed in my paper on \"coping with finiteness\"\u2014then there's a humongous number of possible algorithms that do nM bitwise or addition or shift operations on n given bits, and it's really hard to believe that all of those algorithms fail. G\u00f6del asked whether theorem-proving (now known to be co-NP-complete) could be solved in quadratic or linear time, and pointed out one of the most important consequences \u2013 that if so, then the discovery of mathematical proofs could be automated.The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that can produce the correct answer for any input string of length n in at most cnk steps, where k and c are constants independent of the input string, then we say that the problem can be solved in polynomial time and we place it in the class P. Formally, P is defined as the set of all languages that can be decided by a deterministic polynomial-time Turing machine. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P. Similarly, NP is the set of languages expressible in existential second-order logic\u2014that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets. Let L be a language over a finite alphabet \u03a3. L is NP-complete if, and only if, the following two conditions are satisfied: L \u2208 NP; and any L' in NP is polynomial-time-reducible to L (written as L \u2032 \u2264 p L {\\displaystyle L'\\leq _{p}L} ), where L \u2032 \u2264 p L {\\displaystyle L'\\leq _{p}L} if, and only if, the following two conditions are satisfied: There exists f : \u03a3* \u2192 \u03a3* such that for all w in \u03a3* we have: ( w \u2208 L \u2032 \u21d4 f ( w ) \u2208 L ) {\\displaystyle (w\\in L'\\Leftrightarrow f(w)\\in L)} ; and there exists a polynomial-time Turing machine that halts with f(w) on its tape on any input w.Alternatively, if L \u2208 NP, and there is another NP-complete problem that can be polynomial-time reduced to L, then L is NP-complete. My main point, however, is that I don't believe that the equality P = NP will turn out to be helpful even if it is proved, because such a proof will almost surely be nonconstructive.A proof showing that P \u2260 NP would lack the practical computational benefits of a proof that P = NP, but would nevertheless represent a very significant advance in computational complexity theory and provide guidance for future research. However, if it can be shown, using techniques of the sort that are currently known to be applicable, that the problem cannot be decided even with much weaker assumptions extending the Peano axioms (PA) for integer arithmetic, then there would necessarily exist nearly polynomial-time algorithms for every problem in NP. If the shortest program that can solve SUBSET-SUM in polynomial time is b bits long, the above algorithm will try at least 2b \u2212 1 other programs first.Conceptually speaking, a decision problem is a problem that takes as input some string w over an alphabet \u03a3, and outputs \"yes\" or \"no\". Additionally, this result implies that proving independence from PA or ZFC using currently known techniques is no easier than proving the existence of efficient algorithms for all problems in NP.While the P versus NP problem is generally considered unsolved, many amateur and some professional researchers have claimed solutions. These polls do not imply anything about whether P = NP is true, as stated by Gasarch himself: \"This does not bring us any closer to solving P=?NP or to knowing when it will be solved, but it attempts to be an objective report on the subjective opinion of this era. For example, the problem of deciding whether a graph G contains H as a minor, where H is fixed, can be solved in a running time of O(n2), where n is the number of vertices in G. However, the big O notation hides a constant that depends superexponentially on H. The constant is greater than 2 \u2191\u2191 ( 2 \u2191\u2191 ( 2 \u2191\u2191 ( h / 2 ) ) ) {\\displaystyle 2\\uparrow \\uparrow (2\\uparrow \\uparrow (2\\uparrow \\uparrow (h/2)))} (using Knuth's up-arrow notation), and where h is the number of vertices in H.On the other hand, even if a problem is shown to be NP-complete, and even if P \u2260 NP, there may still be effective approaches to tackling the problem in practice. Let L be a language over a finite alphabet, \u03a3. L \u2208 NP if, and only if, there exists a binary relation R \u2282 \u03a3 \u2217 \u00d7 \u03a3 \u2217 {\\displaystyle R\\subset \\Sigma ^{*}\\times \\Sigma ^{*}} and a positive integer k such that the following two conditions are satisfied: For all x \u2208 \u03a3 \u2217 {\\displaystyle x\\in \\Sigma ^{*}} , x \u2208 L \u21d4 \u2203 y \u2208 \u03a3 \u2217 {\\displaystyle x\\in L\\Leftrightarrow \\exists y\\in \\Sigma ^{*}} such that (x, y) \u2208 R and | y | \u2208 O ( | x | k ) {\\displaystyle |y|\\in O(|x|^{k})} ; and the language L R = { x # y : ( x , y ) \u2208 R } {\\displaystyle L_{R}=\\{x\\#y:(x,y)\\in R\\}} over \u03a3 \u222a { # } {\\displaystyle \\Sigma \\cup \\{\\#\\}} is decidable by a deterministic Turing machine in polynomial time.A Turing machine that decides LR is called a verifier for L and a y such that (x, y) \u2208 R is called a certificate of membership of x in L. In general, a verifier does not have to be polynomial-time.",
        "combined_approach": "however l np must verifier runs polynomial timethe film travelling salesman director timothy lanzone story four mathematicians hired us government solve p versus np problemin sixth episode simpsons seventh season treehouse horror vi equation p np seen shortly homer accidentally stumbles third dimensionin second episode season 2 elementary solve x revolves around sherlock watson investigating murders mathematicians attempting solve p versus np. example simplex algorithm linear programming works surprisingly well practice despite exponential worstcase time complexity runs par best known polynomialtime algorithmsfinally types computations conform turing machine model p np defined quantum computation randomized algorithmscook provides restatement problem p versus np problem p np. additional evidence difficulty problem essentially known proof techniques computational complexity theory fall one following classifications known insufficient prove p \u2260 np barriers another reason npcomplete problems useful polynomialtime algorithm demonstrated npcomplete problem would solve p np problem way excluded results. donald knuth stated come believe p np reserved impact possible proof imagine number finite incredibly large \u2014 like say number 10\u2191\u2191\u2191\u21913 discussed paper coping finiteness \u2014 humongous number possible algorithms nm bitwise addition shift operations n given bits really hard believe algorithms fail. g\u00f6del asked whether theoremproving known conpcomplete could solved quadratic linear time pointed one important consequences \u2013 discovery mathematical proofs could automatedthe relation complexity classes p np studied computational complexity theory part theory computation dealing resources required computation solve given problem. algorithm say turing machine computer program unbounded memory produce correct answer input string length n cnk steps k c constants independent input string say problem solved polynomial time place class p formally p defined set languages decided deterministic polynomialtime turing machine. long signature contains least one predicate function addition distinguished order relation amount space taken store finite structures actually polynomial number elements structure precisely characterizes p similarly np set languages expressible existential secondorder logic \u2014 secondorder logic restricted exclude universal quantification relations functions subsets. let l language finite alphabet \u03c3 l npcomplete following two conditions satisfied l \u2208 np l np polynomialtimereducible l written l \u2032 \u2264 p l displaystyle lleq pl l \u2032 \u2264 p l displaystyle lleq pl following two conditions satisfied exists f \u03c3 \u2192 \u03c3 w \u03c3 w \u2208 l \u2032 \u21d4 f w \u2208 l displaystyle win lleftrightarrow fwin l exists polynomialtime turing machine halts fw tape input walternatively l \u2208 np another npcomplete problem polynomialtime reduced l l npcomplete. main point however nt believe equality p np turn helpful even proved proof almost surely nonconstructivea proof showing p \u2260 np would lack practical computational benefits proof p np would nevertheless represent significant advance computational complexity theory provide guidance future research. however shown using techniques sort currently known applicable problem decided even much weaker assumptions extending peano axioms pa integer arithmetic would necessarily exist nearly polynomialtime algorithms every problem np. shortest program solve subsetsum polynomial time b bits long algorithm try least 2b \u2212 1 programs firstconceptually speaking decision problem problem takes input string w alphabet \u03c3 outputs yes. additionally result implies proving independence pa zfc using currently known techniques easier proving existence efficient algorithms problems npwhile p versus np problem generally considered unsolved many amateur professional researchers claimed solutions. polls imply anything whether p np true stated gasarch bring us closer solving pnp knowing solved attempts objective report subjective opinion era. example problem deciding whether graph g contains h minor h fixed solved running time on2 n number vertices g however big notation hides constant depends superexponentially h constant greater 2 \u2191\u2191 2 \u2191\u2191 2 \u2191\u2191 h 2 displaystyle 2uparrow uparrow 2uparrow uparrow 2uparrow uparrow h2 using knuths uparrow notation h number vertices hon hand even problem shown npcomplete even p \u2260 np may still effective approaches tackling problem practice. let l language finite alphabet \u03c3 l \u2208 np exists binary relation r \u2282 \u03c3 \u2217 \u00d7 \u03c3 \u2217 displaystyle rsubset sigma times sigma positive integer k following two conditions satisfied x \u2208 \u03c3 \u2217 displaystyle xin sigma x \u2208 l \u21d4 \u2203 \u2208 \u03c3 \u2217 displaystyle xin lleftrightarrow exists yin sigma x \u2208 r \u2208 x k displaystyle yin oxk language l r x x \u2208 r displaystyle lrxyxyin r \u03c3 \u222a displaystyle sigma cup decidable deterministic turing machine polynomial timea turing machine decides lr called verifier l x \u2208 r called certificate membership x l general verifier polynomialtime."
    },
    {
        "topic": "Geometric complexity theory",
        "summary": "Geometric complexity theory (GCT), is a research program in computational complexity theory proposed by Ketan Mulmuley and Milind Sohoni. The goal of the program is to answer the most famous open problem in computer science \u2013 whether P = NP \u2013 by showing that the complexity class P is not equal to the complexity class NP.\nThe idea behind the approach is to adopt and develop advanced tools in algebraic geometry and representation theory (i.e., geometric invariant theory) to prove lower bounds for problems. Currently the main focus of the program is on algebraic complexity classes. Proving that computing the permanent cannot be efficiently reduced to computing determinants is considered to be a major milestone for the program. These computational problems can be characterized by their symmetries. The program aims at utilizing these symmetries for proving lower bounds.\nThe approach is considered by some to be the only viable currently active program to separate P from NP. However, Ketan Mulmuley believes the program, if viable, is likely to take about 100 years before it can settle the P vs. NP problem.The program is pursued by several researchers in mathematics and theoretical computer science. Part of the reason for the interest in the program is the existence of arguments for the program avoiding known barriers such as relativization and natural proofs for proving general lower bounds.\n\n",
        "content": "\n== References ==\n\n\n== Further reading ==\nK. D. Mulmuley and M. Sohoni. Geometric Complexity Theory I: An Approach to the P vs. NP and Related Problems. SIAM J. Comput. 31(2), 496\u2013526, 2001.\nK. D. Mulmuley and M. Sohoni. Geometric Complexity Theory II: Towards Explicit Obstructions for Embeddings among Class Varieties. SIAM J. Comput., 38(3), 1175\u20131206, 2008.\nK. D. Mulmuley, H. Narayanan, and M. Sohoni. Geometric complexity theory III: on deciding nonvanishing of a Littlewood-Richardson coefficient. J. Algebraic Combin. 36 (2012), no. 1, 103\u2013110.\nK. D. Mulmuley. Geometric Complexity Theory V: Efficient algorithms for Noether normalization. J. Amer. Math. Soc. 30 (2017), no. 1, 225-309. arXiv:1209.5993 [cs.CC]\nK. D. Mulmuley. Geometric Complexity Theory VI: the flip via positivity., Technical Report, Computer Science department, The University of Chicago, January 2011.\n\n\n== External links ==\nGCT page, University of Chicago\nDescription on the Simons Institute webpage\nGCT questions on cstheory\nWikipedia-style explanation of Geometric Complexity Theory by Joshua Grochow\nWhat are the current breakthroughs of Geometric Complexity Theory?",
        "content_traditional": "references reading k mulmuley sohoni. geometric complexity theory approach p vs np related problems. siam j comput. 312 496\u2013526 2001. k mulmuley sohoni. geometric complexity theory ii towards explicit obstructions embeddings among class varieties. siam j. comput 383 1175\u20131206 2008. k mulmuley h narayanan sohoni. geometric complexity theory iii deciding nonvanishing littlewoodrichardson coefficient. j algebraic combin. 36 2012. 1 103\u2013110. k mulmuley. geometric complexity theory v efficient algorithms noether normalization. j amer. math. soc. 30 2017. 1 225309 arxiv12095993 cscc k mulmuley. geometric complexity theory vi flip via positivity technical report computer science department university chicago january 2011. external links gct page university chicago description simons institute webpage gct questions cstheory wikipediastyle explanation geometric complexity theory joshua grochow current breakthroughs geometric complexity theory.",
        "custom_approach": "",
        "combined_approach": "."
    },
    {
        "topic": "NP (complexity)",
        "summary": "In computational complexity theory, NP (nondeterministic polynomial time) is a complexity class used to classify decision problems.  NP is the set of decision problems for which the problem instances, where the answer is \"yes\", have proofs verifiable in polynomial time by a deterministic Turing machine, or alternatively the set of problems that can be solved in polynomial time by a nondeterministic Turing machine.An equivalent definition of NP is the set of decision problems solvable in polynomial time by a nondeterministic Turing machine. This definition is the basis for the abbreviation NP; \"nondeterministic, polynomial time\".   These two definitions are equivalent because the algorithm based on the Turing machine consists of two phases, the first of which consists of a guess about the solution, which is generated in a nondeterministic way, while the second phase consists of a deterministic algorithm that verifies whether the guess is a solution to the problem.It is easy to see that the complexity class P (all problems solvable, deterministically, in polynomial time) is contained in NP (problems where solutions can be verified in polynomial time), because if a problem is solvable in polynomial time, then a solution is also verifiable in polynomial time by simply solving the problem. But NP contains many more problems, the hardest of which are called NP-complete problems. An algorithm solving such a problem in polynomial time is also able to solve any other NP problem in polynomial time. The most important P versus NP (\u201cP = NP?\u201d) problem, asks whether polynomial-time algorithms exist for solving NP-complete, and by corollary, all NP problems. It is widely believed that this is not the case.The complexity class NP is related to the complexity class co-NP, for which the answer \"no\" can be verified in polynomial time. Whether or not NP = co-NP is another outstanding question in complexity theory.",
        "content": "\n\n\n== Formal definition ==\nThe complexity class NP can be defined in terms of NTIME as follows:\n\n  \n    \n      \n        \n          \n            N\n            P\n          \n        \n        =\n        \n          \u22c3\n          \n            k\n            \u2208\n            \n              N\n            \n          \n        \n        \n          \n            N\n            T\n            I\n            M\n            E\n          \n        \n        (\n        \n          n\n          \n            k\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle {\\mathsf {NP}}=\\bigcup _{k\\in \\mathbb {N} }{\\mathsf {NTIME}}(n^{k}),}\n  where \n  \n    \n      \n        \n          \n            N\n            T\n            I\n            M\n            E\n          \n        \n        (\n        \n          n\n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathsf {NTIME}}(n^{k})}\n   is the set of decision problems that can be solved by a nondeterministic Turing machine in \n  \n    \n      \n        O\n        (\n        \n          n\n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle O(n^{k})}\n   time.\nAlternatively, NP can be defined using deterministic Turing machines as verifiers. A language L is in NP if and only if there exist polynomials p and q, and a deterministic Turing machine M, such that\n\nFor all x and y, the machine M runs in time p(|x|) on input \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle (x,y)}\n  .\nFor all x in L, there exists a string y of length q(|x|) such that \n  \n    \n      \n        M\n        (\n        x\n        ,\n        y\n        )\n        =\n        1\n      \n    \n    {\\displaystyle M(x,y)=1}\n  .\nFor all x not in L and all strings y of length q(|x|), \n  \n    \n      \n        M\n        (\n        x\n        ,\n        y\n        )\n        =\n        0\n      \n    \n    {\\displaystyle M(x,y)=0}\n  .\n\n\n== Background ==\nMany computer science problems are contained in NP, like decision versions of many search and optimization problems.\n\n\n=== Verifier-based definition ===\nIn order to explain the verifier-based definition of NP, consider the subset sum problem:\nAssume that we are given some integers, {\u22127, \u22123, \u22122, 5, 8}, and we wish to know whether some of these integers sum up to zero. Here the answer is \"yes\", since the integers {\u22123, \u22122, 5} corresponds to the sum (\u22123) + (\u22122) + 5 = 0. \nTo answer whether some of the integers add to zero we can create an algorithm that obtains all the possible subsets. As the number of integers that we feed into the algorithm becomes larger, both the number of subsets and the computation time grows exponentially.\nBut notice that if we are given a particular subset, we can efficiently verify whether the subset sum is zero, by summing the integers of the subset. If the sum is zero, that subset is a proof or witness for the answer is \"yes\". An algorithm that verifies whether a given subset has sum zero is a verifier. Clearly, summing the integers of a subset can be done in polynomial time, and the subset sum problem is therefore in NP.\nThe above example can be generalized for any decision problem. Given any instance I of problem \n  \n    \n      \n        \u03a0\n      \n    \n    {\\displaystyle \\Pi }\n   and witness W, if there exists a verifier V so that given the ordered pair (I, W) as input, V returns \"yes\" in polynomial time if the witness proves that the answer is \"yes\" or \"no\" in polynomial time otherwise, then \n  \n    \n      \n        \u03a0\n      \n    \n    {\\displaystyle \\Pi }\n   is in NP.\nThe \"no\"-answer version of this problem is stated as: \"given a finite set of integers, does every non-empty subset have a nonzero sum?\". The verifier-based definition of NP does not require an efficient verifier for the \"no\"-answers. The class of problems with such verifiers for the \"no\"-answers is called co-NP. In fact, it is an open question whether all problems in NP also have verifiers for the \"no\"-answers and thus are in co-NP.\nIn some literature the verifier is called the \"certifier\", and the witness the \"certificate\".\n\n\n=== Machine-definition ===\nEquivalent to the verifier-based definition is the following characterization: NP is the class of decision problems solvable by a nondeterministic Turing machine that runs in polynomial time. That is to say, a decision problem \n  \n    \n      \n        \u03a0\n      \n    \n    {\\displaystyle \\Pi }\n   is in NP whenever \n  \n    \n      \n        \u03a0\n      \n    \n    {\\displaystyle \\Pi }\n   is recognized by some polynomial-time nondeterministic Turing machine \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   with an existential acceptance condition, meaning that \n  \n    \n      \n        w\n        \u2208\n        \u03a0\n      \n    \n    {\\displaystyle w\\in \\Pi }\n   if and only if some computation path of \n  \n    \n      \n        M\n        (\n        w\n        )\n      \n    \n    {\\displaystyle M(w)}\n   leads to an accepting state. This definition is equivalent to the verifier-based definition because a nondeterministic Turing machine could solve an NP problem in polynomial time by nondeterministically selecting a certificate and running the verifier on the certificate.  Similarly, if such a machine exists, then a polynomial time verifier can naturally be constructed from it.\nIn this light, we can define co-NP dually as the class of decision problems recognizable by polynomial-time nondeterministic Turing machines with an existential rejection condition.  Since an existential rejection condition is exactly the same thing as a universal acceptance condition, we can understand the NP vs. co-NP question as asking whether the existential and universal acceptance conditions have the same expressive power for the class of polynomial-time nondeterministic Turing machines.\n\n\n== Properties ==\nNP is closed under union, intersection, concatenation, Kleene star and reversal. It is not known whether NP is closed under complement (this question is the so-called \"NP versus co-NP\" question).\n\n\n== Why some NP problems are hard to solve ==\nBecause of the many important problems in this class, there have been extensive efforts to find polynomial-time algorithms for problems in NP. However, there remain a large number of problems in NP that defy such attempts, seeming to require super-polynomial time. Whether these problems are not decidable in polynomial time is one of the greatest open questions in computer science (see P versus NP (\"P = NP\") problem for an in-depth discussion).\nAn important notion in this context is the set of NP-complete decision problems, which is a subset of NP and might be informally described as the \"hardest\" problems in NP. If there is a polynomial-time algorithm for even one of them, then there is a polynomial-time algorithm for all the problems in NP. Because of this, and because dedicated research has failed to find a polynomial algorithm for any NP-complete problem, once a problem has been proven to be NP-complete, this is widely regarded as a sign that a polynomial algorithm for this problem is unlikely to exist.\nHowever, in practical uses, instead of spending computational resources looking for an optimal solution, a good enough (but potentially suboptimal) solution may often be found in polynomial time. Also, the real-life applications of some problems are easier than their theoretical equivalents.\n\n\n== Equivalence of definitions ==\nThe two definitions of NP as the class of problems solvable by a nondeterministic Turing machine (TM) in polynomial time and the class of problems verifiable by a deterministic Turing machine in polynomial time are equivalent. The proof is described by many textbooks, for example, Sipser's Introduction to the Theory of Computation, section 7.3.\nTo show this, first, suppose we have a deterministic verifier. A non-deterministic machine can simply nondeterministically run the verifier on all possible proof strings (this requires only polynomially many steps because it can nondeterministically choose the next character in the proof string in each step, and the length of the proof string must be polynomially bounded). If any proof is valid, some path will accept; if no proof is valid, the string is not in the language and it will reject.\nConversely, suppose we have a non-deterministic TM called A accepting a given language L. At each of its polynomially many steps, the machine's computation tree branches in at most a finite number of directions. There must be at least one accepting path, and the string describing this path is the proof supplied to the verifier. The verifier can then deterministically simulate A, following only the accepting path, and verifying that it accepts at the end. If A rejects the input, there is no accepting path, and the verifier will always reject.\n\n\n== Relationship to other classes ==\n\nNP contains all problems in P, since one can verify any instance of the problem by simply ignoring the proof and solving it. NP is contained in PSPACE\u2014to show this, it suffices to construct a PSPACE machine that loops over all proof strings and feeds each one to a polynomial-time verifier. Since a polynomial-time machine can only read polynomially many bits, it cannot use more than polynomial space, nor can it read a proof string occupying more than polynomial space (so we do not have to consider proofs longer than this). NP is also contained in EXPTIME, since the same algorithm operates in exponential time.\nco-NP contains those problems that have a simple proof for no instances, sometimes called counterexamples. For example, primality testing trivially lies in co-NP, since one can refute the primality of an integer by merely supplying a nontrivial factor. NP and co-NP together form the first level in the polynomial hierarchy, higher only than P.\nNP is defined using only deterministic machines. If we permit the verifier to be probabilistic (this, however, is not necessarily a BPP machine), we get the class MA solvable using an Arthur\u2013Merlin protocol with no communication from Arthur to Merlin.\nThe relationship between BPP and NP is unknown: it is not known whether BPP is a subset of NP, NP is a subset of BPP or neither. If NP is contained in BPP, which is considered unlikely since it would imply practical solutions for NP-complete problems, then NP = RP and PH \u2286 BPP.NP is a class of decision problems; the analogous class of function problems is FNP.\nThe only known strict inclusions come from the time hierarchy theorem and the space hierarchy theorem, and respectively they are \n  \n    \n      \n        \n          \n            N\n            P\n            \u228a\n            N\n            E\n            X\n            P\n            T\n            I\n            M\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {NP\\subsetneq NEXPTIME}}}\n   and \n  \n    \n      \n        \n          \n            N\n            P\n            \u228a\n            E\n            X\n            P\n            S\n            P\n            A\n            C\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {NP\\subsetneq EXPSPACE}}}\n  .\n\n\n== Other characterizations ==\nIn terms of descriptive complexity theory, NP corresponds precisely to the set of languages definable by existential second-order logic (Fagin's theorem).\nNP can be seen as a very simple type of interactive proof system, where the prover comes up with the proof certificate and the verifier is a deterministic polynomial-time machine that checks it. It is complete because the right proof string will make it accept if there is one, and it is sound because the verifier cannot accept if there is no acceptable proof string.\nA major result of complexity theory is that NP can be characterized as the problems solvable by probabilistically checkable proofs where the verifier uses O(log n) random bits and examines only a constant number of bits of the proof string (the class PCP(log n, 1)). More informally, this means that the NP verifier described above can be replaced with one that just \"spot-checks\" a few places in the proof string, and using a limited number of coin flips can determine the correct answer with high probability. This allows several results about the hardness of approximation algorithms to be proven.\n\n\n== Examples ==\n\n\n=== P ===\nAll problems in P, denoted \n  \n    \n      \n        \n          \n            P\n            \u2286\n            N\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P\\subseteq NP}}}\n  . Given a certificate for a problem in P, we can ignore the certificate and just solve the problem in polynomial time.\n\n\n=== Integer factorization ===\nThe decision problem version of the integer factorization problem: given integers n and k, is there a factor f with 1 < f < k and f dividing n?\n\n\n=== NP-complete problems ===\n\nEvery NP-complete problem is in NP.\n\n\n==== Boolean satisfiability ====\nThe boolean satisfiability problem (SAT), where we want to know whether or not a certain formula in propositional logic with boolean variables is true for some value of the variables.\n\n\n==== Travelling salesman ====\nThe decision version of the travelling salesman problem is in NP. Given an input matrix of distances between n cities, the problem is to determine if there is a route visiting all cities with total distance less than k.\nA proof can simply be a list of the cities. Then verification can clearly be done in polynomial time. It simply adds the matrix entries corresponding to the paths between the cities.\nA nondeterministic Turing machine can find such a route as follows:\n\nAt each city it visits it will \"guess\" the next city to visit, until it has visited every vertex. If it gets stuck, it stops immediately.\nAt the end it verifies that the route it has taken has cost less than k in O(n) time.One can think of each guess as \"forking\" a new copy of the Turing machine to follow each of the possible paths forward, and if at least one machine finds a route of distance less than k, that machine accepts the input. (Equivalently, this can be thought of as a single Turing machine that always guesses correctly)\nA binary search on the range of possible distances can convert the decision version of Traveling Salesman to the optimization version, by calling the decision version repeatedly (a polynomial number of times).\n\n\n==== Subgraph isomorphism ====\nThe subgraph isomorphism problem of determining whether graph G contains a subgraph that is isomorphic to graph H.\n\n\n== See also ==\nTuring machine \u2013 Computation model defining an abstract machine\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nThomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms, Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Section 34.2: Polynomial-time verification, pp. 979\u2013983.\nMichael Sipser (1997). Introduction to the Theory of Computation. PWS Publishing. ISBN 0-534-94728-X. Sections 7.3\u20137.5 (The Class NP, NP-completeness, Additional NP-complete Problems), pp. 241\u2013271.\nDavid Harel, Yishai Feldman. Algorithmics: The Spirit of Computing,  Addison-Wesley, Reading, MA, 3rd edition, 2004.\n\n\n== External links ==\nComplexity Zoo: NP\nAmerican Scientist primer on traditional and recent complexity theory research: \"Accidental Algorithms\"",
        "content_traditional": "end verifies route taken cost less k timeone think guess forking new copy turing machine follow possible paths forward least one machine finds route distance less k machine accepts input. informally means np verifier described replaced one spotchecks places proof string using limited number coin flips determine correct answer high probability. nondeterministic machine simply nondeterministically run verifier possible proof strings requires polynomially many steps nondeterministically choose next character proof string step length proof string must polynomially bounded. equivalently thought single turing machine always guesses correctly binary search range possible distances convert decision version traveling salesman optimization version calling decision version repeatedly polynomial number times. major result complexity theory np characterized problems solvable probabilistically checkable proofs verifier uses olog n random bits examines constant number bits proof string class pcplog n 1. given instance problem \u03c0 displaystyle pi witness w exists verifier v given ordered pair w input v returns yes polynomial time witness proves answer yes polynomial time otherwise \u03c0 displaystyle pi np. since existential rejection condition exactly thing universal acceptance condition understand np vs conp question asking whether existential universal acceptance conditions expressive power class polynomialtime nondeterministic turing machines. subgraph isomorphism subgraph isomorphism problem determining whether graph g contains subgraph isomorphic graph h see also turing machine \u2013 computation model defining abstract machine notes references reading thomas h cormen charles e leiserson ronald l rivest clifford stein. conversely suppose nondeterministic tm called accepting given language l polynomially many steps machines computation tree branches finite number directions. np seen simple type interactive proof system prover comes proof certificate verifier deterministic polynomialtime machine checks. dedicated research failed find polynomial algorithm npcomplete problem problem proven npcomplete widely regarded sign polynomial algorithm problem unlikely exist. np contained bpp considered unlikely since would imply practical solutions npcomplete problems np rp ph \u2286 bppnp class decision problems analogous class function problems fnp. since polynomialtime machine read polynomially many bits use polynomial space read proof string occupying polynomial space consider proofs longer. light define conp dually class decision problems recognizable polynomialtime nondeterministic turing machines existential rejection condition. verifierbased definition order explain verifierbased definition np consider subset sum problem assume given integers \u22127 \u22123 \u22122 5 8 wish know whether integers sum zero. say decision problem \u03c0 displaystyle pi np whenever \u03c0 displaystyle pi recognized polynomialtime nondeterministic turing machine displaystyle existential acceptance condition meaning w \u2208 \u03c0 displaystyle win pi computation path w displaystyle mw leads accepting state. permit verifier probabilistic however necessarily bpp machine get class solvable using arthur \u2013 merlin protocol communication arthur merlin. whether problems decidable polynomial time one greatest open questions computer science see p versus np p np problem indepth discussion. np problems hard solve many important problems class extensive efforts find polynomialtime algorithms problems np. definition equivalent verifierbased definition nondeterministic turing machine could solve np problem polynomial time nondeterministically selecting certificate running verifier certificate. relationship classes np contains problems p since one verify instance problem simply ignoring proof solving. formal definition complexity class np defined terms ntime follows n p \u22c3 k \u2208 n n e n k displaystyle mathsf npbigcup kin mathbb n mathsf ntimenk n e n k displaystyle mathsf ntimenk set decision problems solved nondeterministic turing machine n k displaystyle onk time. given input matrix distances n cities problem determine route visiting cities total distance less k proof simply list cities. however practical uses instead spending computational resources looking optimal solution good enough potentially suboptimal solution may often found polynomial time. important notion context set npcomplete decision problems subset np might informally described hardest problems np. nondeterministic turing machine find route follows city visits guess next city visit visited every vertex. characterizations terms descriptive complexity theory np corresponds precisely set languages definable existential secondorder logic fagins theorem. machinedefinition equivalent verifierbased definition following characterization np class decision problems solvable nondeterministic turing machine runs polynomial time. noanswer version problem stated given finite set integers every nonempty subset nonzero sum. equivalence definitions two definitions np class problems solvable nondeterministic turing machine tm polynomial time class problems verifiable deterministic turing machine polynomial time equivalent. np contained pspace \u2014 show suffices construct pspace machine loops proof strings feeds one polynomialtime verifier. fact open question whether problems np also verifiers noanswers thus conp.",
        "custom_approach": "For all x not in L and all strings y of length q(|x|), M ( x , y ) = 0 {\\displaystyle M(x,y)=0} .Many computer science problems are contained in NP, like decision versions of many search and optimization problems.In order to explain the verifier-based definition of NP, consider the subset sum problem: Assume that we are given some integers, {\u22127, \u22123, \u22122, 5, 8}, and we wish to know whether some of these integers sum up to zero. Given a certificate for a problem in P, we can ignore the certificate and just solve the problem in polynomial time.The decision problem version of the integer factorization problem: given integers n and k, is there a factor f with 1 < f < k and f dividing n?Every NP-complete problem is in NP.The boolean satisfiability problem (SAT), where we want to know whether or not a certain formula in propositional logic with boolean variables is true for some value of the variables.The decision version of the travelling salesman problem is in NP. Since an existential rejection condition is exactly the same thing as a universal acceptance condition, we can understand the NP vs. co-NP question as asking whether the existential and universal acceptance conditions have the same expressive power for the class of polynomial-time nondeterministic Turing machines.NP is closed under union, intersection, concatenation, Kleene star and reversal. (Equivalently, this can be thought of as a single Turing machine that always guesses correctly) A binary search on the range of possible distances can convert the decision version of Traveling Salesman to the optimization version, by calling the decision version repeatedly (a polynomial number of times).The subgraph isomorphism problem of determining whether graph G contains a subgraph that is isomorphic to graph H. At the end it verifies that the route it has taken has cost less than k in O(n) time.One can think of each guess as \"forking\" a new copy of the Turing machine to follow each of the possible paths forward, and if at least one machine finds a route of distance less than k, that machine accepts the input. The only known strict inclusions come from the time hierarchy theorem and the space hierarchy theorem, and respectively they are N P \u228a N E X P T I M E {\\displaystyle {\\mathsf {NP\\subsetneq NEXPTIME}}} and N P \u228a E X P S P A C E {\\displaystyle {\\mathsf {NP\\subsetneq EXPSPACE}}} .In terms of descriptive complexity theory, NP corresponds precisely to the set of languages definable by existential second-order logic (Fagin's theorem). More informally, this means that the NP verifier described above can be replaced with one that just \"spot-checks\" a few places in the proof string, and using a limited number of coin flips can determine the correct answer with high probability. It is not known whether NP is closed under complement (this question is the so-called \"NP versus co-NP\" question).Because of the many important problems in this class, there have been extensive efforts to find polynomial-time algorithms for problems in NP. A non-deterministic machine can simply nondeterministically run the verifier on all possible proof strings (this requires only polynomially many steps because it can nondeterministically choose the next character in the proof string in each step, and the length of the proof string must be polynomially bounded). If A rejects the input, there is no accepting path, and the verifier will always reject.NP contains all problems in P, since one can verify any instance of the problem by simply ignoring the proof and solving it. Also, the real-life applications of some problems are easier than their theoretical equivalents.The two definitions of NP as the class of problems solvable by a nondeterministic Turing machine (TM) in polynomial time and the class of problems verifiable by a deterministic Turing machine in polynomial time are equivalent. A major result of complexity theory is that NP can be characterized as the problems solvable by probabilistically checkable proofs where the verifier uses O(log n) random bits and examines only a constant number of bits of the proof string (the class PCP(log n, 1)). Given any instance I of problem \u03a0 {\\displaystyle \\Pi } and witness W, if there exists a verifier V so that given the ordered pair (I, W) as input, V returns \"yes\" in polynomial time if the witness proves that the answer is \"yes\" or \"no\" in polynomial time otherwise, then \u03a0 {\\displaystyle \\Pi } is in NP. In some literature the verifier is called the \"certifier\", and the witness the \"certificate\".Equivalent to the verifier-based definition is the following characterization: NP is the class of decision problems solvable by a nondeterministic Turing machine that runs in polynomial time. Conversely, suppose we have a non-deterministic TM called A accepting a given language L. At each of its polynomially many steps, the machine's computation tree branches in at most a finite number of directions. NP can be seen as a very simple type of interactive proof system, where the prover comes up with the proof certificate and the verifier is a deterministic polynomial-time machine that checks it. Because of this, and because dedicated research has failed to find a polynomial algorithm for any NP-complete problem, once a problem has been proven to be NP-complete, this is widely regarded as a sign that a polynomial algorithm for this problem is unlikely to exist. If NP is contained in BPP, which is considered unlikely since it would imply practical solutions for NP-complete problems, then NP = RP and PH \u2286 BPP.NP is a class of decision problems; the analogous class of function problems is FNP. Since a polynomial-time machine can only read polynomially many bits, it cannot use more than polynomial space, nor can it read a proof string occupying more than polynomial space (so we do not have to consider proofs longer than this). In this light, we can define co-NP dually as the class of decision problems recognizable by polynomial-time nondeterministic Turing machines with an existential rejection condition. That is to say, a decision problem \u03a0 {\\displaystyle \\Pi } is in NP whenever \u03a0 {\\displaystyle \\Pi } is recognized by some polynomial-time nondeterministic Turing machine M {\\displaystyle M} with an existential acceptance condition, meaning that w \u2208 \u03a0 {\\displaystyle w\\in \\Pi } if and only if some computation path of M ( w ) {\\displaystyle M(w)} leads to an accepting state. If we permit the verifier to be probabilistic (this, however, is not necessarily a BPP machine), we get the class MA solvable using an Arthur\u2013Merlin protocol with no communication from Arthur to Merlin. Whether these problems are not decidable in polynomial time is one of the greatest open questions in computer science (see P versus NP (\"P = NP\") problem for an in-depth discussion). This definition is equivalent to the verifier-based definition because a nondeterministic Turing machine could solve an NP problem in polynomial time by nondeterministically selecting a certificate and running the verifier on the certificate. Given an input matrix of distances between n cities, the problem is to determine if there is a route visiting all cities with total distance less than k. A proof can simply be a list of the cities. However, in practical uses, instead of spending computational resources looking for an optimal solution, a good enough (but potentially suboptimal) solution may often be found in polynomial time. An important notion in this context is the set of NP-complete decision problems, which is a subset of NP and might be informally described as the \"hardest\" problems in NP. A nondeterministic Turing machine can find such a route as follows: At each city it visits it will \"guess\" the next city to visit, until it has visited every vertex.",
        "combined_approach": "x l strings length qx x 0 displaystyle mxy0 many computer science problems contained np like decision versions many search optimization problemsin order explain verifierbased definition np consider subset sum problem assume given integers \u22127 \u22123 \u22122 5 8 wish know whether integers sum zero. given certificate problem p ignore certificate solve problem polynomial timethe decision problem version integer factorization problem given integers n k factor f 1 f k f dividing nevery npcomplete problem npthe boolean satisfiability problem sat want know whether certain formula propositional logic boolean variables true value variablesthe decision version travelling salesman problem np. since existential rejection condition exactly thing universal acceptance condition understand np vs conp question asking whether existential universal acceptance conditions expressive power class polynomialtime nondeterministic turing machinesnp closed union intersection concatenation kleene star reversal. equivalently thought single turing machine always guesses correctly binary search range possible distances convert decision version traveling salesman optimization version calling decision version repeatedly polynomial number timesthe subgraph isomorphism problem determining whether graph g contains subgraph isomorphic graph h end verifies route taken cost less k timeone think guess forking new copy turing machine follow possible paths forward least one machine finds route distance less k machine accepts input. known strict inclusions come time hierarchy theorem space hierarchy theorem respectively n p \u228a n e x p e displaystyle mathsf npsubsetneq nexptime n p \u228a e x p p c e displaystyle mathsf npsubsetneq expspace terms descriptive complexity theory np corresponds precisely set languages definable existential secondorder logic fagins theorem. informally means np verifier described replaced one spotchecks places proof string using limited number coin flips determine correct answer high probability. known whether np closed complement question socalled np versus conp questionbecause many important problems class extensive efforts find polynomialtime algorithms problems np. nondeterministic machine simply nondeterministically run verifier possible proof strings requires polynomially many steps nondeterministically choose next character proof string step length proof string must polynomially bounded. rejects input accepting path verifier always rejectnp contains problems p since one verify instance problem simply ignoring proof solving. also reallife applications problems easier theoretical equivalentsthe two definitions np class problems solvable nondeterministic turing machine tm polynomial time class problems verifiable deterministic turing machine polynomial time equivalent. major result complexity theory np characterized problems solvable probabilistically checkable proofs verifier uses olog n random bits examines constant number bits proof string class pcplog n 1. given instance problem \u03c0 displaystyle pi witness w exists verifier v given ordered pair w input v returns yes polynomial time witness proves answer yes polynomial time otherwise \u03c0 displaystyle pi np. literature verifier called certifier witness certificateequivalent verifierbased definition following characterization np class decision problems solvable nondeterministic turing machine runs polynomial time. conversely suppose nondeterministic tm called accepting given language l polynomially many steps machines computation tree branches finite number directions. np seen simple type interactive proof system prover comes proof certificate verifier deterministic polynomialtime machine checks. dedicated research failed find polynomial algorithm npcomplete problem problem proven npcomplete widely regarded sign polynomial algorithm problem unlikely exist. np contained bpp considered unlikely since would imply practical solutions npcomplete problems np rp ph \u2286 bppnp class decision problems analogous class function problems fnp. since polynomialtime machine read polynomially many bits use polynomial space read proof string occupying polynomial space consider proofs longer. light define conp dually class decision problems recognizable polynomialtime nondeterministic turing machines existential rejection condition. say decision problem \u03c0 displaystyle pi np whenever \u03c0 displaystyle pi recognized polynomialtime nondeterministic turing machine displaystyle existential acceptance condition meaning w \u2208 \u03c0 displaystyle win pi computation path w displaystyle mw leads accepting state. permit verifier probabilistic however necessarily bpp machine get class solvable using arthur \u2013 merlin protocol communication arthur merlin. whether problems decidable polynomial time one greatest open questions computer science see p versus np p np problem indepth discussion. definition equivalent verifierbased definition nondeterministic turing machine could solve np problem polynomial time nondeterministically selecting certificate running verifier certificate. given input matrix distances n cities problem determine route visiting cities total distance less k proof simply list cities. however practical uses instead spending computational resources looking optimal solution good enough potentially suboptimal solution may often found polynomial time. important notion context set npcomplete decision problems subset np might informally described hardest problems np. nondeterministic turing machine find route follows city visits guess next city visit visited every vertex."
    },
    {
        "topic": "Natural proof",
        "summary": "In computational complexity theory, a natural proof is a certain kind of proof establishing that one complexity class differs from another one. While these proofs are in some sense \"natural\", it can be shown (assuming a widely believed conjecture on the existence of pseudorandom functions) that no such proof can possibly be used to solve the P vs. NP problem.",
        "content": "\n\n\n== Overview ==\nThe notion of natural proofs was introduced by Alexander Razborov and Steven Rudich in their article \"Natural Proofs\", first presented in 1994, and later published in 1997, for which they received the 2007 G\u00f6del Prize.Specifically, natural proofs prove lower bounds on the circuit complexity of boolean functions. \nA natural proof shows, either directly or indirectly, that a boolean function has a certain natural combinatorial property. Under the assumption that pseudorandom functions exist with \"exponential hardness\" as specified in their main theorem, Razborov and Rudich show that these proofs cannot separate certain complexity classes. Notably, assuming pseudorandom functions exist, these proofs cannot separate the complexity classes P and NP.For example, their article states:\n\n[...] consider a commonly envisioned proof strategy for proving P \u2260 NP:\nFormulate some mathematical notion of \"discrepancy\" or \"scatter\" or \"variation\" of the values of a Boolean function, or of an associated polytope or other structure. [...]\nShow by an inductive argument that polynomial-sized circuits can only compute functions of \"low\" discrepancy. [...]\nThen show that SAT, or some other function in NP, has \"high\" discrepancy.\nOur main theorem in Section 4 gives evidence that no proof strategy along these lines can ever succeed.A property of boolean functions is defined to be natural if it contains a property meeting the constructivity and largeness conditions defined by Razborov and Rudich. Roughly speaking, the constructivity condition requires that a property be decidable in (quasi-)polynomial time when the 2n-sized truth table of an n-input boolean function is given as input, asymptotically as n increases. This is the same as time singly exponential in n.  Properties that are easy to understand are likely to satisfy this condition. The largeness condition requires that the property hold for a sufficiently large fraction of the set of all boolean functions.\nA property is useful against a complexity class C if every sequence of boolean functions having the property infinitely often defines a language outside of C. A natural proof is a proof that establishes that a certain language lies outside of C and refers to a natural property that is useful against C.\nRazborov and Rudich give a number of examples of lower-bound proofs against classes C smaller than P/poly that can be \"naturalized\", i.e. converted into natural proofs. An important example treats proofs that the parity problem is not in the class AC0.  They give strong evidence that the techniques used in these proofs cannot be extended to show stronger lower bounds. In particular, AC0-natural proofs cannot be useful against AC0[m].\nRazborov and Rudich also reproduce Avi Wigderson's unconditional proof that natural proofs cannot prove exponential lower bounds for the discrete logarithm problem.\nThere is strong current belief that the mechanism of this paper actually blocks lower-bound proofs against the complexity class TC0 of constant-depth, polynomial-sized threshold circuits, which is believed but not proven smaller than P/poly. This belief is because, under widely believed conjectures regarding the hardness of factoring in certain elliptic curve groups, there exist exponentially hard pseudorandom functions computable in TC0. However, some researchers believe that the Razborov-Rudich limitations are actually good guidance for what a \"super-natural\" lower-bound proof might involve, such as properties hard or complete for exponential space.\n\n\n== Notes ==\n\n\n== References ==\nA. A. Razborov (2004). \"Feasible Proofs and Computations: Partnership and Fusion\". Proceedings of the 31st ICALP. Lecture Notes in Computer Science. Vol. 3142. pp. 8\u201314. (Draft)\nLance Fortnow (2006-05-10). \"The Importance of Natural Proofs\".\nChow, Timothy Y. (2011), \"WHAT IS... a Natural Proof?\" (PDF), Notices, AMS, 58 (11), retrieved 2014-08-05",
        "content_traditional": "overview notion natural proofs introduced alexander razborov steven rudich article natural proofs first presented 1994 later published 1997 received 2007 g\u00f6del prizespecifically natural proofs prove lower bounds circuit complexity boolean functions. natural proof shows either directly indirectly boolean function certain natural combinatorial property. assumption pseudorandom functions exist exponential hardness specified main theorem razborov rudich show proofs separate certain complexity classes. notably assuming pseudorandom functions exist proofs separate complexity classes p npfor example article states consider commonly envisioned proof strategy proving p \u2260 np formulate mathematical notion discrepancy scatter variation values boolean function associated polytope structure. show inductive argument polynomialsized circuits compute functions low discrepancy. show sat function np high discrepancy. main theorem section 4 gives evidence proof strategy along lines ever succeeda property boolean functions defined natural contains property meeting constructivity largeness conditions defined razborov rudich. roughly speaking constructivity condition requires property decidable quasipolynomial time 2nsized truth table ninput boolean function given input asymptotically n increases. time singly exponential n properties easy understand likely satisfy condition. largeness condition requires property hold sufficiently large fraction set boolean functions. property useful complexity class c every sequence boolean functions property infinitely often defines language outside c natural proof proof establishes certain language lies outside c refers natural property useful c razborov rudich give number examples lowerbound proofs classes c smaller ppoly naturalized ie. converted natural proofs. important example treats proofs parity problem class ac0. give strong evidence techniques used proofs extended show stronger lower bounds. particular ac0natural proofs useful ac0. razborov rudich also reproduce avi wigdersons unconditional proof natural proofs prove exponential lower bounds discrete logarithm problem. strong current belief mechanism paper actually blocks lowerbound proofs complexity class tc0 constantdepth polynomialsized threshold circuits believed proven smaller ppoly. belief widely believed conjectures regarding hardness factoring certain elliptic curve groups exist exponentially hard pseudorandom functions computable tc0. however researchers believe razborovrudich limitations actually good guidance supernatural lowerbound proof might involve properties hard complete exponential space. notes references. razborov 2004. feasible proofs computations partnership fusion. proceedings 31st icalp. lecture notes computer science. vol. 3142 pp. 8\u201314. draft lance fortnow 20060510. importance natural proofs. chow timothy. 2011 natural proof. pdf notices ams 58 11 retrieved 20140805.",
        "custom_approach": "The notion of natural proofs was introduced by Alexander Razborov and Steven Rudich in their article \"Natural Proofs\", first presented in 1994, and later published in 1997, for which they received the 2007 G\u00f6del Prize.Specifically, natural proofs prove lower bounds on the circuit complexity of boolean functions. A natural proof shows, either directly or indirectly, that a boolean function has a certain natural combinatorial property. Under the assumption that pseudorandom functions exist with \"exponential hardness\" as specified in their main theorem, Razborov and Rudich show that these proofs cannot separate certain complexity classes. Notably, assuming pseudorandom functions exist, these proofs cannot separate the complexity classes P and NP.For example, their article states: [...] consider a commonly envisioned proof strategy for proving P \u2260 NP: Formulate some mathematical notion of \"discrepancy\" or \"scatter\" or \"variation\" of the values of a Boolean function, or of an associated polytope or other structure. [...] Show by an inductive argument that polynomial-sized circuits can only compute functions of \"low\" discrepancy. [...] Then show that SAT, or some other function in NP, has \"high\" discrepancy. Our main theorem in Section 4 gives evidence that no proof strategy along these lines can ever succeed.A property of boolean functions is defined to be natural if it contains a property meeting the constructivity and largeness conditions defined by Razborov and Rudich. Roughly speaking, the constructivity condition requires that a property be decidable in (quasi-)polynomial time when the 2n-sized truth table of an n-input boolean function is given as input, asymptotically as n increases. This is the same as time singly exponential in n. Properties that are easy to understand are likely to satisfy this condition. The largeness condition requires that the property hold for a sufficiently large fraction of the set of all boolean functions. A property is useful against a complexity class C if every sequence of boolean functions having the property infinitely often defines a language outside of C. A natural proof is a proof that establishes that a certain language lies outside of C and refers to a natural property that is useful against C. Razborov and Rudich give a number of examples of lower-bound proofs against classes C smaller than P/poly that can be \"naturalized\", i.e. converted into natural proofs. An important example treats proofs that the parity problem is not in the class AC0. They give strong evidence that the techniques used in these proofs cannot be extended to show stronger lower bounds. In particular, AC0-natural proofs cannot be useful against AC0[m]. Razborov and Rudich also reproduce Avi Wigderson's unconditional proof that natural proofs cannot prove exponential lower bounds for the discrete logarithm problem. There is strong current belief that the mechanism of this paper actually blocks lower-bound proofs against the complexity class TC0 of constant-depth, polynomial-sized threshold circuits, which is believed but not proven smaller than P/poly. This belief is because, under widely believed conjectures regarding the hardness of factoring in certain elliptic curve groups, there exist exponentially hard pseudorandom functions computable in TC0. However, some researchers believe that the Razborov-Rudich limitations are actually good guidance for what a \"super-natural\" lower-bound proof might involve, such as properties hard or complete for exponential space.",
        "combined_approach": "notion natural proofs introduced alexander razborov steven rudich article natural proofs first presented 1994 later published 1997 received 2007 g\u00f6del prizespecifically natural proofs prove lower bounds circuit complexity boolean functions. natural proof shows either directly indirectly boolean function certain natural combinatorial property. assumption pseudorandom functions exist exponential hardness specified main theorem razborov rudich show proofs separate certain complexity classes. notably assuming pseudorandom functions exist proofs separate complexity classes p npfor example article states consider commonly envisioned proof strategy proving p \u2260 np formulate mathematical notion discrepancy scatter variation values boolean function associated polytope structure. show inductive argument polynomialsized circuits compute functions low discrepancy. show sat function np high discrepancy. main theorem section 4 gives evidence proof strategy along lines ever succeeda property boolean functions defined natural contains property meeting constructivity largeness conditions defined razborov rudich. roughly speaking constructivity condition requires property decidable quasipolynomial time 2nsized truth table ninput boolean function given input asymptotically n increases. time singly exponential n properties easy understand likely satisfy condition. largeness condition requires property hold sufficiently large fraction set boolean functions. property useful complexity class c every sequence boolean functions property infinitely often defines language outside c natural proof proof establishes certain language lies outside c refers natural property useful c razborov rudich give number examples lowerbound proofs classes c smaller ppoly naturalized ie. converted natural proofs. important example treats proofs parity problem class ac0. give strong evidence techniques used proofs extended show stronger lower bounds. particular ac0natural proofs useful ac0. razborov rudich also reproduce avi wigdersons unconditional proof natural proofs prove exponential lower bounds discrete logarithm problem. strong current belief mechanism paper actually blocks lowerbound proofs complexity class tc0 constantdepth polynomialsized threshold circuits believed proven smaller ppoly. belief widely believed conjectures regarding hardness factoring certain elliptic curve groups exist exponentially hard pseudorandom functions computable tc0. however researchers believe razborovrudich limitations actually good guidance supernatural lowerbound proof might involve properties hard complete exponential space."
    },
    {
        "topic": "Stephen Cook",
        "summary": "Stephen Arthur Cook  (born December 14, 1939) is an American-Canadian computer scientist and mathematician who has made significant contributions to the fields of complexity theory and proof complexity. He is a university professor at the University of Toronto, Department of Computer Science and Department of Mathematics.",
        "content": "\n\n\n== Biography ==\n\nCook received his bachelor's degree in 1961 from the University of Michigan, and his master's degree and PhD from Harvard University, respectively in 1962 and 1966, from the Mathematics Department. He joined the University of California, Berkeley, mathematics department in 1966 as an assistant professor, and stayed there until 1970 when he was denied reappointment. In a speech celebrating the 30th anniversary of the Berkeley electrical engineering and computer sciences department, fellow Turing Award winner and Berkeley professor Richard Karp said that, \"It is to our everlasting shame that we were unable to persuade the math department to give him tenure.\" Cook joined the faculty of the University of Toronto, Computer Science and Mathematics Departments in 1970 as an associate professor, where he was promoted to professor in 1975 and Distinguished Professor in 1985.\n\n\n== Research ==\nStephen Cook is considered one of the forefathers of computational complexity theory.\nDuring his PhD, Cook worked on complexity of functions, mainly on multiplication. In his seminal 1971 paper \"The Complexity of Theorem Proving Procedures\", Cook formalized the notions of polynomial-time reduction (also known as Cook reduction) and NP-completeness, and proved the existence of an NP-complete problem by showing that the Boolean satisfiability problem (usually known as SAT) is NP-complete. This theorem was proven independently by Leonid Levin in the Soviet Union, and has thus been given the name the Cook\u2013Levin theorem. The paper also formulated the most famous problem in computer science, the P vs. NP problem. Informally, the \"P vs. NP\" question asks whether every optimization problem whose answers can be efficiently verified for correctness/optimality can be solved optimally with an efficient algorithm. Given the abundance of such optimization problems in everyday life, a positive answer to the \"P vs. NP\" question would likely have profound practical and philosophical consequences.\nCook conjectures that there are optimization problems (with easily checkable solutions) that cannot be solved by efficient algorithms, i.e., P is not equal to NP. This conjecture has generated a great deal of research in computational complexity theory, which has considerably improved our understanding of the inherent difficulty of computational problems and what can be computed efficiently. Yet, the conjecture remains open and is among the seven famous Millennium Prize Problems.In 1982, Cook received the Turing Award for his contributions to complexity theory. His citation reads:\n\nFor his advancement of our understanding of the complexity of computation in a significant and profound way. His seminal paper, The Complexity of Theorem Proving Procedures, presented at the 1971 ACM SIGACT Symposium on the Theory of Computing, laid the foundations for the theory of NP-Completeness. The ensuing exploration of the boundaries and nature of NP-complete class of problems has been one of the most active and important research activities in computer science for the last decade.\nIn his \"Feasibly Constructive Proofs and the Propositional Calculus\" paper published in 1975, he introduced the equational theory PV (standing for Polynomial-time Verifiable) to formalize the notion of proofs using only polynomial-time concepts. He made another major contribution to the field in his 1979 paper, joint with his student Robert A. Reckhow, \"The Relative Efficiency of Propositional Proof Systems\", in which they formalized the notions of p-simulation and efficient propositional proof system, which started an area now called propositional proof complexity. They proved that the existence of a proof system in which every true formula has a short proof is equivalent to NP = coNP. Cook co-authored a book with his student Phuong The Nguyen in this area titled \"Logical Foundations of Proof Complexity\".His main research areas are complexity theory and proof complexity, with excursions into programming language semantics, parallel computation, and artificial intelligence. Other areas that he has contributed to include bounded arithmetic, bounded reverse mathematics, complexity of higher type functions, complexity of analysis, and lower bounds in propositional proof systems.\n\n\n=== Some other contributions ===\nHe named the complexity class NC after Nick Pippenger. The complexity class SC is named after him. The definition of the complexity class AC0 and its hierarchy AC are also introduced by him.According to Don Knuth the KMP algorithm was inspired by Cook's automata for recognizing concatenated palindromes in linear time.\n\n\n== Awards and honors ==\nCook was awarded an NSERC E.W.R. Steacie Memorial Fellowship in 1977, a Killam Research Fellowship in 1982, and received the CRM-Fields-PIMS prize in 1999. He has won John L. Synge Award and Bernard Bolzano Medal, and is a fellow of the Royal Society of London and Royal Society of Canada. Cook was elected to membership in the National Academy of Sciences (United States) and the American Academy of Arts and Sciences. He is a corresponding member of the G\u00f6ttingen Academy of Sciences and Humanities.\nCook won the ACM Turing Award in 1982. \nAssociation for Computing Machinery honored him as a Fellow of ACM in 2008 for his\nfundamental contributions to the theory of computational complexity.\nHe was selected by the Association for Symbolic Logic to give the G\u00f6del Lecture in 1999.The Government of Ontario appointed him to the Order of Ontario in 2013, the highest honor in Ontario. He has won the 2012 Gerhard Herzberg Canada Gold Medal for Science and Engineering, the highest honor for scientists and engineers in Canada. The Herzberg Medal is awarded by NSERC for \"both the sustained excellence and overall influence of research work conducted in Canada in the natural sciences or engineering\". He was named an Officer of the Order of Canada in 2015.Cook was granted the BBVA Foundation Frontiers of Knowledge Award 2015 in the Information and Communication Technologies category \"for his important role in identifying what computers can and cannot solve efficiently,\" in the words of the jury's citation. His work, it continues, \"has had a dramatic impact in all fields where complex computations are crucial.\"\nCook has supervised numerous MSc students, and 36 PhD students have completed their degrees under his supervision.\n\n\n== Personal life ==\nCook lives with his wife in Toronto. They have two sons, Gordon and James. He plays the violin and enjoys sailing. He is often called by his short name Steve Cook.\n\n\n== See also ==\nList of pioneers in computer science\n\n\n== References ==\n\n\n== External links ==\n\nHome page of Stephen A. Cook\n'P versus NP' and the Limits of Computation \u2013 Public lecture given by Stephen Cook at the University of Toronto\nOral history interview with Stephen Cook at Charles Babbage Institute, University of Minnesota.   Cook discussed his education at the University of Michigan and Harvard University and early work at the University of California, Berkeley, and his growing interest in problems of computational complexity. Cook recounted his move to the University of Toronto in 1970 and the reception of his work on NP-completeness, leading up to his A.M. Turing Award.\nStephen Arthur Cook at the Mathematics Genealogy Project \nStephen A. Cook at DBLP Bibliography Server",
        "content_traditional": "biography cook received bachelors degree 1961 university michigan masters degree phd harvard university respectively 1962 1966 mathematics department. joined university california berkeley mathematics department 1966 assistant professor stayed 1970 denied reappointment. speech celebrating 30th anniversary berkeley electrical engineering computer sciences department fellow turing award winner berkeley professor richard karp said everlasting shame unable persuade math department give tenure. cook joined faculty university toronto computer science mathematics departments 1970 associate professor promoted professor 1975 distinguished professor 1985. research stephen cook considered one forefathers computational complexity theory. phd cook worked complexity functions mainly multiplication. seminal 1971 paper complexity theorem proving procedures cook formalized notions polynomialtime reduction also known cook reduction npcompleteness proved existence npcomplete problem showing boolean satisfiability problem usually known sat npcomplete. theorem proven independently leonid levin soviet union thus given name cook \u2013 levin theorem. paper also formulated famous problem computer science p vs np problem. informally p vs np question asks whether every optimization problem whose answers efficiently verified correctnessoptimality solved optimally efficient algorithm. given abundance optimization problems everyday life positive answer p vs np question would likely profound practical philosophical consequences. cook conjectures optimization problems easily checkable solutions solved efficient algorithms ie p equal np. conjecture generated great deal research computational complexity theory considerably improved understanding inherent difficulty computational problems computed efficiently. yet conjecture remains open among seven famous millennium prize problemsin 1982 cook received turing award contributions complexity theory. citation reads advancement understanding complexity computation significant profound way. seminal paper complexity theorem proving procedures presented 1971 acm sigact symposium theory computing laid foundations theory npcompleteness. ensuing exploration boundaries nature npcomplete class problems one active important research activities computer science last decade. feasibly constructive proofs propositional calculus paper published 1975 introduced equational theory pv standing polynomialtime verifiable formalize notion proofs using polynomialtime concepts. made another major contribution field 1979 paper joint student robert reckhow relative efficiency propositional proof systems formalized notions psimulation efficient propositional proof system started area called propositional proof complexity. proved existence proof system every true formula short proof equivalent np conp. cook coauthored book student phuong nguyen area titled logical foundations proof complexityhis main research areas complexity theory proof complexity excursions programming language semantics parallel computation artificial intelligence. areas contributed include bounded arithmetic bounded reverse mathematics complexity higher type functions complexity analysis lower bounds propositional proof systems. contributions named complexity class nc nick pippenger. complexity class sc named. definition complexity class ac0 hierarchy ac also introduced himaccording knuth kmp algorithm inspired cooks automata recognizing concatenated palindromes linear time. awards honors cook awarded nserc ewr. steacie memorial fellowship 1977 killam research fellowship 1982 received crmfieldspims prize 1999. john l synge award bernard bolzano medal fellow royal society london royal society canada. cook elected membership national academy sciences united states american academy arts sciences. corresponding member g\u00f6ttingen academy sciences humanities. cook acm turing award 1982. association computing machinery honored fellow acm 2008 fundamental contributions theory computational complexity. selected association symbolic logic give g\u00f6del lecture 1999the government ontario appointed order ontario 2013 highest honor ontario. 2012 gerhard herzberg canada gold medal science engineering highest honor scientists engineers canada. herzberg medal awarded nserc sustained excellence overall influence research work conducted canada natural sciences engineering. named officer order canada 2015cook granted bbva foundation frontiers knowledge award 2015 information communication technologies category important role identifying computers solve efficiently words jurys citation. work continues dramatic impact fields complex computations crucial. cook supervised numerous msc students 36 phd students completed degrees supervision. personal life cook lives wife toronto. two sons gordon james. plays violin enjoys sailing. often called short name steve cook. see also list pioneers computer science references external links home page stephen cook p versus np limits computation \u2013 public lecture given stephen cook university toronto oral history interview stephen cook charles babbage institute university minnesota. cook discussed education university michigan harvard university early work university california berkeley growing interest problems computational complexity. cook recounted move university toronto 1970 reception work npcompleteness leading turing award. stephen arthur cook mathematics genealogy project stephen cook dblp bibliography server.",
        "custom_approach": "Cook received his bachelor's degree in 1961 from the University of Michigan, and his master's degree and PhD from Harvard University, respectively in 1962 and 1966, from the Mathematics Department. He joined the University of California, Berkeley, mathematics department in 1966 as an assistant professor, and stayed there until 1970 when he was denied reappointment. In a speech celebrating the 30th anniversary of the Berkeley electrical engineering and computer sciences department, fellow Turing Award winner and Berkeley professor Richard Karp said that, \"It is to our everlasting shame that we were unable to persuade the math department to give him tenure.\" Cook joined the faculty of the University of Toronto, Computer Science and Mathematics Departments in 1970 as an associate professor, where he was promoted to professor in 1975 and Distinguished Professor in 1985.Stephen Cook is considered one of the forefathers of computational complexity theory. During his PhD, Cook worked on complexity of functions, mainly on multiplication. In his seminal 1971 paper \"The Complexity of Theorem Proving Procedures\", Cook formalized the notions of polynomial-time reduction (also known as Cook reduction) and NP-completeness, and proved the existence of an NP-complete problem by showing that the Boolean satisfiability problem (usually known as SAT) is NP-complete. This theorem was proven independently by Leonid Levin in the Soviet Union, and has thus been given the name the Cook\u2013Levin theorem. The paper also formulated the most famous problem in computer science, the P vs. NP problem. Informally, the \"P vs. NP\" question asks whether every optimization problem whose answers can be efficiently verified for correctness/optimality can be solved optimally with an efficient algorithm. Given the abundance of such optimization problems in everyday life, a positive answer to the \"P vs. NP\" question would likely have profound practical and philosophical consequences. Cook conjectures that there are optimization problems (with easily checkable solutions) that cannot be solved by efficient algorithms, i.e., P is not equal to NP. This conjecture has generated a great deal of research in computational complexity theory, which has considerably improved our understanding of the inherent difficulty of computational problems and what can be computed efficiently. Yet, the conjecture remains open and is among the seven famous Millennium Prize Problems.In 1982, Cook received the Turing Award for his contributions to complexity theory. His citation reads: For his advancement of our understanding of the complexity of computation in a significant and profound way. His seminal paper, The Complexity of Theorem Proving Procedures, presented at the 1971 ACM SIGACT Symposium on the Theory of Computing, laid the foundations for the theory of NP-Completeness. The ensuing exploration of the boundaries and nature of NP-complete class of problems has been one of the most active and important research activities in computer science for the last decade. In his \"Feasibly Constructive Proofs and the Propositional Calculus\" paper published in 1975, he introduced the equational theory PV (standing for Polynomial-time Verifiable) to formalize the notion of proofs using only polynomial-time concepts. He made another major contribution to the field in his 1979 paper, joint with his student Robert A. Reckhow, \"The Relative Efficiency of Propositional Proof Systems\", in which they formalized the notions of p-simulation and efficient propositional proof system, which started an area now called propositional proof complexity. They proved that the existence of a proof system in which every true formula has a short proof is equivalent to NP = coNP. Cook co-authored a book with his student Phuong The Nguyen in this area titled \"Logical Foundations of Proof Complexity\".His main research areas are complexity theory and proof complexity, with excursions into programming language semantics, parallel computation, and artificial intelligence. Other areas that he has contributed to include bounded arithmetic, bounded reverse mathematics, complexity of higher type functions, complexity of analysis, and lower bounds in propositional proof systems.He named the complexity class NC after Nick Pippenger. The complexity class SC is named after him. The definition of the complexity class AC0 and its hierarchy AC are also introduced by him.According to Don Knuth the KMP algorithm was inspired by Cook's automata for recognizing concatenated palindromes in linear time.Cook was awarded an NSERC E.W.R. Steacie Memorial Fellowship in 1977, a Killam Research Fellowship in 1982, and received the CRM-Fields-PIMS prize in 1999. He has won John L. Synge Award and Bernard Bolzano Medal, and is a fellow of the Royal Society of London and Royal Society of Canada. Cook was elected to membership in the National Academy of Sciences (United States) and the American Academy of Arts and Sciences. He is a corresponding member of the G\u00f6ttingen Academy of Sciences and Humanities. Cook won the ACM Turing Award in 1982. Association for Computing Machinery honored him as a Fellow of ACM in 2008 for his fundamental contributions to the theory of computational complexity. He was selected by the Association for Symbolic Logic to give the G\u00f6del Lecture in 1999.The Government of Ontario appointed him to the Order of Ontario in 2013, the highest honor in Ontario. He has won the 2012 Gerhard Herzberg Canada Gold Medal for Science and Engineering, the highest honor for scientists and engineers in Canada. The Herzberg Medal is awarded by NSERC for \"both the sustained excellence and overall influence of research work conducted in Canada in the natural sciences or engineering\". He was named an Officer of the Order of Canada in 2015.Cook was granted the BBVA Foundation Frontiers of Knowledge Award 2015 in the Information and Communication Technologies category \"for his important role in identifying what computers can and cannot solve efficiently,\" in the words of the jury's citation. His work, it continues, \"has had a dramatic impact in all fields where complex computations are crucial.\" Cook has supervised numerous MSc students, and 36 PhD students have completed their degrees under his supervision.Cook lives with his wife in Toronto. They have two sons, Gordon and James. He plays the violin and enjoys sailing. He is often called by his short name Steve Cook.",
        "combined_approach": "cook received bachelors degree 1961 university michigan masters degree phd harvard university respectively 1962 1966 mathematics department. joined university california berkeley mathematics department 1966 assistant professor stayed 1970 denied reappointment. speech celebrating 30th anniversary berkeley electrical engineering computer sciences department fellow turing award winner berkeley professor richard karp said everlasting shame unable persuade math department give tenure. cook joined faculty university toronto computer science mathematics departments 1970 associate professor promoted professor 1975 distinguished professor 1985stephen cook considered one forefathers computational complexity theory. phd cook worked complexity functions mainly multiplication. seminal 1971 paper complexity theorem proving procedures cook formalized notions polynomialtime reduction also known cook reduction npcompleteness proved existence npcomplete problem showing boolean satisfiability problem usually known sat npcomplete. theorem proven independently leonid levin soviet union thus given name cook \u2013 levin theorem. paper also formulated famous problem computer science p vs np problem. informally p vs np question asks whether every optimization problem whose answers efficiently verified correctnessoptimality solved optimally efficient algorithm. given abundance optimization problems everyday life positive answer p vs np question would likely profound practical philosophical consequences. cook conjectures optimization problems easily checkable solutions solved efficient algorithms ie p equal np. conjecture generated great deal research computational complexity theory considerably improved understanding inherent difficulty computational problems computed efficiently. yet conjecture remains open among seven famous millennium prize problemsin 1982 cook received turing award contributions complexity theory. citation reads advancement understanding complexity computation significant profound way. seminal paper complexity theorem proving procedures presented 1971 acm sigact symposium theory computing laid foundations theory npcompleteness. ensuing exploration boundaries nature npcomplete class problems one active important research activities computer science last decade. feasibly constructive proofs propositional calculus paper published 1975 introduced equational theory pv standing polynomialtime verifiable formalize notion proofs using polynomialtime concepts. made another major contribution field 1979 paper joint student robert reckhow relative efficiency propositional proof systems formalized notions psimulation efficient propositional proof system started area called propositional proof complexity. proved existence proof system every true formula short proof equivalent np conp. cook coauthored book student phuong nguyen area titled logical foundations proof complexityhis main research areas complexity theory proof complexity excursions programming language semantics parallel computation artificial intelligence. areas contributed include bounded arithmetic bounded reverse mathematics complexity higher type functions complexity analysis lower bounds propositional proof systemshe named complexity class nc nick pippenger. complexity class sc named. definition complexity class ac0 hierarchy ac also introduced himaccording knuth kmp algorithm inspired cooks automata recognizing concatenated palindromes linear timecook awarded nserc ewr. steacie memorial fellowship 1977 killam research fellowship 1982 received crmfieldspims prize 1999. john l synge award bernard bolzano medal fellow royal society london royal society canada. cook elected membership national academy sciences united states american academy arts sciences. corresponding member g\u00f6ttingen academy sciences humanities. cook acm turing award 1982. association computing machinery honored fellow acm 2008 fundamental contributions theory computational complexity. selected association symbolic logic give g\u00f6del lecture 1999the government ontario appointed order ontario 2013 highest honor ontario. 2012 gerhard herzberg canada gold medal science engineering highest honor scientists engineers canada. herzberg medal awarded nserc sustained excellence overall influence research work conducted canada natural sciences engineering. named officer order canada 2015cook granted bbva foundation frontiers knowledge award 2015 information communication technologies category important role identifying computers solve efficiently words jurys citation. work continues dramatic impact fields complex computations crucial. cook supervised numerous msc students 36 phd students completed degrees supervisioncook lives wife toronto. two sons gordon james. plays violin enjoys sailing. often called short name steve cook."
    },
    {
        "topic": "Kevin McCurley (cryptographer)",
        "summary": "Kevin Snow McCurley is a mathematician, computer scientist, and cryptographer, and a former research scientist at Google. He has written publications about information retrieval, algorithms, parallel computing, cryptography, and number theory.",
        "content": "\n\n\n== Early life and education ==\nWhen he was a child, McCurley had built model planes and cars, and he enjoyed making things with his hands.McCurley attended a high school in San Jose, California. There, one of his teachers, Judy Jones, showed him that \"mathematics really could be fun and interesting\" and encouraged him to attend mathematical contests.In his first year at Santa Clara University, McCurley had Jerry Anderson, a former president of the MAA, as his professor in calculus; Anderson told \"interesting stories\" and was able to \"relate the mathematics to history and to activities that were meaningful\". He started out as a mathematician, but he later retrained himself as a computer scientist.In 1981, McCurley received his Ph.D. in mathematics from the University of Illinois at Urbana-Champaign. His dissertation in analytic number theory was titled Explicit Estimates for Functions of Primes in Arithmetic Progressions, and his advisor was Paul Trevier Bateman. He also received a master's in statistics there.In the fall of 1995, McCurley taught an undergraduate course on cryptology at the University of New Mexico.After he was a post-doc at Michigan State University, McCurley took a job at USC (Los Angeles), where he published some papers with Leonard Adleman about algorithms and complexity.\n\n\n== Career ==\nBefore 2005, McCurley worked at IBM Almaden Research Center, Sandia National Laboratories, and at the University of Southern California. McCurley worked in a cryptography group at Sandia National Laboratories, where he worked on applying number theory to cryptography and parallel computing. He then worked at IBM Research in California on digital rights management, where he wrote a few patents; he was there in January 1999.A former president of the International Association for Cryptologic Research, McCurley was selected as an IACR Fellow in 2005 for his \"exemplary service as IACR President and essential leadership in IACR information systems\".From 2005 to at least 2009 McCurley was a research scientist at Google Research. There, he worked on search, advertisements, and Android.\n\n\n== Miscellany ==\nIn 2000, McCurley suggested, while speaking at Financial Cryptography '00 conference, that, as a countermeasure against email spam, recipients of email from unknown senders should request that the message include a first name, a few dollars, or a donation to a specific charity as compensation. He also suggested that this be formalized in an open standard.\n\n\n=== Bets about P vs NP ===\nMcCurley has made three bets with Ron Fagin about the outcome of the P versus NP problem. In each bet, the outcome P = NP would require Fagin to pay McCurley $50, whereas P != NP would require McCurley to pay Fagin $10. The first bet had a deadline of 31 December 2010, the second a deadline of 31 December 2020, and the third (made in 2021) a deadline of 31 December 2030.\n\n\n== References ==\n\n\n== External links ==\nKevin McCurley's personal home page\nSelected publications",
        "content_traditional": "early life education child mccurley built model planes cars enjoyed making things handsmccurley attended high school san jose california. one teachers judy jones showed mathematics really could fun interesting encouraged attend mathematical contestsin first year santa clara university mccurley jerry anderson former president maa professor calculus anderson told interesting stories able relate mathematics history activities meaningful. started mathematician later retrained computer scientistin 1981 mccurley received phd mathematics university illinois urbanachampaign. dissertation analytic number theory titled explicit estimates functions primes arithmetic progressions advisor paul trevier bateman. also received masters statistics therein fall 1995 mccurley taught undergraduate course cryptology university new mexicoafter postdoc michigan state university mccurley took job usc los angeles published papers leonard adleman algorithms complexity. career 2005 mccurley worked ibm almaden research center sandia national laboratories university southern california. mccurley worked cryptography group sandia national laboratories worked applying number theory cryptography parallel computing. worked ibm research california digital rights management wrote patents january 1999a former president international association cryptologic research mccurley selected iacr fellow 2005 exemplary service iacr president essential leadership iacr information systemsfrom 2005 least 2009 mccurley research scientist google research. worked search advertisements android. miscellany 2000 mccurley suggested speaking financial cryptography 00 conference countermeasure email spam recipients email unknown senders request message include first name dollars donation specific charity compensation. also suggested formalized open standard. bets p vs np mccurley made three bets ron fagin outcome p versus np problem. bet outcome p np would require fagin pay mccurley 50 whereas p np would require mccurley pay fagin 10. first bet deadline 31 december 2010 second deadline 31 december 2020 third made 2021 deadline 31 december 2030. references external links kevin mccurleys personal home page selected publications.",
        "custom_approach": "When he was a child, McCurley had built model planes and cars, and he enjoyed making things with his hands.McCurley attended a high school in San Jose, California. There, one of his teachers, Judy Jones, showed him that \"mathematics really could be fun and interesting\" and encouraged him to attend mathematical contests.In his first year at Santa Clara University, McCurley had Jerry Anderson, a former president of the MAA, as his professor in calculus; Anderson told \"interesting stories\" and was able to \"relate the mathematics to history and to activities that were meaningful\". He started out as a mathematician, but he later retrained himself as a computer scientist.In 1981, McCurley received his Ph.D. in mathematics from the University of Illinois at Urbana-Champaign. His dissertation in analytic number theory was titled Explicit Estimates for Functions of Primes in Arithmetic Progressions, and his advisor was Paul Trevier Bateman. He also received a master's in statistics there.In the fall of 1995, McCurley taught an undergraduate course on cryptology at the University of New Mexico.After he was a post-doc at Michigan State University, McCurley took a job at USC (Los Angeles), where he published some papers with Leonard Adleman about algorithms and complexity.Before 2005, McCurley worked at IBM Almaden Research Center, Sandia National Laboratories, and at the University of Southern California. McCurley worked in a cryptography group at Sandia National Laboratories, where he worked on applying number theory to cryptography and parallel computing. He then worked at IBM Research in California on digital rights management, where he wrote a few patents; he was there in January 1999.A former president of the International Association for Cryptologic Research, McCurley was selected as an IACR Fellow in 2005 for his \"exemplary service as IACR President and essential leadership in IACR information systems\".From 2005 to at least 2009 McCurley was a research scientist at Google Research. There, he worked on search, advertisements, and Android.In 2000, McCurley suggested, while speaking at Financial Cryptography '00 conference, that, as a countermeasure against email spam, recipients of email from unknown senders should request that the message include a first name, a few dollars, or a donation to a specific charity as compensation. He also suggested that this be formalized in an open standard.McCurley has made three bets with Ron Fagin about the outcome of the P versus NP problem. In each bet, the outcome P = NP would require Fagin to pay McCurley $50, whereas P != NP would require McCurley to pay Fagin $10. The first bet had a deadline of 31 December 2010, the second a deadline of 31 December 2020, and the third (made in 2021) a deadline of 31 December 2030.",
        "combined_approach": "child mccurley built model planes cars enjoyed making things handsmccurley attended high school san jose california. one teachers judy jones showed mathematics really could fun interesting encouraged attend mathematical contestsin first year santa clara university mccurley jerry anderson former president maa professor calculus anderson told interesting stories able relate mathematics history activities meaningful. started mathematician later retrained computer scientistin 1981 mccurley received phd mathematics university illinois urbanachampaign. dissertation analytic number theory titled explicit estimates functions primes arithmetic progressions advisor paul trevier bateman. also received masters statistics therein fall 1995 mccurley taught undergraduate course cryptology university new mexicoafter postdoc michigan state university mccurley took job usc los angeles published papers leonard adleman algorithms complexitybefore 2005 mccurley worked ibm almaden research center sandia national laboratories university southern california. mccurley worked cryptography group sandia national laboratories worked applying number theory cryptography parallel computing. worked ibm research california digital rights management wrote patents january 1999a former president international association cryptologic research mccurley selected iacr fellow 2005 exemplary service iacr president essential leadership iacr information systemsfrom 2005 least 2009 mccurley research scientist google research. worked search advertisements androidin 2000 mccurley suggested speaking financial cryptography 00 conference countermeasure email spam recipients email unknown senders request message include first name dollars donation specific charity compensation. also suggested formalized open standardmccurley made three bets ron fagin outcome p versus np problem. bet outcome p np would require fagin pay mccurley 50 whereas p np would require mccurley pay fagin 10. first bet deadline 31 december 2010 second deadline 31 december 2020 third made 2021 deadline 31 december 2030."
    },
    {
        "topic": "Philosophy of computer science",
        "summary": "The philosophy of computer science is concerned with the philosophical questions that arise within the study of computer science. There is still no common understanding of the content, aim, focus, or topic of the philosophy of computer science, despite some attempts to develop a philosophy of computer science like the philosophy of physics or the philosophy of mathematics. Due to the abstract nature of computer programs and the technological ambitions of computer science, many of the conceptual questions of the philosophy of computer science are also comparable to the philosophy of science, philosophy of mathematics, and the philosophy of technology.",
        "content": "\n\n\n== Overview ==\nMany of the central philosophical questions of computer science are centered on the logical, ontological and epistemological issues that concern it. Some of these questions may include:\n\nWhat is computation?\nDoes the Church\u2013Turing thesis capture the mathematical notion of an effective method in logic and mathematics?\nWhat are the philosophical consequences of the P vs NP problem?\nWhat is information?\n\n\n== Church\u2013Turing thesis ==\nThe Church\u2013Turing thesis and its variations are central to the theory of computation. Since, as an informal notion, the concept of effective calculability does not have a formal definition, the thesis, although it has near-universal acceptance, cannot be formally proven. The implications of this thesis is also of philosophical concern. Philosophers have interpreted the Church\u2013Turing thesis as having implications for the philosophy of mind.\n\n\n== P versus NP problem ==\nThe P versus NP problem is an unsolved problem in computer science and mathematics. It asks whether every problem whose solution can be verified in polynomial time (and so defined to belong to the class NP) can also be solved in polynomial time (and so defined to belong to the class P). Most computer scientists believe that P \u2260 NP. Apart from the reason that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems, philosophical reasons that concern its implications may have motivated this belief.\nFor instance, according to Scott Aaronson, the American computer scientist then at MIT:\n\nIf P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in \"creative leaps\", no fundamental gap between solving a problem and recognizing the solution once it's found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss.\n\n\n== See also ==\nComputer-assisted proof: Philosophical objections\nPhilosophy of artificial intelligence\nPhilosophy of information\nPhilosophy of mathematics\nPhilosophy of science\nPhilosophy of technology\n\n\n== References ==\n\n\n== Further reading ==\nMatti Tedre (2014). The Science of Computing: Shaping a Discipline. Chapman Hall.\nScott Aaronson. \"Why Philosophers Should Care About Computational Complexity\". In Computability: G\u00f6del, Turing, Church, and beyond.\nTimothy Colburn. Philosophy and Computer Science. Explorations in Philosophy. M.E. Sharpe, 1999. ISBN 1-56324-991-X.\nA.K. Dewdney. New Turing Omnibus: 66 Excursions in Computer Science\nLuciano Floridi (editor). The Blackwell Guide to the Philosophy of Computing and Information, 2004.\nLuciano Floridi (editor). Philosophy of Computing and Information: 5 Questions. Automatic Press, 2008.\nLuciano Floridi. Philosophy and Computing: An Introduction, Routledge, 1999.\nChristian Jongeneel. The informatical worldview, an inquiry into the methodology of computer science.\nJan van Leeuwen. \"Towards a philosophy of the information and computing sciences\", NIAS Newsletter 42, 2009.\nMoschovakis, Y. (2001). What is an algorithm? In Enquist, B. and Schmid, W., editors, Mathematics unlimited \u2014 2001 and beyond, pages 919\u2013936. Springer.\nAlexander Ollongren, Jaap van den Herik. Filosofie van de informatica. London and New York: Routledge, 1999. ISBN 0-415-19749-X\nTedre, Matti (2014), The Science of Computing: Shaping a Discipline, ISBN 9781482217698 Taylor and Francis.\nRay Turner and Nicola Angius. \"The Philosophy of Computer Science\". Stanford Encyclopedia of Philosophy.\nMatti Tedre (2011). Computing as a Science: A Survey of Competing Viewpoints. Minds & Machines 21, 3, 361\u2013387.\nRay Turner. Computational Artefacts-Towards a Philosophy of Computer Science. Springer. [1]\n\n\n== External links ==\nThe International Association for Computing and Philosophy\nPhilosophy of Computing and Information at PhilPapers\nPhilosophy of Computation at Berkeley\nRapaport, William J. (2020-07-27). \"Philosophy of Computer Science (draft version)\" (PDF). Archived from the original (PDF) on 2021-10-26.",
        "content_traditional": "overview many central philosophical questions computer science centered logical ontological epistemological issues concern. questions may include computation. church \u2013 turing thesis capture mathematical notion effective method logic mathematics. philosophical consequences p vs np problem. information. church \u2013 turing thesis church \u2013 turing thesis variations central theory computation. since informal notion concept effective calculability formal definition thesis although nearuniversal acceptance formally proven. implications thesis also philosophical concern. philosophers interpreted church \u2013 turing thesis implications philosophy mind. p versus np problem p versus np problem unsolved problem computer science mathematics. asks whether every problem whose solution verified polynomial time defined belong class np also solved polynomial time defined belong class p. computer scientists believe p \u2260 np. apart reason decades studying problems one able find polynomialtime algorithm 3000 important known npcomplete problems philosophical reasons concern implications may motivated belief. instance according scott aaronson american computer scientist mit p np world would profoundly different place usually assume. would special value creative leaps fundamental gap solving problem recognizing solution found. everyone could appreciate symphony would mozart everyone could follow stepbystep argument would gauss. see also computerassisted proof philosophical objections philosophy artificial intelligence philosophy information philosophy mathematics philosophy science philosophy technology references reading matti tedre 2014. science computing shaping discipline. chapman hall. scott aaronson. philosophers care computational complexity. computability g\u00f6del turing church beyond. timothy colburn. philosophy computer science. explorations philosophy. . sharpe 1999. isbn 156324991x. ak. dewdney. new turing omnibus 66 excursions computer science luciano floridi editor. blackwell guide philosophy computing information 2004. luciano floridi editor. philosophy computing information 5 questions. automatic press 2008. luciano floridi. philosophy computing introduction routledge 1999. christian jongeneel. informatical worldview inquiry methodology computer science. jan van leeuwen. towards philosophy information computing sciences nias newsletter 42 2009. moschovakis. 2001. algorithm. enquist b schmid w editors mathematics unlimited \u2014 2001 beyond pages 919\u2013936. springer. alexander ollongren jaap van den herik. filosofie van de informatica. london new york routledge 1999. isbn 041519749x tedre matti 2014 science computing shaping discipline isbn 9781482217698 taylor francis. ray turner nicola angius. philosophy computer science. stanford encyclopedia philosophy. matti tedre 2011. computing science survey competing viewpoints. minds machines 21 3 361\u2013387. ray turner. computational artefactstowards philosophy computer science. springer. 1 external links international association computing philosophy philosophy computing information philpapers philosophy computation berkeley rapaport william j. 20200727. philosophy computer science draft version pdf. archived original pdf 20211026.",
        "custom_approach": "Many of the central philosophical questions of computer science are centered on the logical, ontological and epistemological issues that concern it. Some of these questions may include: What is computation? Does the Church\u2013Turing thesis capture the mathematical notion of an effective method in logic and mathematics? What are the philosophical consequences of the P vs NP problem? What is information?The Church\u2013Turing thesis and its variations are central to the theory of computation. Since, as an informal notion, the concept of effective calculability does not have a formal definition, the thesis, although it has near-universal acceptance, cannot be formally proven. The implications of this thesis is also of philosophical concern. Philosophers have interpreted the Church\u2013Turing thesis as having implications for the philosophy of mind.The P versus NP problem is an unsolved problem in computer science and mathematics. It asks whether every problem whose solution can be verified in polynomial time (and so defined to belong to the class NP) can also be solved in polynomial time (and so defined to belong to the class P). Most computer scientists believe that P \u2260 NP. Apart from the reason that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3000 important known NP-complete problems, philosophical reasons that concern its implications may have motivated this belief. For instance, according to Scott Aaronson, the American computer scientist then at MIT: If P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in \"creative leaps\", no fundamental gap between solving a problem and recognizing the solution once it's found. Everyone who could appreciate a symphony would be Mozart; everyone who could follow a step-by-step argument would be Gauss.",
        "combined_approach": "many central philosophical questions computer science centered logical ontological epistemological issues concern. questions may include computation. church \u2013 turing thesis capture mathematical notion effective method logic mathematics. philosophical consequences p vs np problem. informationthe church \u2013 turing thesis variations central theory computation. since informal notion concept effective calculability formal definition thesis although nearuniversal acceptance formally proven. implications thesis also philosophical concern. philosophers interpreted church \u2013 turing thesis implications philosophy mindthe p versus np problem unsolved problem computer science mathematics. asks whether every problem whose solution verified polynomial time defined belong class np also solved polynomial time defined belong class p. computer scientists believe p \u2260 np. apart reason decades studying problems one able find polynomialtime algorithm 3000 important known npcomplete problems philosophical reasons concern implications may motivated belief. instance according scott aaronson american computer scientist mit p np world would profoundly different place usually assume. would special value creative leaps fundamental gap solving problem recognizing solution found. everyone could appreciate symphony would mozart everyone could follow stepbystep argument would gauss."
    },
    {
        "topic": "Computational complexity theory",
        "summary": "In theoretical computer science and mathematics, computational complexity theory focuses on classifying computational problems according to their resource usage, and relating these classes to each other. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.\nA problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying their computational complexity, i.e., the amount of resources needed to solve them, such as time and storage. Other measures of complexity are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do. The P versus NP problem, one of the seven Millennium Prize Problems, is dedicated to the field of computational complexity.Closely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, computational complexity theory tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes computational complexity from computability theory: the latter theory asks what kinds of problems can, in principle, be solved algorithmically.",
        "content": "\n\n\n== Computational problems ==\n\n\n=== Problem instances ===\nA computational problem can be viewed as an infinite collection of instances together with a set (possibly empty) of solutions for every instance. The input string for a computational problem is referred to as a problem instance, and should not be confused with the problem itself. In computational complexity theory, a problem refers to the abstract question to be solved. In contrast, an instance of this problem is a rather concrete utterance, which can serve as the input for a decision problem. For example, consider the problem of primality testing. The instance is a number (e.g., 15) and the solution is \"yes\" if the number is prime and \"no\" otherwise (in this case, 15 is not prime and the answer is \"no\"). Stated another way, the instance is a particular input to the problem, and the solution is the output corresponding to the given input.\nTo further highlight the difference between a problem and an instance, consider the following instance of the decision version of the traveling salesman problem: Is there a route of at most 2000 kilometres passing through all of Germany's 15 largest cities? The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. For this reason, complexity theory addresses computational problems and not particular problem instances.\n\n\n=== Representing problem instances ===\nWhen considering computational problems, a problem instance is a string over an alphabet. Usually, the alphabet is taken to be the binary alphabet (i.e., the set {0,1}), and thus the strings are bitstrings. As in a real-world computer, mathematical objects other than bitstrings must be suitably encoded. For example, integers can be represented in binary notation, and graphs can be encoded directly via their adjacency matrices, or by encoding their adjacency lists in binary.\nEven though some proofs of complexity-theoretic theorems regularly assume some concrete choice of input encoding, one tries to keep the discussion abstract enough to be independent of the choice of encoding. This can be achieved by ensuring that different representations can be transformed into each other efficiently.\n\n\n=== Decision problems as formal languages ===\n\nDecision problems are one of the central objects of study in computational complexity theory. A decision problem is a special type of computational problem whose answer is either yes or no, or alternately either 1 or 0. A decision problem can be viewed as a formal language, where the members of the language are instances whose output is yes, and the non-members are those instances whose output is no. The objective is to decide, with the aid of an algorithm, whether a given input string is a member of the formal language under consideration. If the algorithm deciding this problem returns the answer yes, the algorithm is said to accept the input string, otherwise it is said to reject the input.\nAn example of a decision problem is the following. The input is an arbitrary graph. The problem consists in deciding whether the given graph is connected or not. The formal language associated with this decision problem is then the set of all connected graphs \u2014 to obtain a precise definition of this language, one has to decide how graphs are encoded as binary strings.\n\n\n=== Function problems ===\nA function problem is a computational problem where a single output (of a total function) is expected for every input, but the output is more complex than that of a decision problem\u2014that is, the output isn't just yes or no. Notable examples include the traveling salesman problem and the integer factorization problem.\nIt is tempting to think that the notion of function problems is much richer than the notion of decision problems. However, this is not really the case, since function problems can be recast as decision problems. For example, the multiplication of two integers can be expressed as the set of triples (a, b, c) such that the relation a \u00d7 b = c holds. Deciding whether a given triple is a member of this set corresponds to solving the problem of multiplying two numbers.\n\n\n=== Measuring the size of an instance ===\nTo measure the difficulty of solving a computational problem, one may wish to see how much time the best algorithm requires to solve the problem. However, the running time may, in general, depend on the instance. In particular, larger instances will require more time to solve. Thus the time required to solve a problem (or the space required, or any measure of complexity) is calculated as a function of the size of the instance. This is usually taken to be the size of the input in bits. Complexity theory is interested in how algorithms scale with an increase in the input size. For instance, in the problem of finding whether a graph is connected, how much more time does it take to solve a problem for a graph with 2n vertices compared to the time taken for a graph with n vertices?\nIf the input size is n, the time taken can be expressed as a function of n. Since the time taken on different inputs of the same size can be different, the worst-case time complexity T(n) is defined to be the maximum time taken over all inputs of size n. If T(n) is a polynomial in n, then the algorithm is said to be a polynomial time algorithm. Cobham's thesis argues that a problem can be solved with a feasible amount of resources if it admits a polynomial-time algorithm.\n\n\n== Machine models and complexity measures ==\n\n\n=== Turing machine ===\n\nA Turing machine is a mathematical model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a general model of a computing machine\u2014anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church\u2013Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata, lambda calculus or any programming language can be computed on a Turing machine. Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the Turing machine is the most commonly used model in complexity theory.\nMany types of Turing machines are used to define complexity classes, such as deterministic Turing machines, probabilistic Turing machines, non-deterministic Turing machines, quantum Turing machines, symmetric Turing machines and alternating Turing machines. They are all equally powerful in principle, but when resources (such as time or space) are bounded, some of these may be more powerful than others.\nA deterministic Turing machine is the most basic Turing machine, which uses a fixed set of rules to determine its future actions. A probabilistic Turing machine is a deterministic Turing machine with an extra supply of random bits. The ability to make probabilistic decisions often helps algorithms solve problems more efficiently. Algorithms that use random bits are called randomized algorithms. A non-deterministic Turing machine is a deterministic Turing machine with an added feature of non-determinism, which allows a Turing machine to have multiple possible future actions from a given state. One way to view non-determinism is that the Turing machine branches into many possible computational paths at each step, and if it solves the problem in any of these branches, it is said to have solved the problem. Clearly, this model is not meant to be a physically realizable model, it is just a theoretically interesting abstract machine that gives rise to particularly interesting complexity classes. For examples, see non-deterministic algorithm.\n\n\n=== Other machine models ===\nMany machine models different from the standard multi-tape Turing machines have been proposed in the literature, for example random-access machines. Perhaps surprisingly, each of these models can be converted to another without providing any extra computational power. The time and memory consumption of these alternate models may vary. What all these models have in common is that the machines operate deterministically.\nHowever, some computational problems are easier to analyze in terms of more unusual resources. For example, a non-deterministic Turing machine is a computational model that is allowed to branch out to check many different possibilities at once. The non-deterministic Turing machine has very little to do with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing computational problems.\n\n\n=== Complexity measures ===\nFor a precise definition of what it means to solve a problem using a given amount of time and space, a computational model such as the deterministic Turing machine is used. The time required by a deterministic Turing machine M on input x is the total number of state transitions, or steps, the machine makes before it halts and outputs the answer (\"yes\" or \"no\"). A Turing machine M is said to operate within time f(n) if the time required by M on each input of length n is at most f(n). A decision problem A can be solved in time f(n) if there exists a Turing machine operating in time f(n) that solves the problem. Since complexity theory is interested in classifying problems based on their difficulty, one defines sets of problems based on some criteria. For instance, the set of problems solvable within time f(n) on a deterministic Turing machine is then denoted by DTIME(f(n)).\nAnalogous definitions can be made for space requirements. Although time and space are the most well-known complexity resources, any complexity measure can be viewed as a computational resource. Complexity measures are very generally defined by the Blum complexity axioms. Other complexity measures used in complexity theory include communication complexity, circuit complexity, and decision tree complexity.\nThe complexity of an algorithm is often expressed using big O notation.\n\n\n=== Best, worst and average case complexity ===\n\nThe best, worst and average case complexity refer to three different ways of measuring the time complexity (or any other complexity measure) of different inputs of the same size. Since some inputs of size n may be faster to solve than others, we define the following complexities:\n\nBest-case complexity: This is the complexity of solving the problem for the best input of size n.\nAverage-case complexity: This is the complexity of solving the problem on an average. This complexity is only defined with respect to a probability distribution over the inputs. For instance, if all inputs of the same size are assumed to be equally likely to appear, the average case complexity can be defined with respect to the uniform distribution over all inputs of size n.\nAmortized analysis: Amortized analysis considers both the costly and less costly operations together over the whole series of operations of the algorithm.\nWorst-case complexity: This is the complexity of solving the problem for the worst input of size n.The order from cheap to costly is: Best, average (of discrete uniform distribution), amortized, worst.\nFor example, consider the deterministic sorting algorithm quicksort. This solves the problem of sorting a list of integers that is given as the input. The worst-case is when the pivot is always the largest or smallest value in the list (so the list is never divided). In this case the algorithm takes time O(n2). If we assume that all possible permutations of the input list are equally likely, the average time taken for sorting is O(n log n). The best case occurs when each pivoting divides the list in half, also needing O(n log n) time.\n\n\n=== Upper and lower bounds on the complexity of problems ===\nTo classify the computation time (or similar resources, such as space consumption), it is helpful to demonstrate upper and lower bounds on the maximum amount of time required by the most efficient algorithm to solve a given problem. The complexity of an algorithm is usually taken to be its worst-case complexity unless specified otherwise. Analyzing a particular algorithm falls under the field of analysis of algorithms. To show an upper bound T(n) on the time complexity of a problem, one needs to show only that there is a particular algorithm with running time at most T(n). However, proving lower bounds is much more difficult, since lower bounds make a statement about all possible algorithms that solve a given problem. The phrase \"all possible algorithms\" includes not just the algorithms known today, but any algorithm that might be discovered in the future. To show a lower bound of T(n) for a problem requires showing that no algorithm can have time complexity lower than T(n).\nUpper and lower bounds are usually stated using the big O notation, which hides constant factors and smaller terms. This makes the bounds independent of the specific details of the computational model used. For instance, if T(n) = 7n2 + 15n + 40, in big O notation one would write T(n) = O(n2).\n\n\n== Complexity classes ==\n\n\n=== Defining complexity classes ===\nA complexity class is a set of problems of related complexity. Simpler complexity classes are defined by the following factors:\n\nThe type of computational problem: The most commonly used problems are decision problems. However, complexity classes can be defined based on function problems, counting problems, optimization problems, promise problems, etc.\nThe model of computation: The most common model of computation is the deterministic Turing machine, but many complexity classes are based on non-deterministic Turing machines, Boolean circuits, quantum Turing machines, monotone circuits, etc.\nThe resource (or resources) that is being bounded and the bound: These two properties are usually stated together, such as \"polynomial time\", \"logarithmic space\", \"constant depth\", etc.Some complexity classes have complicated definitions that do not fit into this framework. Thus, a typical complexity class has a definition like the following:\n\nThe set of decision problems solvable by a deterministic Turing machine within time f(n). (This complexity class is known as DTIME(f(n)).)But bounding the computation time above by some concrete function f(n) often yields complexity classes that depend on the chosen machine model. For instance, the language {xx | x is any binary string} can be solved in linear time on a multi-tape Turing machine, but necessarily requires quadratic time in the model of single-tape Turing machines. If we allow polynomial variations in running time, Cobham-Edmonds thesis states that \"the time complexities in any two reasonable and general models of computation are polynomially related\" (Goldreich 2008, Chapter 1.2). This forms the basis for the complexity class P, which is the set of decision problems solvable by a deterministic Turing machine within polynomial time. The corresponding set of function problems is FP.\n\n\n=== Important complexity classes ===\n\nMany important complexity classes can be defined by bounding the time or space used by the algorithm. Some important complexity classes of decision problems defined in this manner are the following:\n\nThe logarithmic-space classes (necessarily) do not take into account the space needed to represent the problem.\nIt turns out that PSPACE = NPSPACE and EXPSPACE = NEXPSPACE by Savitch's theorem.\nOther important complexity classes include BPP, ZPP and RP, which are defined using probabilistic Turing machines; AC and NC, which are defined using Boolean circuits; and BQP and QMA, which are defined using quantum Turing machines. #P is an important complexity class of counting problems (not decision problems). Classes like IP and AM are defined using Interactive proof systems. ALL is the class of all decision problems.\n\n\n=== Hierarchy theorems ===\n\nFor the complexity classes defined in this way, it is desirable to prove that relaxing the requirements on (say) computation time indeed defines a bigger set of problems. In particular, although DTIME(n) is contained in DTIME(n2), it would be interesting to know if the inclusion is strict. For time and space requirements, the answer to such questions is given by the time and space hierarchy theorems respectively. They are called hierarchy theorems because they induce a proper hierarchy on the classes defined by constraining the respective resources. Thus there are pairs of complexity classes such that one is properly included in the other. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved.\nMore precisely, the time hierarchy theorem states that\n\n  \n    \n      \n        \n          \n            D\n            T\n            I\n            M\n            E\n          \n        \n        \n          \n            (\n          \n        \n        f\n        (\n        n\n        )\n        \n          \n            )\n          \n        \n        \u228a\n        \n          \n            D\n            T\n            I\n            M\n            E\n          \n        \n        \n          \n            (\n          \n        \n        f\n        (\n        n\n        )\n        \u22c5\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        (\n        f\n        (\n        n\n        )\n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {DTIME}}{\\big (}f(n){\\big )}\\subsetneq {\\mathsf {DTIME}}{\\big (}f(n)\\cdot \\log ^{2}(f(n)){\\big )}}\n  .The space hierarchy theorem states that\n\n  \n    \n      \n        \n          \n            D\n            S\n            P\n            A\n            C\n            E\n          \n        \n        \n          \n            (\n          \n        \n        f\n        (\n        n\n        )\n        \n          \n            )\n          \n        \n        \u228a\n        \n          \n            D\n            S\n            P\n            A\n            C\n            E\n          \n        \n        \n          \n            (\n          \n        \n        f\n        (\n        n\n        )\n        \u22c5\n        log\n        \u2061\n        (\n        f\n        (\n        n\n        )\n        )\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {DSPACE}}{\\big (}f(n){\\big )}\\subsetneq {\\mathsf {DSPACE}}{\\big (}f(n)\\cdot \\log(f(n)){\\big )}}\n  .The time and space hierarchy theorems form the basis for most separation results of complexity classes. For instance, the time hierarchy theorem tells us that P is strictly contained in EXPTIME, and the space hierarchy theorem tells us that L is strictly contained in PSPACE.\n\n\n=== Reduction ===\n\nMany complexity classes are defined using the concept of a reduction. A reduction is a transformation of one problem into another problem. It captures the informal notion of a problem being at most as difficult as another problem. For instance, if a problem X can be solved using an algorithm for Y, X is no more difficult than Y, and we say that X reduces to Y. There are many different types of reductions, based on the method of reduction, such as Cook reductions, Karp reductions and Levin reductions, and the bound on the complexity of reductions, such as polynomial-time reductions or log-space reductions.\nThe most commonly used reduction is a polynomial-time reduction. This means that the reduction process takes polynomial time. For example, the problem of squaring an integer can be reduced to the problem of multiplying two integers. This means an algorithm for multiplying two integers can be used to square an integer. Indeed, this can be done by giving the same input to both inputs of the multiplication algorithm. Thus we see that squaring is not more difficult than multiplication, since squaring can be reduced to multiplication.\nThis motivates the concept of a problem being hard for a complexity class. A problem X is hard for a class of problems C if every problem in C can be reduced to X. Thus no problem in C is harder than X, since an algorithm for X allows us to solve any problem in C. The notion of hard problems depends on the type of reduction being used. For complexity classes larger than P, polynomial-time reductions are commonly used. In particular, the set of problems that are hard for NP is the set of NP-hard problems.\nIf a problem X is in C and hard for C, then X is said to be complete for C. This means that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, \u03a02, to another problem, \u03a01, would indicate that there is no known polynomial-time solution for \u03a01. This is because a polynomial-time solution to \u03a01 would yield a polynomial-time solution to \u03a02. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that can be solved in polynomial time would mean that P = NP.\n\n\n== Important open problems ==\n\n\n=== P versus NP problem ===\n\nThe complexity class P is often seen as a mathematical abstraction modeling those computational tasks that admit an efficient algorithm. This hypothesis is called the Cobham\u2013Edmonds thesis. The complexity class NP, on the other hand, contains many problems that people would like to solve efficiently, but for which no efficient algorithm is known, such as the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem. Since deterministic Turing machines are special non-deterministic Turing machines, it is easily observed that each problem in P is also member of the class NP.\nThe question of whether P equals NP is one of the most important open questions in theoretical computer science because of the wide implications of a solution. If the answer is yes, many important problems can be shown to have more efficient solutions. These include various types of integer programming problems in operations research, many problems in logistics, protein structure prediction in biology, and the ability to find formal proofs of pure mathematics theorems. The P versus NP problem is one of the Millennium Prize Problems proposed by the Clay Mathematics Institute. There is a US$1,000,000 prize for resolving the problem.\n\n\n=== Problems in NP not known to be in P or NP-complete ===\nIt was shown by Ladner that if P \u2260 NP then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete.\nThe graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to L\u00e1szl\u00f3 Babai and Eugene Luks has run time \n  \n    \n      \n        O\n        (\n        \n          2\n          \n            \n              n\n              log\n              \u2061\n              n\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle O(2^{\\sqrt {n\\log n}})}\n   for graphs with n vertices, although some recent work by Babai offers some potentially new perspectives on this.The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a prime factor less than k. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP will equal co-NP). The best known algorithm for integer factorization is the general number field sieve, which takes time \n  \n    \n      \n        O\n        (\n        \n          e\n          \n            \n              (\n              \n                \n                  \n                    64\n                    9\n                  \n                  \n                    3\n                  \n                \n              \n              )\n            \n            \n              \n                \n                  (\n                  log\n                  \u2061\n                  n\n                  )\n                \n                \n                  3\n                \n              \n            \n            \n              \n                \n                  (\n                  log\n                  \u2061\n                  log\n                  \u2061\n                  n\n                  \n                    )\n                    \n                      2\n                    \n                  \n                \n                \n                  3\n                \n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle O(e^{\\left({\\sqrt[{3}]{\\frac {64}{9}}}\\right){\\sqrt[{3}]{(\\log n)}}{\\sqrt[{3}]{(\\log \\log n)^{2}}}})}\n   to factor an odd integer n. However, the best known quantum algorithm for this problem, Shor's algorithm, does run in polynomial time. Unfortunately, this fact doesn't say much about where the problem lies with respect to non-quantum complexity classes.\n\n\n=== Separations between other complexity classes ===\nMany known complexity classes are suspected to be unequal, but this has not been proved. For instance P \u2286 NP \u2286 PP \u2286 PSPACE, but it is possible that P = PSPACE. If P is not equal to NP, then P is not equal to PSPACE either. Since there are many known complexity classes between P and PSPACE, such as RP, BPP, PP, BQP, MA, PH, etc., it is possible that all these complexity classes collapse to one class. Proving that any of these classes are unequal would be a major breakthrough in complexity theory.\nAlong the same lines, co-NP is the class containing the complement problems (i.e. problems with the yes/no answers reversed) of NP problems. It is believed that NP is not equal to co-NP; however, it has not yet been proven. It is clear that if these two complexity classes are not equal then P is not equal to NP, since P=co-P.  Thus if P=NP we would have co-P=co-NP whence NP=P=co-P=co-NP.\nSimilarly, it is not known if L (the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to P. Again, there are many complexity classes between the two, such as NL and NC, and it is not known if they are distinct or equal classes.\nIt is suspected that P and BPP are equal. However, it is currently open if BPP = NEXP.\n\n\n== Intractability ==\n\nA problem that can be solved in theory (e.g. given large but finite resources, especially time), but for which in practice any solution takes too many resources to be useful, is known as an intractable problem. Conversely, a problem that can be solved in practice is called a tractable problem, literally \"a problem that can be handled\". The term infeasible (literally \"cannot be done\") is sometimes used interchangeably with intractable, though this risks confusion with a feasible solution in mathematical optimization.Tractable problems are frequently identified with problems that have polynomial-time solutions (P, PTIME); this is known as the Cobham\u2013Edmonds thesis. Problems that are known to be intractable in this sense include those that are EXPTIME-hard. If NP is not the same as P, then NP-hard problems are also intractable in this sense.\nHowever, this identification is inexact: a polynomial-time solution with large degree or large leading coefficient grows quickly, and may be impractical for practical size problems; conversely, an exponential-time solution that grows slowly may be practical on realistic input, or a solution that takes a long time in the worst case may take a short time in most cases or the average case, and thus still be practical. Saying that a problem is not in P does not imply that all large cases of the problem are hard or even that most of them are. For example, the decision problem in Presburger arithmetic has been shown not to be in P, yet algorithms have been written that solve the problem in reasonable times in most cases. Similarly, algorithms can solve the NP-complete knapsack problem over a wide range of sizes in less than quadratic time and SAT solvers routinely handle large instances of the NP-complete Boolean satisfiability problem.\nTo see why exponential-time algorithms are generally unusable in practice, consider a program that makes 2n operations before halting. For small n, say 100, and assuming for the sake of example that the computer does 1012 operations each second, the program would run for about 4 \u00d7 1010 years, which is the same order of magnitude as the age of the universe. Even with a much faster computer, the program would only be useful for very small instances and in that sense the intractability of a problem is somewhat independent of technological progress. However, an exponential-time algorithm that takes 1.0001n operations is practical until n gets relatively large.\nSimilarly, a polynomial time algorithm is not always practical. If its running time is, say, n15, it is unreasonable to consider it efficient and it is still useless except on small instances. Indeed, in practice even n3 or n2 algorithms are often impractical on realistic sizes of problems.\n\n\n== Continuous complexity theory ==\nContinuous complexity theory can refer to complexity theory of problems that involve continuous functions that are approximated by discretizations, as studied in numerical analysis. One approach to complexity theory of numerical analysis is information based complexity.\nContinuous complexity theory can also refer to complexity theory of the use of analog computation, which uses continuous dynamical systems and differential equations. Control theory can be considered a form of computation and differential equations are used in the modelling of continuous-time and hybrid discrete-continuous-time systems.\n\n\n== History ==\nAn early example of algorithm complexity analysis is the running time analysis of the Euclidean algorithm done by Gabriel Lam\u00e9 in 1844.\nBefore the actual research explicitly devoted to the complexity of algorithmic problems started off, numerous foundations were laid out by various researchers. Most influential among these was the definition of Turing machines by Alan Turing in 1936, which turned out to be a very robust and flexible simplification of a computer.\nThe beginning of systematic studies in computational complexity is attributed to the seminal 1965 paper \"On the Computational Complexity of Algorithms\" by Juris Hartmanis and Richard E. Stearns, which laid out the definitions of time complexity and space complexity, and proved the hierarchy theorems. In addition, in 1965 Edmonds suggested to consider a \"good\" algorithm to be one with running time bounded by a polynomial of the input size.Earlier papers studying problems solvable by Turing machines with specific bounded resources include John Myhill's definition of linear bounded automata (Myhill 1960), Raymond Smullyan's study of rudimentary sets (1961), as well as Hisao Yamada's paper on real-time computations (1962). Somewhat earlier, Boris Trakhtenbrot (1956), a pioneer in the field from the USSR, studied another specific complexity measure. As he remembers:\n\nHowever, [my] initial interest [in automata theory] was increasingly set aside in favor of computational complexity, an exciting fusion of combinatorial methods, inherited from switching theory, with the conceptual arsenal of the theory of algorithms. These ideas had occurred to me earlier in 1955 when I coined the term \"signalizing function\", which is nowadays commonly known as \"complexity measure\".\nIn 1967, Manuel Blum formulated a set of axioms (now known as Blum axioms) specifying desirable properties of complexity measures on the set of computable functions and proved an important result, the so-called speed-up theorem. The field began to flourish in 1971 when Stephen Cook and Leonid Levin proved the existence of practically relevant problems that are NP-complete. In 1972, Richard Karp took this idea a leap forward with his landmark paper, \"Reducibility Among Combinatorial Problems\", in which he showed that 21 diverse combinatorial and graph theoretical problems, each infamous for its computational intractability, are NP-complete.\n\n\n== See also ==\n\n\n== Works on complexity ==\nWuppuluri, Shyam; Doria, Francisco A., eds. (2020), Unravelling Complexity: The Life and Work of Gregory Chaitin, World Scientific, doi:10.1142/11270, ISBN 978-981-12-0006-9, S2CID 198790362\n\n\n== References ==\n\n\n=== Citations ===\n\n\n=== Textbooks ===\nArora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4, Zbl 1193.68112\nDowney, Rod; Fellows, Michael (1999), Parameterized complexity, Monographs in Computer Science, Berlin, New York: Springer-Verlag, ISBN 9780387948836\nDu, Ding-Zhu; Ko, Ker-I (2000), Theory of Computational Complexity, John Wiley & Sons, ISBN 978-0-471-34506-0\nGarey, Michael R.; Johnson, David S. (1979), Computers and Intractability: A Guide to the Theory of NP-Completeness, W. H. Freeman, ISBN 0-7167-1045-5\nGoldreich, Oded (2008), Computational Complexity: A Conceptual Perspective, Cambridge University Press\nvan Leeuwen, Jan, ed. (1990), Handbook of theoretical computer science (vol. A): algorithms and complexity, MIT Press, ISBN 978-0-444-88071-0\nPapadimitriou, Christos (1994), Computational Complexity (1st ed.), Addison Wesley, ISBN 978-0-201-53082-7\nSipser, Michael (2006), Introduction to the Theory of Computation (2nd ed.), USA: Thomson Course Technology, ISBN 978-0-534-95097-2\n\n\n=== Surveys ===\nKhalil, Hatem; Ulery, Dana (1976), \"A Review of Current Studies on Complexity of Algorithms for Partial Differential Equations\", Proceedings of the Annual Conference on - ACM 76, ACM '76: 197\u2013201, doi:10.1145/800191.805573, ISBN 9781450374897, S2CID 15497394\nCook, Stephen (1983), \"An overview of computational complexity\", Commun. ACM, 26 (6): 400\u2013408, doi:10.1145/358141.358144, ISSN 0001-0782, S2CID 14323396\nFortnow, Lance; Homer, Steven (2003), \"A Short History of Computational Complexity\" (PDF), Bulletin of the EATCS, 80: 95\u2013133\nMertens, Stephan (2002), \"Computational Complexity for Physicists\", Computing in Science and Eng., 4 (3): 31\u201347, arXiv:cond-mat/0012185, Bibcode:2002CSE.....4c..31M, doi:10.1109/5992.998639, ISSN 1521-9615, S2CID 633346\n\n\n== External links ==\n\nThe Complexity Zoo\n\"Computational complexity classes\", Encyclopedia of Mathematics, EMS Press, 2001 [1994]\nWhat are the most important results (and papers) in complexity theory that every one should know?\nScott Aaronson: Why Philosophers Should Care About Computational Complexity",
        "content_traditional": "2020 unravelling complexity life work gregory chaitin world scientific doi10114211270 isbn 9789811200069 s2cid 198790362 references citations textbooks arora sanjeev barak boaz 2009 computational complexity modern approach cambridge university press isbn 9780521424264 zbl 119368112 downey rod fellows michael 1999 parameterized complexity monographs computer science berlin new york springerverlag isbn 9780387948836 du dingzhu ko keri 2000 theory computational complexity john wiley sons isbn 9780471345060 garey michael r johnson david 1979 computers intractability guide theory npcompleteness w h freeman isbn 0716710455 goldreich oded 2008 computational complexity conceptual perspective cambridge university press van leeuwen jan ed. acm 26 6 400\u2013408 doi101145358141358144 issn 00010782 s2cid 14323396 fortnow lance homer steven 2003 short history computational complexity pdf bulletin eatcs 80 95\u2013133 mertens stephan 2002 computational complexity physicists computing science eng 4 3 31\u201347 arxivcondmat0012185 bibcode2002cse4c31 doi1011095992998639 issn 15219615 s2cid 633346 external links complexity zoo computational complexity classes encyclopedia mathematics ems press 2001 1994 important results papers complexity theory every one know. addition 1965 edmonds suggested consider good algorithm one running time bounded polynomial input sizeearlier papers studying problems solvable turing machines specific bounded resources include john myhills definition linear bounded automata myhill 1960 raymond smullyans study rudimentary sets 1961 well hisao yamadas paper realtime computations 1962. problem x c hard c x said complete c means x hardest problem c since many problems could equally hard one might say x one hardest problems c thus class npcomplete problems contains difficult problems np sense ones likely p problem p np solved able reduce known npcomplete problem \u03c02 another problem \u03c01 would indicate known polynomialtime solution \u03c01. usa thomson course technology isbn 9780534950972 surveys khalil hatem ulery dana 1976 review current studies complexity algorithms partial differential equations proceedings annual conference acm 76 acm 76 197\u2013201 doi101145800191805573 isbn 9781450374897 s2cid 15497394 cook stephen 1983 overview computational complexity commun. however identification inexact polynomialtime solution large degree large leading coefficient grows quickly may impractical practical size problems conversely exponentialtime solution grows slowly may practical realistic input solution takes long time worst case may take short time cases average case thus still practical. resource resources bounded bound two properties usually stated together polynomial time logarithmic space constant depth etcsome complexity classes complicated definitions fit framework. best algorithm problem due l\u00e1szl\u00f3 babai eugene luks run time 2 n log \u2061 n displaystyle o2sqrt nlog n graphs n vertices although recent work babai offers potentially new perspectives thisthe integer factorization problem computational problem determining prime factorization given integer. term infeasible literally done sometimes used interchangeably intractable though risks confusion feasible solution mathematical optimizationtractable problems frequently identified problems polynomialtime solutions p ptime known cobham \u2013 edmonds thesis. similarly known l set problems solved logarithmic space strictly contained p equal p many complexity classes two nl nc known distinct equal classes. instance inputs size assumed equally likely appear average case complexity defined respect uniform distribution inputs size n amortized analysis amortized analysis considers costly less costly operations together whole series operations algorithm. 1972 richard karp took idea leap forward landmark paper reducibility among combinatorial problems showed 21 diverse combinatorial graph theoretical problems infamous computational intractability npcomplete. phrased decision problem problem deciding whether input prime factor less k efficient integer factorization algorithm known fact forms basis several modern cryptographic systems rsa algorithm. complexity class np hand contains many problems people would like solve efficiently efficient algorithm known boolean satisfiability problem hamiltonian path problem vertex cover problem. quantitative answer particular problem instance little use solving instances problem asking round trip sites milan whose total length 10 km. nondeterministic turing machine little physically want compute algorithms branching exactly captures many mathematical models want analyze nondeterministic time important resource analyzing computational problems. deduced proper set inclusions proceed make quantitative statements much additional time space needed order increase number problems solved. furthermore known everything computed models computation known us today ram machine conways game life cellular automata lambda calculus programming language computed turing machine. highlight difference problem instance consider following instance decision version traveling salesman problem route 2000 kilometres passing germanys 15 largest cities. small n say 100 assuming sake example computer 1012 operations second program would run 4 \u00d7 1010 years order magnitude age universe. upper lower bounds complexity problems classify computation time similar resources space consumption helpful demonstrate upper lower bounds maximum amount time required efficient algorithm solve given problem. remembers however initial interest automata theory increasingly set aside favor computational complexity exciting fusion combinatorial methods inherited switching theory conceptual arsenal theory algorithms.",
        "custom_approach": "(2020), Unravelling Complexity: The Life and Work of Gregory Chaitin, World Scientific, doi:10.1142/11270, ISBN 978-981-12-0006-9, S2CID 198790362Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge University Press, ISBN 978-0-521-42426-4, Zbl 1193.68112 Downey, Rod; Fellows, Michael (1999), Parameterized complexity, Monographs in Computer Science, Berlin, New York: Springer-Verlag, ISBN 9780387948836 Du, Ding-Zhu; Ko, Ker-I (2000), Theory of Computational Complexity, John Wiley & Sons, ISBN 978-0-471-34506-0 Garey, Michael R.; Johnson, David S. (1979), Computers and Intractability: A Guide to the Theory of NP-Completeness, W. H. Freeman, ISBN 0-7167-1045-5 Goldreich, Oded (2008), Computational Complexity: A Conceptual Perspective, Cambridge University Press van Leeuwen, Jan, ed. ACM, 26 (6): 400\u2013408, doi:10.1145/358141.358144, ISSN 0001-0782, S2CID 14323396 Fortnow, Lance; Homer, Steven (2003), \"A Short History of Computational Complexity\" (PDF), Bulletin of the EATCS, 80: 95\u2013133 Mertens, Stephan (2002), \"Computational Complexity for Physicists\", Computing in Science and Eng., 4 (3): 31\u201347, arXiv:cond-mat/0012185, Bibcode:2002CSE.....4c..31M, doi:10.1109/5992.998639, ISSN 1521-9615, S2CID 633346 The non-deterministic Turing machine has very little to do with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing computational problems.For a precise definition of what it means to solve a problem using a given amount of time and space, a computational model such as the deterministic Turing machine is used. In addition, in 1965 Edmonds suggested to consider a \"good\" algorithm to be one with running time bounded by a polynomial of the input size.Earlier papers studying problems solvable by Turing machines with specific bounded resources include John Myhill's definition of linear bounded automata (Myhill 1960), Raymond Smullyan's study of rudimentary sets (1961), as well as Hisao Yamada's paper on real-time computations (1962). If a problem X is in C and hard for C, then X is said to be complete for C. This means that X is the hardest problem in C. (Since many problems could be equally hard, one might say that X is one of the hardest problems in C.) Thus the class of NP-complete problems contains the most difficult problems in NP, in the sense that they are the ones most likely not to be in P. Because the problem P = NP is not solved, being able to reduce a known NP-complete problem, \u03a02, to another problem, \u03a01, would indicate that there is no known polynomial-time solution for \u03a01. ), USA: Thomson Course Technology, ISBN 978-0-534-95097-2Khalil, Hatem; Ulery, Dana (1976), \"A Review of Current Studies on Complexity of Algorithms for Partial Differential Equations\", Proceedings of the Annual Conference on - ACM 76, ACM '76: 197\u2013201, doi:10.1145/800191.805573, ISBN 9781450374897, S2CID 15497394 Cook, Stephen (1983), \"An overview of computational complexity\", Commun. The best case occurs when each pivoting divides the list in half, also needing O(n log n) time.To classify the computation time (or similar resources, such as space consumption), it is helpful to demonstrate upper and lower bounds on the maximum amount of time required by the most efficient algorithm to solve a given problem. The formal language associated with this decision problem is then the set of all connected graphs \u2014 to obtain a precise definition of this language, one has to decide how graphs are encoded as binary strings.A function problem is a computational problem where a single output (of a total function) is expected for every input, but the output is more complex than that of a decision problem\u2014that is, the output isn't just yes or no. In 1972, Richard Karp took this idea a leap forward with his landmark paper, \"Reducibility Among Combinatorial Problems\", in which he showed that 21 diverse combinatorial and graph theoretical problems, each infamous for its computational intractability, are NP-complete.Wuppuluri, Shyam; Doria, Francisco A., eds. However, this identification is inexact: a polynomial-time solution with large degree or large leading coefficient grows quickly, and may be impractical for practical size problems; conversely, an exponential-time solution that grows slowly may be practical on realistic input, or a solution that takes a long time in the worst case may take a short time in most cases or the average case, and thus still be practical. The resource (or resources) that is being bounded and the bound: These two properties are usually stated together, such as \"polynomial time\", \"logarithmic space\", \"constant depth\", etc.Some complexity classes have complicated definitions that do not fit into this framework. The best algorithm for this problem, due to L\u00e1szl\u00f3 Babai and Eugene Luks has run time O ( 2 n log \u2061 n ) {\\displaystyle O(2^{\\sqrt {n\\log n}})} for graphs with n vertices, although some recent work by Babai offers some potentially new perspectives on this.The integer factorization problem is the computational problem of determining the prime factorization of a given integer. The term infeasible (literally \"cannot be done\") is sometimes used interchangeably with intractable, though this risks confusion with a feasible solution in mathematical optimization.Tractable problems are frequently identified with problems that have polynomial-time solutions (P, PTIME); this is known as the Cobham\u2013Edmonds thesis. Similarly, it is not known if L (the set of all problems that can be solved in logarithmic space) is strictly contained in P or equal to P. Again, there are many complexity classes between the two, such as NL and NC, and it is not known if they are distinct or equal classes. Similarly, because all NP problems can be reduced to the set, finding an NP-complete problem that can be solved in polynomial time would mean that P = NP.The complexity class P is often seen as a mathematical abstraction modeling those computational tasks that admit an efficient algorithm. For instance, if all inputs of the same size are assumed to be equally likely to appear, the average case complexity can be defined with respect to the uniform distribution over all inputs of size n. Amortized analysis: Amortized analysis considers both the costly and less costly operations together over the whole series of operations of the algorithm. Phrased as a decision problem, it is the problem of deciding whether the input has a prime factor less than k. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The complexity class NP, on the other hand, contains many problems that people would like to solve efficiently, but for which no efficient algorithm is known, such as the Boolean satisfiability problem, the Hamiltonian path problem and the vertex cover problem. Control theory can be considered a form of computation and differential equations are used in the modelling of continuous-time and hybrid discrete-continuous-time systems.An early example of algorithm complexity analysis is the running time analysis of the Euclidean algorithm done by Gabriel Lam\u00e9 in 1844. The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. Having deduced such proper set inclusions, we can proceed to make quantitative statements about how much more additional time or space is needed in order to increase the number of problems that can be solved. Indeed, in practice even n3 or n2 algorithms are often impractical on realistic sizes of problems.Continuous complexity theory can refer to complexity theory of problems that involve continuous functions that are approximated by discretizations, as studied in numerical analysis.",
        "combined_approach": "2020 unravelling complexity life work gregory chaitin world scientific doi10114211270 isbn 9789811200069 s2cid 198790362arora sanjeev barak boaz 2009 computational complexity modern approach cambridge university press isbn 9780521424264 zbl 119368112 downey rod fellows michael 1999 parameterized complexity monographs computer science berlin new york springerverlag isbn 9780387948836 du dingzhu ko keri 2000 theory computational complexity john wiley sons isbn 9780471345060 garey michael r johnson david 1979 computers intractability guide theory npcompleteness w h freeman isbn 0716710455 goldreich oded 2008 computational complexity conceptual perspective cambridge university press van leeuwen jan ed. acm 26 6 400\u2013408 doi101145358141358144 issn 00010782 s2cid 14323396 fortnow lance homer steven 2003 short history computational complexity pdf bulletin eatcs 80 95\u2013133 mertens stephan 2002 computational complexity physicists computing science eng 4 3 31\u201347 arxivcondmat0012185 bibcode2002cse4c31 doi1011095992998639 issn 15219615 s2cid 633346 nondeterministic turing machine little physically want compute algorithms branching exactly captures many mathematical models want analyze nondeterministic time important resource analyzing computational problemsfor precise definition means solve problem using given amount time space computational model deterministic turing machine used. addition 1965 edmonds suggested consider good algorithm one running time bounded polynomial input sizeearlier papers studying problems solvable turing machines specific bounded resources include john myhills definition linear bounded automata myhill 1960 raymond smullyans study rudimentary sets 1961 well hisao yamadas paper realtime computations 1962. problem x c hard c x said complete c means x hardest problem c since many problems could equally hard one might say x one hardest problems c thus class npcomplete problems contains difficult problems np sense ones likely p problem p np solved able reduce known npcomplete problem \u03c02 another problem \u03c01 would indicate known polynomialtime solution \u03c01. usa thomson course technology isbn 9780534950972khalil hatem ulery dana 1976 review current studies complexity algorithms partial differential equations proceedings annual conference acm 76 acm 76 197\u2013201 doi101145800191805573 isbn 9781450374897 s2cid 15497394 cook stephen 1983 overview computational complexity commun. best case occurs pivoting divides list half also needing log n timeto classify computation time similar resources space consumption helpful demonstrate upper lower bounds maximum amount time required efficient algorithm solve given problem. formal language associated decision problem set connected graphs \u2014 obtain precise definition language one decide graphs encoded binary stringsa function problem computational problem single output total function expected every input output complex decision problem \u2014 output nt yes. 1972 richard karp took idea leap forward landmark paper reducibility among combinatorial problems showed 21 diverse combinatorial graph theoretical problems infamous computational intractability npcompletewuppuluri shyam doria francisco eds. however identification inexact polynomialtime solution large degree large leading coefficient grows quickly may impractical practical size problems conversely exponentialtime solution grows slowly may practical realistic input solution takes long time worst case may take short time cases average case thus still practical. resource resources bounded bound two properties usually stated together polynomial time logarithmic space constant depth etcsome complexity classes complicated definitions fit framework. best algorithm problem due l\u00e1szl\u00f3 babai eugene luks run time 2 n log \u2061 n displaystyle o2sqrt nlog n graphs n vertices although recent work babai offers potentially new perspectives thisthe integer factorization problem computational problem determining prime factorization given integer. term infeasible literally done sometimes used interchangeably intractable though risks confusion feasible solution mathematical optimizationtractable problems frequently identified problems polynomialtime solutions p ptime known cobham \u2013 edmonds thesis. similarly known l set problems solved logarithmic space strictly contained p equal p many complexity classes two nl nc known distinct equal classes. similarly np problems reduced set finding npcomplete problem solved polynomial time would mean p npthe complexity class p often seen mathematical abstraction modeling computational tasks admit efficient algorithm. instance inputs size assumed equally likely appear average case complexity defined respect uniform distribution inputs size n amortized analysis amortized analysis considers costly less costly operations together whole series operations algorithm. phrased decision problem problem deciding whether input prime factor less k efficient integer factorization algorithm known fact forms basis several modern cryptographic systems rsa algorithm. complexity class np hand contains many problems people would like solve efficiently efficient algorithm known boolean satisfiability problem hamiltonian path problem vertex cover problem. control theory considered form computation differential equations used modelling continuoustime hybrid discretecontinuoustime systemsan early example algorithm complexity analysis running time analysis euclidean algorithm done gabriel lam\u00e9 1844. quantitative answer particular problem instance little use solving instances problem asking round trip sites milan whose total length 10 km. deduced proper set inclusions proceed make quantitative statements much additional time space needed order increase number problems solved. indeed practice even n3 n2 algorithms often impractical realistic sizes problemscontinuous complexity theory refer complexity theory problems involve continuous functions approximated discretizations studied numerical analysis."
    },
    {
        "topic": "Arithmetic circuit complexity",
        "summary": "In computational complexity theory, arithmetic circuits are the standard model for computing polynomials. Informally, an arithmetic circuit takes as inputs either variables or numbers, and is allowed to either add or multiply two expressions it has already computed. Arithmetic circuits provide a formal way to understand the complexity of computing polynomials. The basic type of question in this line of research is \"what is the most efficient way to compute a given polynomial \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  ?\"",
        "content": "\n\n\n== Definitions ==\n\nAn arithmetic circuit \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   over the field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   and the set of variables \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x_{1},\\ldots ,x_{n}}\n   is a directed acyclic graph as follows. Every node in it with indegree zero is called an input gate and is labeled by either a variable \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n   or a field element in \n  \n    \n      \n        F\n        .\n      \n    \n    {\\displaystyle F.}\n   Every other gate is labeled by either \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n   or \n  \n    \n      \n        \u00d7\n        ;\n      \n    \n    {\\displaystyle \\times ;}\n   in the first case it is a sum gate and in the second a product gate. An arithmetic formula is a circuit in which every gate has outdegree one (and so the underlying graph is a directed tree).\nA circuit has two complexity measures associated with it: size and depth. The size of a circuit is the number of gates in it, and the depth of a circuit is the length of the longest directed path in it. For example, the circuit in the figure has size six and depth two.\nAn arithmetic circuit computes a polynomial in the following natural way. An input gate computes the polynomial it is labeled by. A sum gate \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   computes the sum of the polynomials computed by its children (a gate \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n   is a child of \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   if the directed edge \n  \n    \n      \n        (\n        v\n        ,\n        u\n        )\n      \n    \n    {\\displaystyle (v,u)}\n   is in the graph). A product gate computes the product of the polynomials computed by its children. Consider the circuit in the figure, for example: the input gates compute (from left to right) \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{1},x_{2}}\n   and \n  \n    \n      \n        1\n        ,\n      \n    \n    {\\displaystyle 1,}\n   the sum gates compute \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{1}+x_{2}}\n   and \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        1\n        ,\n      \n    \n    {\\displaystyle x_{2}+1,}\n   and the product gate computes \n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        )\n        \n          x\n          \n            2\n          \n        \n        (\n        \n          x\n          \n            2\n          \n        \n        +\n        1\n        )\n        .\n      \n    \n    {\\displaystyle (x_{1}+x_{2})x_{2}(x_{2}+1).}\n  \n\n\n== Overview ==\nGiven a polynomial \n  \n    \n      \n        f\n        ,\n      \n    \n    {\\displaystyle f,}\n   we may ask ourselves what is the best way to compute it \u2014 for example, what is the smallest size of a circuit computing \n  \n    \n      \n        f\n        .\n      \n    \n    {\\displaystyle f.}\n   The answer to this question consists of two parts. The first part is finding some circuit that computes \n  \n    \n      \n        f\n        ;\n      \n    \n    {\\displaystyle f;}\n   this part is usually called upper bounding the complexity of \n  \n    \n      \n        f\n        .\n      \n    \n    {\\displaystyle f.}\n   The second part is showing that no other circuit can do better; this part is called lower bounding the complexity of  \n  \n    \n      \n        f\n        .\n      \n    \n    {\\displaystyle f.}\n   Although these two tasks are strongly related, proving lower bounds is usually harder, since in order to prove a lower bound one needs to argue about all circuits at the same time.\nNote that we are interested in the formal computation of polynomials, rather than the functions that the polynomials define. For example, consider the polynomial \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        x\n        ;\n      \n    \n    {\\displaystyle x^{2}+x;}\n   over the field of two elements this polynomial represents the zero function, but it is not the zero polynomial. This is one of the differences between the study of arithmetic circuits and the study of Boolean circuits. In Boolean complexity, one is mostly interested in computing a function, rather than some representation of it (in our case, a representation by a polynomial). This is one of the reasons that make Boolean complexity harder than arithmetic complexity. The study of arithmetic circuits may also be considered as one of the intermediate steps towards the study of the Boolean case, which we hardly understand.\n\n\n=== Upper bounds ===\nAs part of the study of the complexity of computing polynomials, some clever circuits (alternatively algorithms) were found. A well-known example is Strassen's algorithm for matrix product. The straightforward way for computing the product of two \n  \n    \n      \n        n\n        \u00d7\n        n\n      \n    \n    {\\displaystyle n\\times n}\n   matrices requires a circuit of size order \n  \n    \n      \n        \n          n\n          \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle n^{3}.}\n   Strassen showed that we can, in fact, multiply two matrices using a circuit of size roughly \n  \n    \n      \n        \n          n\n          \n            2.807\n          \n        \n        .\n      \n    \n    {\\displaystyle n^{2.807}.}\n   Strassen's basic idea is a clever way for multiplying \n  \n    \n      \n        2\n        \u00d7\n        2\n      \n    \n    {\\displaystyle 2\\times 2}\n   matrices. This idea is the starting point of the best theoretical way for multiplying two matrices that takes time roughly \n  \n    \n      \n        \n          n\n          \n            2.376\n          \n        \n        .\n      \n    \n    {\\displaystyle n^{2.376}.}\n  \nAnother interesting story lies behind the computation of the determinant of an \n  \n    \n      \n        n\n        \u00d7\n        n\n      \n    \n    {\\displaystyle n\\times n}\n   matrix. The naive way for computing the determinant requires circuits of size roughly \n  \n    \n      \n        n\n        !\n        .\n      \n    \n    {\\displaystyle n!.}\n   Nevertheless, we know that there are circuits of size polynomial in \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   for computing the determinant. These circuits, however, have depth that is linear in \n  \n    \n      \n        n\n        .\n      \n    \n    {\\displaystyle n.}\n   Berkowitz came up with an improvement: a circuit of size polynomial in \n  \n    \n      \n        n\n        ,\n      \n    \n    {\\displaystyle n,}\n   but of depth \n  \n    \n      \n        O\n        (\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        (\n        n\n        )\n        )\n        .\n      \n    \n    {\\displaystyle O(\\log ^{2}(n)).}\n  We would also like to mention the best circuit known for the permanent of an \n  \n    \n      \n        n\n        \u00d7\n        n\n      \n    \n    {\\displaystyle n\\times n}\n   matrix. As for the determinant, the naive circuit for the permanent has size roughly \n  \n    \n      \n        n\n        !\n        .\n      \n    \n    {\\displaystyle n!.}\n   However, for the permanent the best circuit known has size roughly \n  \n    \n      \n        \n          2\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle 2^{n},}\n   which is given by Ryser's formula: for an \n  \n    \n      \n        n\n        \u00d7\n        n\n      \n    \n    {\\displaystyle n\\times n}\n   matrix \n  \n    \n      \n        X\n        =\n        (\n        \n          x\n          \n            i\n            ,\n            j\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle X=(x_{i,j}),}\n  \n\n  \n    \n      \n        perm\n        \u2061\n        (\n        X\n        )\n        =\n        (\n        \u2212\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          \u2211\n          \n            S\n            \u2286\n            {\n            1\n            ,\n            \u2026\n            ,\n            n\n            }\n          \n        \n        (\n        \u2212\n        1\n        \n          )\n          \n            \n              |\n            \n            S\n            \n              |\n            \n          \n        \n        \n          \u220f\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \u2211\n          \n            j\n            \u2208\n            S\n          \n        \n        \n          x\n          \n            i\n            ,\n            j\n          \n        \n      \n    \n    {\\displaystyle \\operatorname {perm} (X)=(-1)^{n}\\sum _{S\\subseteq \\{1,\\ldots ,n\\}}(-1)^{|S|}\\prod _{i=1}^{n}\\sum _{j\\in S}x_{i,j}}\n  (this is a depth three circuit).\n\n\n=== Lower bounds ===\nIn terms of proving lower bounds, our knowledge is very limited. Since we study the computation of formal polynomials, we know that polynomials of very large degree require large circuits, for example, a polynomial of degree \n  \n    \n      \n        \n          2\n          \n            \n              2\n              \n                n\n              \n            \n          \n        \n      \n    \n    {\\displaystyle 2^{2^{n}}}\n   require a circuit of size roughly \n  \n    \n      \n        \n          2\n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle 2^{n}.}\n   So, the main goal is to prove lower bound for polynomials of small degree, say, polynomial in \n  \n    \n      \n        n\n        .\n      \n    \n    {\\displaystyle n.}\n   In fact, as in many areas of mathematics, counting arguments tell us that there are polynomials of polynomial degree that require circuits of superpolynomial size. However, these counting arguments usually do not improve our understanding of computation. The following problem is the main open problem in this area of research: find an explicit polynomial of polynomial degree that requires circuits of superpolynomial size.\nThe state of the art is a \n  \n    \n      \n        \u03a9\n        (\n        n\n        log\n        \u2061\n        d\n        )\n      \n    \n    {\\displaystyle \\Omega (n\\log d)}\n   lower bound for the size of a circuit computing, e.g., the polynomial \n  \n    \n      \n        \n          x\n          \n            1\n          \n          \n            d\n          \n        \n        +\n        \u22ef\n        +\n        \n          x\n          \n            n\n          \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle x_{1}^{d}+\\cdots +x_{n}^{d}}\n   given by Strassen and by Baur and Strassen. More precisely, Strassen used B\u00e9zout's lemma to show that any circuit that simultaneously computes the \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   polynomials \n  \n    \n      \n        \n          x\n          \n            1\n          \n          \n            d\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            n\n          \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle x_{1}^{d},\\ldots ,x_{n}^{d}}\n   is of size \n  \n    \n      \n        \u03a9\n        (\n        n\n        log\n        \u2061\n        d\n        )\n        ,\n      \n    \n    {\\displaystyle \\Omega (n\\log d),}\n   and later Baur and Strassen showed the following: given an arithmetic circuit of size \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   computing a polynomial \n  \n    \n      \n        f\n        ,\n      \n    \n    {\\displaystyle f,}\n   one can construct a new circuit of size at most \n  \n    \n      \n        O\n        (\n        s\n        )\n      \n    \n    {\\displaystyle O(s)}\n   that computes \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   and all the \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   partial derivatives of \n  \n    \n      \n        f\n        .\n      \n    \n    {\\displaystyle f.}\n   Since the partial derivatives of \n  \n    \n      \n        \n          x\n          \n            1\n          \n          \n            d\n          \n        \n        +\n        \u22ef\n        +\n        \n          x\n          \n            n\n          \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle x_{1}^{d}+\\cdots +x_{n}^{d}}\n   are \n  \n    \n      \n        d\n        \n          x\n          \n            1\n          \n          \n            d\n            \u2212\n            1\n          \n        \n        ,\n        \u2026\n        ,\n        d\n        \n          x\n          \n            n\n          \n          \n            d\n            \u2212\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle dx_{1}^{d-1},\\ldots ,dx_{n}^{d-1},}\n   the lower bound of Strassen applies to \n  \n    \n      \n        \n          x\n          \n            1\n          \n          \n            d\n          \n        \n        +\n        \u22ef\n        +\n        \n          x\n          \n            n\n          \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle x_{1}^{d}+\\cdots +x_{n}^{d}}\n   as well. This is one example where some upper bound helps in proving lower bounds; the construction of a circuit given by Baur and Strassen implies a lower bound for more general polynomials.\nThe lack of ability to prove lower bounds brings us to consider simpler models of computation. Some examples are: monotone circuits (in which all the field elements are nonnegative real numbers), constant depth circuits, and multilinear circuits (in which every gate computes a multilinear polynomial). These restricted models have been studied extensively and some understanding and results were obtained.\n\n\n== Algebraic P and NP ==\nThe most interesting open problem in computational complexity theory is the P vs. NP problem. Roughly, this problem is to determine whether a given problem can be solved as easily as it can be shown that a solution exists to the given problem. In his seminal work Valiant suggested an algebraic analog of this problem, the VP vs. VNP problem.\nThe class VP is the algebraic analog of P; it is the class of polynomials  \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   of polynomial degree that have polynomial size circuits over a fixed field \n  \n    \n      \n        K\n        .\n      \n    \n    {\\displaystyle K.}\n   The class VNP is the analog of NP. VNP can be thought of as the class of polynomials \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   of polynomial degree such that given a monomial we can determine its coefficient in \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   efficiently, with a polynomial size circuit.\nOne of the basic notions in complexity theory is the notion of completeness. Given a class of polynomials (such as VP or VNP), a complete polynomial \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   for this class is a polynomial with two properties: (1) it is part of the class, and (2) any other polynomial \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   in the class is easier than \n  \n    \n      \n        f\n        ,\n      \n    \n    {\\displaystyle f,}\n   in the sense that if \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   has a small circuit then so does \n  \n    \n      \n        g\n        .\n      \n    \n    {\\displaystyle g.}\n   Valiant showed that the permanent is complete for the class VNP. So in order to show that VP is not equal to VNP, one needs to show that the permanent does not have polynomial size circuits. This remains an outstanding open problem.\n\n\n== Depth reduction ==\nOne benchmark in our understanding of the computation of polynomials is the work of Valiant, Skyum, Berkowitz and Rackoff. They showed that if a polynomial \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   of degree \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   has a circuit of size \n  \n    \n      \n        s\n        ,\n      \n    \n    {\\displaystyle s,}\n   then \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   also has a circuit of size polynomial in \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   and \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   of depth \n  \n    \n      \n        O\n        (\n        log\n        \u2061\n        (\n        r\n        )\n        log\n        \u2061\n        (\n        s\n        )\n        )\n        .\n      \n    \n    {\\displaystyle O(\\log(r)\\log(s)).}\n   For example, any polynomial of degree \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   that has a polynomial size circuit, also has a polynomial size circuit of depth roughly \n  \n    \n      \n        \n          log\n          \n            2\n          \n        \n        \u2061\n        (\n        n\n        )\n        .\n      \n    \n    {\\displaystyle \\log ^{2}(n).}\n   This result generalizes the circuit of Berkowitz to any polynomial of polynomial degree that has a polynomial size circuit (such as the determinant). The analog of this result in the Boolean setting is believed to be false.\nOne corollary of this result is a simulation of circuits by relatively small formulas, formulas of quasipolynomial size: if a polynomial \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   of degree \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   has a circuit of size \n  \n    \n      \n        s\n        ,\n      \n    \n    {\\displaystyle s,}\n   then it has a formula of size \n  \n    \n      \n        \n          s\n          \n            O\n            (\n            log\n            \u2061\n            (\n            r\n            )\n            )\n          \n        \n        .\n      \n    \n    {\\displaystyle s^{O(\\log(r))}.}\n   This simulation is easier than the depth reduction of Valiant el al. and was shown earlier by Hyafil.\n\n\n== See also ==\nPolynomial evaluation for a more general and less formal discussion of the complexity of polynomial evaluation.\n\n\n== Further reading ==\nB\u00fcrgisser, Peter (2000). Completeness and reduction in algebraic complexity theory. Algorithms and Computation in Mathematics. Vol. 7. Berlin: Springer-Verlag. ISBN 978-3-540-66752-0. Zbl 0948.68082.\nB\u00fcrgisser, Peter; Clausen, Michael; Shokrollahi, M. Amin (1997). Algebraic complexity theory. Grundlehren der Mathematischen Wissenschaften. Vol. 315. With the collaboration of Thomas Lickteig. Berlin: Springer-Verlag. ISBN 978-3-540-60582-9. Zbl 1087.68568.\nvon zur Gathen, Joachim (1988). \"Algebraic complexity theory\". Annual Review of Computer Science. 3: 317\u2013347. doi:10.1146/annurev.cs.03.060188.001533.\n\n\n== Footnotes ==",
        "content_traditional": "precisely strassen used b\u00e9zouts lemma show circuit simultaneously computes n displaystyle n polynomials x 1 \u2026 x n displaystyle x1dldots xnd size \u03c9 n log \u2061 displaystyle omega nlog later baur strassen showed following given arithmetic circuit size displaystyle computing polynomial f displaystyle f one construct new circuit size displaystyle os computes f displaystyle f n displaystyle n partial derivatives f. given class polynomials vp vnp complete polynomial f displaystyle f class polynomial two properties 1 part class 2 polynomial g displaystyle g class easier f displaystyle f sense f displaystyle f small circuit g. displaystyle f although two tasks strongly related proving lower bounds usually harder since order prove lower bound one needs argue circuits time. however permanent best circuit known size roughly 2 n displaystyle 2n given rysers formula n \u00d7 n displaystyle ntimes n matrix x x j displaystyle xxij perm \u2061 x \u2212 1 n \u2211 \u2286 1 \u2026 n \u2212 1 \u220f 1 n \u2211 j \u2208 x j displaystyle operatorname perm x1nsum ssubseteq 1ldots n1sprod i1nsum jin sxij depth three circuit. one example upper bound helps proving lower bounds construction circuit given baur strassen implies lower bound general polynomials. vnp thought class polynomials f displaystyle f polynomial degree given monomial determine coefficient f displaystyle f efficiently polynomial size circuit. every node indegree zero called input gate labeled either variable x displaystyle xi field element f. displaystyle n fact many areas mathematics counting arguments tell us polynomials polynomial degree require circuits superpolynomial size. one corollary result simulation circuits relatively small formulas formulas quasipolynomial size polynomial f displaystyle f degree r displaystyle r circuit size displaystyle formula size log \u2061 r. state art \u03c9 n log \u2061 displaystyle omega nlog lower bound size circuit computing eg polynomial x 1 \u22ef x n displaystyle x1dcdots xnd given strassen baur strassen. overview given polynomial f displaystyle f may ask best way compute \u2014 example smallest size circuit computing f. following problem main open problem area research find explicit polynomial polynomial degree requires circuits superpolynomial size. study arithmetic circuits may also considered one intermediate steps towards study boolean case hardly understand. examples monotone circuits field elements nonnegative real numbers constant depth circuits multilinear circuits every gate computes multilinear polynomial. definitions arithmetic circuit c displaystyle c field f displaystyle f set variables x 1 \u2026 x n displaystyle x1ldots xn directed acyclic graph follows. arithmetic formula circuit every gate outdegree one underlying graph directed tree. idea starting point best theoretical way multiplying two matrices takes time roughly n 2376. since study computation formal polynomials know polynomials large degree require large circuits example polynomial degree 2 2 n displaystyle 22n require circuit size roughly 2 n. class vp algebraic analog p class polynomials f displaystyle f polynomial degree polynomial size circuits fixed field k. depth reduction one benchmark understanding computation polynomials work valiant skyum berkowitz rackoff. displaystyle f every gate labeled either displaystyle \u00d7 displaystyle times first case sum gate second product gate. displaystyle f second part showing circuit better part called lower bounding complexity f. upper bounds part study complexity computing polynomials clever circuits alternatively algorithms found. sum gate v displaystyle v computes sum polynomials computed children gate u displaystyle u child v displaystyle v directed edge v u displaystyle vu graph. order show vp equal vnp one needs show permanent polynomial size circuits. boolean complexity one mostly interested computing function rather representation case representation polynomial. example consider polynomial x 2 x displaystyle x2x field two elements polynomial represents zero function zero polynomial. would also like mention best circuit known permanent n \u00d7 n displaystyle ntimes n matrix. roughly problem determine whether given problem solved easily shown solution exists given problem. result generalizes circuit berkowitz polynomial polynomial degree polynomial size circuit determinant. main goal prove lower bound polynomials small degree say polynomial n.",
        "custom_approach": "More precisely, Strassen used B\u00e9zout's lemma to show that any circuit that simultaneously computes the n {\\displaystyle n} polynomials x 1 d , \u2026 , x n d {\\displaystyle x_{1}^{d},\\ldots ,x_{n}^{d}} is of size \u03a9 ( n log \u2061 d ) , {\\displaystyle \\Omega (n\\log d),} and later Baur and Strassen showed the following: given an arithmetic circuit of size s {\\displaystyle s} computing a polynomial f , {\\displaystyle f,} one can construct a new circuit of size at most O ( s ) {\\displaystyle O(s)} that computes f {\\displaystyle f} and all the n {\\displaystyle n} partial derivatives of f . However, for the permanent the best circuit known has size roughly 2 n , {\\displaystyle 2^{n},} which is given by Ryser's formula: for an n \u00d7 n {\\displaystyle n\\times n} matrix X = ( x i , j ) , {\\displaystyle X=(x_{i,j}),} perm \u2061 ( X ) = ( \u2212 1 ) n \u2211 S \u2286 { 1 , \u2026 , n } ( \u2212 1 ) | S | \u220f i = 1 n \u2211 j \u2208 S x i , j {\\displaystyle \\operatorname {perm} (X)=(-1)^{n}\\sum _{S\\subseteq \\{1,\\ldots ,n\\}}(-1)^{|S|}\\prod _{i=1}^{n}\\sum _{j\\in S}x_{i,j}} (this is a depth three circuit).In terms of proving lower bounds, our knowledge is very limited. Given a class of polynomials (such as VP or VNP), a complete polynomial f {\\displaystyle f} for this class is a polynomial with two properties: (1) it is part of the class, and (2) any other polynomial g {\\displaystyle g} in the class is easier than f , {\\displaystyle f,} in the sense that if f {\\displaystyle f} has a small circuit then so does g . {\\displaystyle f.} Although these two tasks are strongly related, proving lower bounds is usually harder, since in order to prove a lower bound one needs to argue about all circuits at the same time. The study of arithmetic circuits may also be considered as one of the intermediate steps towards the study of the Boolean case, which we hardly understand.As part of the study of the complexity of computing polynomials, some clever circuits (alternatively algorithms) were found. These restricted models have been studied extensively and some understanding and results were obtained.The most interesting open problem in computational complexity theory is the P vs. NP problem. This is one example where some upper bound helps in proving lower bounds; the construction of a circuit given by Baur and Strassen implies a lower bound for more general polynomials. VNP can be thought of as the class of polynomials f {\\displaystyle f} of polynomial degree such that given a monomial we can determine its coefficient in f {\\displaystyle f} efficiently, with a polynomial size circuit. Every node in it with indegree zero is called an input gate and is labeled by either a variable x i {\\displaystyle x_{i}} or a field element in F . {\\displaystyle n.} In fact, as in many areas of mathematics, counting arguments tell us that there are polynomials of polynomial degree that require circuits of superpolynomial size. This remains an outstanding open problem.One benchmark in our understanding of the computation of polynomials is the work of Valiant, Skyum, Berkowitz and Rackoff. One corollary of this result is a simulation of circuits by relatively small formulas, formulas of quasipolynomial size: if a polynomial f {\\displaystyle f} of degree r {\\displaystyle r} has a circuit of size s , {\\displaystyle s,} then it has a formula of size s O ( log \u2061 ( r ) ) . The state of the art is a \u03a9 ( n log \u2061 d ) {\\displaystyle \\Omega (n\\log d)} lower bound for the size of a circuit computing, e.g., the polynomial x 1 d + \u22ef + x n d {\\displaystyle x_{1}^{d}+\\cdots +x_{n}^{d}} given by Strassen and by Baur and Strassen. The following problem is the main open problem in this area of research: find an explicit polynomial of polynomial degree that requires circuits of superpolynomial size. Some examples are: monotone circuits (in which all the field elements are nonnegative real numbers), constant depth circuits, and multilinear circuits (in which every gate computes a multilinear polynomial). }Given a polynomial f , {\\displaystyle f,} we may ask ourselves what is the best way to compute it \u2014 for example, what is the smallest size of a circuit computing f . An arithmetic formula is a circuit in which every gate has outdegree one (and so the underlying graph is a directed tree). This idea is the starting point of the best theoretical way for multiplying two matrices that takes time roughly n 2.376 . Since we study the computation of formal polynomials, we know that polynomials of very large degree require large circuits, for example, a polynomial of degree 2 2 n {\\displaystyle 2^{2^{n}}} require a circuit of size roughly 2 n . The class VP is the algebraic analog of P; it is the class of polynomials f {\\displaystyle f} of polynomial degree that have polynomial size circuits over a fixed field K . An arithmetic circuit C {\\displaystyle C} over the field F {\\displaystyle F} and the set of variables x 1 , \u2026 , x n {\\displaystyle x_{1},\\ldots ,x_{n}} is a directed acyclic graph as follows. {\\displaystyle F.} Every other gate is labeled by either + {\\displaystyle +} or \u00d7 ; {\\displaystyle \\times ;} in the first case it is a sum gate and in the second a product gate. {\\displaystyle f.} The second part is showing that no other circuit can do better; this part is called lower bounding the complexity of f . A sum gate v {\\displaystyle v} computes the sum of the polynomials computed by its children (a gate u {\\displaystyle u} is a child of v {\\displaystyle v} if the directed edge ( v , u ) {\\displaystyle (v,u)} is in the graph). So in order to show that VP is not equal to VNP, one needs to show that the permanent does not have polynomial size circuits. In Boolean complexity, one is mostly interested in computing a function, rather than some representation of it (in our case, a representation by a polynomial). For example, consider the polynomial x 2 + x ; {\\displaystyle x^{2}+x;} over the field of two elements this polynomial represents the zero function, but it is not the zero polynomial. We would also like to mention the best circuit known for the permanent of an n \u00d7 n {\\displaystyle n\\times n} matrix. This result generalizes the circuit of Berkowitz to any polynomial of polynomial degree that has a polynomial size circuit (such as the determinant). Roughly, this problem is to determine whether a given problem can be solved as easily as it can be shown that a solution exists to the given problem.",
        "combined_approach": "precisely strassen used b\u00e9zouts lemma show circuit simultaneously computes n displaystyle n polynomials x 1 \u2026 x n displaystyle x1dldots xnd size \u03c9 n log \u2061 displaystyle omega nlog later baur strassen showed following given arithmetic circuit size displaystyle computing polynomial f displaystyle f one construct new circuit size displaystyle os computes f displaystyle f n displaystyle n partial derivatives f. however permanent best circuit known size roughly 2 n displaystyle 2n given rysers formula n \u00d7 n displaystyle ntimes n matrix x x j displaystyle xxij perm \u2061 x \u2212 1 n \u2211 \u2286 1 \u2026 n \u2212 1 \u220f 1 n \u2211 j \u2208 x j displaystyle operatorname perm x1nsum ssubseteq 1ldots n1sprod i1nsum jin sxij depth three circuitin terms proving lower bounds knowledge limited. given class polynomials vp vnp complete polynomial f displaystyle f class polynomial two properties 1 part class 2 polynomial g displaystyle g class easier f displaystyle f sense f displaystyle f small circuit g. displaystyle f although two tasks strongly related proving lower bounds usually harder since order prove lower bound one needs argue circuits time. study arithmetic circuits may also considered one intermediate steps towards study boolean case hardly understandas part study complexity computing polynomials clever circuits alternatively algorithms found. restricted models studied extensively understanding results obtainedthe interesting open problem computational complexity theory p vs np problem. one example upper bound helps proving lower bounds construction circuit given baur strassen implies lower bound general polynomials. vnp thought class polynomials f displaystyle f polynomial degree given monomial determine coefficient f displaystyle f efficiently polynomial size circuit. every node indegree zero called input gate labeled either variable x displaystyle xi field element f. displaystyle n fact many areas mathematics counting arguments tell us polynomials polynomial degree require circuits superpolynomial size. remains outstanding open problemone benchmark understanding computation polynomials work valiant skyum berkowitz rackoff. one corollary result simulation circuits relatively small formulas formulas quasipolynomial size polynomial f displaystyle f degree r displaystyle r circuit size displaystyle formula size log \u2061 r. state art \u03c9 n log \u2061 displaystyle omega nlog lower bound size circuit computing eg polynomial x 1 \u22ef x n displaystyle x1dcdots xnd given strassen baur strassen. following problem main open problem area research find explicit polynomial polynomial degree requires circuits superpolynomial size. examples monotone circuits field elements nonnegative real numbers constant depth circuits multilinear circuits every gate computes multilinear polynomial. given polynomial f displaystyle f may ask best way compute \u2014 example smallest size circuit computing f. arithmetic formula circuit every gate outdegree one underlying graph directed tree. idea starting point best theoretical way multiplying two matrices takes time roughly n 2376. since study computation formal polynomials know polynomials large degree require large circuits example polynomial degree 2 2 n displaystyle 22n require circuit size roughly 2 n. class vp algebraic analog p class polynomials f displaystyle f polynomial degree polynomial size circuits fixed field k. arithmetic circuit c displaystyle c field f displaystyle f set variables x 1 \u2026 x n displaystyle x1ldots xn directed acyclic graph follows. displaystyle f every gate labeled either displaystyle \u00d7 displaystyle times first case sum gate second product gate. displaystyle f second part showing circuit better part called lower bounding complexity f. sum gate v displaystyle v computes sum polynomials computed children gate u displaystyle u child v displaystyle v directed edge v u displaystyle vu graph. order show vp equal vnp one needs show permanent polynomial size circuits. boolean complexity one mostly interested computing function rather representation case representation polynomial. example consider polynomial x 2 x displaystyle x2x field two elements polynomial represents zero function zero polynomial. would also like mention best circuit known permanent n \u00d7 n displaystyle ntimes n matrix. result generalizes circuit berkowitz polynomial polynomial degree polynomial size circuit determinant. roughly problem determine whether given problem solved easily shown solution exists given problem."
    },
    {
        "topic": "List of films about mathematicians",
        "summary": "This is a list of feature films and documentaries that include mathematicians, scientists who use math or references to mathematicians.",
        "content": "\n\n\n== About mathematics ==\nFilms where mathematics is central to the plot:\n\n21 (2008) \u2013 A group of MIT current and former students, mostly mathematicians, and an algebra professor devise a card counting scheme for success at Las Vegas Strip blackjack tables.\nThe Bank (2001) \u2013 A mathematician discovers a formula to predict fluctuations in the stock market.\nCube (1997) \u2013 Six people, including Leaven, a math student, awake in a deathtrap based on mathematical principles.\nFermat's Room (2007) \u2013 Three mathematicians and one inventor are invited to a house under the premise of solving a great enigma and told to use pseudonyms based on famous historical mathematicians. At the house, they are trapped in a room. They must solve puzzles given by the host, who calls himself \"Fermat\", in order to escape the slowly closing walls of the room.\nGifted (2017) \u2013 Frank Adler (Chris Evans) is a single man raising a child prodigy\u2014his spirited young niece Mary (Mckenna Grace)\u2014in a coastal town in Florida after the death of her mother Diane, a mathematician. Mary's grandmother Evelyn (Lindsay Duncan) and uncle have different ideas on how to raise her. Mary tells her grandmother she wants to solve the problem her mother was working on, the Navier-Stokes existence and smoothness problem.\nGood Will Hunting (1997) \u2013 Janitor and genius Will Hunting (Matt Damon) begins to turn his life around with the help of psychologist (Robin Williams) and a Fields Medal-winning professor (Stellan Skarsg\u00e5rd).\nI.Q. (1994) \u2013 Albert Einstein (Walter Matthau) helps a young man (Tim Robbins) pretend to be a physicist in order to catch the attention of Einstein's niece (Meg Ryan).\nAn Invisible Sign (2011) \u2013 Mona Gray (Jessica Alba) gives up everything important to her in life, except mathematics, as part of a \"deal with the universe\" to help restore her father (a mathematician) to health. Years later, Mona teaches the subject, and does her best to help her students contend with their own personal crises.\nMoebius (1996) \u2013 Topologists including a young girl make contributions to the subway system and other facets of reality in Argentina in this math film with a science fiction and surreal feel.\nMoneyball (2011) \u2013 Oakland Athletics baseball team's general manager Billy Beane attempts to assemble a competitive team using statistics.\nThe Oxford Murders (2008) \u2013 A Student (Elijah Wood) finds out about mysterious killings in Oxford and helped by a professor (John Hurt), they reveal the math patterns used by the killer.\nPi (1998) \u2013 A mathematician searches for the number that underlies all of nature.\nProof (2005) \u2013 A former student (Jake Gyllenhaal) of a recently deceased, brilliant mathematician (Anthony Hopkins) finds a notebook in his office containing a proof of an important theorem, but the mathematician's daughter (Gwyneth Paltrow) claims it is hers. The ensuing dispute is complicated by signs that she may have inherited her father's mental illness and a burgeoning romance.\nRaising Genius (2004) \u2013 The film is about a boy (Justin Long) who locks himself in the bathroom to work out math equations on the shower wall.\nSneakers (1992) \u2013 An eclectic team is blackmailed into stealing a mathematician's code-breaking box.\nTravelling Salesman (2012) \u2013 The US government hires four mathematicians to solve the most powerful problem ever to plague computer science (P vs NP problem).\nX+Y (2014) A teenage mathematical prodigy has difficulty understanding people, but finds comfort in numbers.\n\n\n== Mathematician biographical films ==\nBiographical films based on real-life mathematicians:\n\nAgora (2009) \u2013 The life of the mathematician, astronomer, and philosopher Hypatia (Rachel Weisz), directed by Alejandro Amen\u00e1bar.\nA Beautiful Mind (2001) \u2013 A fictional account based loosely on the life of mathematician John Nash (Russell Crowe), who made a breakthrough that wins him the Nobel Memorial Prize in Economic Sciences.\nA Brief History of Time (1991) \u2013 A biographical documentary film about the physicist Stephen Hawking, directed by Errol Morris.\nCartesius (1973) - A miniseries on the life of Ren\u00e9 Descartes, directed by Roberto Rossellini.\nCounting from Infinity: Yitang Zhang and the Twin Prime Conjecture (2015) \u2013 A documentary film by George Paul Csicsery about Yitang Zhang, a lecturer at the University of New Hampshire, working in complete isolation and making an important breakthrough towards solving the Twin Prime Conjecture.\nEnigma (2001) \u2013 A story of romantic and psychological intrigue set in Bletchley Park during the World War II effort to crack the German Enigma machine.\nGirls who fell in love with Math (2017) \u2013 Career profiles of mathematicians Sun-Yung Alice Chang and Fan Chung.\nHidden Figures (2016) \u2013 African-American mathematicians Katherine Johnson, Dorothy Vaughan, and Mary Jackson are featured in this film about the early years of the NASA Project Mercury and racial and sexual segregation.\nA Hill on the Dark Side of the Moon (1983) \u2013 A drama film about the professor of mathematics, Sofya Kovalevskaya.\nThe Imitation Game (2014) \u2013 British mathematician Alan Turing (Benedict Cumberbatch), a pioneer in digital computing and artificial intelligence, is tasked with cracking Nazi Germany's Enigma code that would help the Allies win World War II. A new adaptation of the play \"Breaking the Code\".\nInfinity (1996) \u2013 A story about Nobel Prize-winning physicist Richard Feynman (Matthew Broderick).\nThe Man Who Knew Infinity (2015) \u2013 The true story of Indian mathematical genius, Srinivasa Ramanujan (Dev Patel), who develops numerous properties of infinite series as a clerk in India before writing to Cambridge mathematicians who invite him to UK. Directed by Matthew Brown\nN Is a Number: A Portrait of Paul Erd\u0151s (1993) \u2013 A documentary directed by George Csicsery about the life of Hungarian mathematician Paul Erd\u0151s.\nRamanujan (2014) \u2013 A biographical film by Gnana Rajasekaran based on the life of Srinivasa Ramanujan.\nSecrets of the Surface The Mathematical Vision of Maryam Mirzakhani (2020) \u2013 A documentary film by George Csicsery about the Fields medalist and Iranian national hero.\nSofia Kovalevskaya (1985) \u2013 Epic film in four episodes, based on a true story of mathematician Sofya Kovalevskaya.\nThe Theory of Everything (2014) \u2013 The story of the life and hardships faced by theoretical physicist and mathematician Stephen Hawking.\n\n\n== Starring mathematicians ==\nFilms where one or more mathematicians play the main role, but that are not otherwise about mathematics:\n\nIt's My Turn (1980) \u2013 A mathematics professor (Jill Clayburgh) falls in love with her father's bride's son (Michael Douglas).\nThe Mirror Has Two Faces (1996) \u2013 A math professor (Jeff Bridges) marries a literature professor (Barbra Streisand), but they want different things from the relationship.\nStand and Deliver (1988) \u2013 Based on the true story of math teacher Jaime Escalante, who inspired the students at a school in a troubled Hispanic neighborhood to take Advanced Placement Calculus. The method of tabular integration is featured in the film.\nStraw Dogs (1971) \u2013 David Sumner (Dustin Hoffman) is an American mathematical physicist who moves to England, where he and his wife are violently harassed by locals.\nA Summer's Tale (1996) \u2013 A young mathematician vacationing in Brittany.\nTall Story (1960) \u2013 A college physics and mathematics whiz is also the star basketball player, partly because he has devised equations for making baskets.\nA Serious Man (2009)\n\n\n== Featuring mathematicians ==\nFilms where one or more of the members of the main cast is a mathematician:\n\n21 Grams (2003) \u2013 An accident changes many lives, including that of a critically ill mathematics professor (Sean Penn).\nAntonia's Line (1995) \u2013 A genealogical \"line\" of five generations of women includes a child prodigy, Th\u00e9r\u00e8se, who grows up to be a mathematician.\nJurassic Park (1993) \u2013 A mathematician studying chaos theory (Jeff Goldblum) is among those invited to a theme park with cloned dinosaurs, in order to assess its safety.\nThe Lost World: Jurassic Park (1997) \u2013 Mathematician Ian Malcolm (Jeff Goldblum) travels to an auxiliary Jurassic Park site to document dinosaurs.\n\n\n== See also ==\nList of fictional child prodigies\n\n\n== References ==\n\n\n== External links ==\nMathematical Fiction: films by Alex Kasman (College of Charleston)\nThe Mathematical Movie Database by Burkard Polster and Marty Ross\nMathematics in Movies by Oliver Knill (Harvard University)\nMy Math Movie Picks by Brian Harbourne (University of Nebraska\u2013Lincoln)\nMath in the Movies by Arnold G. Reinhold\nMath Becomes Way Cool by Keith Devlin (Mathematical Association of America)\nTop 10 Math Movies (infographic)",
        "content_traditional": "see also list fictional child prodigies references external links mathematical fiction films alex kasman college charleston mathematical movie database burkard polster marty ross mathematics movies oliver knill harvard university math movie picks brian harbourne university nebraska \u2013 lincoln math movies arnold g reinhold math becomes way cool keith devlin mathematical association america top 10 math movies infographic starring mathematicians films one mathematicians play main role otherwise mathematics turn 1980 \u2013 mathematics professor jill clayburgh falls love fathers brides son michael douglas. mathematics films mathematics central plot 21 2008 \u2013 group mit current former students mostly mathematicians algebra professor devise card counting scheme success las vegas strip blackjack tables. serious man 2009 featuring mathematicians films one members main cast mathematician 21 grams 2003 \u2013 accident changes many lives including critically ill mathematics professor sean penn. imitation game 2014 \u2013 british mathematician alan turing benedict cumberbatch pioneer digital computing artificial intelligence tasked cracking nazi germanys enigma code would help allies win world war ii. man knew infinity 2015 \u2013 true story indian mathematical genius srinivasa ramanujan dev patel develops numerous properties infinite series clerk india writing cambridge mathematicians invite uk. gifted 2017 \u2013 frank adler chris evans single man raising child prodigy \u2014 spirited young niece mary mckenna grace \u2014 coastal town florida death mother diane mathematician. proof 2005 \u2013 former student jake gyllenhaal recently deceased brilliant mathematician anthony hopkins finds notebook office containing proof important theorem mathematicians daughter gwyneth paltrow claims. counting infinity yitang zhang twin prime conjecture 2015 \u2013 documentary film george paul csicsery yitang zhang lecturer university new hampshire working complete isolation making important breakthrough towards solving twin prime conjecture. invisible sign 2011 \u2013 mona gray jessica alba gives everything important life except mathematics part deal universe help restore father mathematician health. hidden figures 2016 \u2013 africanamerican mathematicians katherine johnson dorothy vaughan mary jackson featured film early years nasa project mercury racial sexual segregation. beautiful mind 2001 \u2013 fictional account based loosely life mathematician john nash russell crowe made breakthrough wins nobel memorial prize economic sciences. stand deliver 1988 \u2013 based true story math teacher jaime escalante inspired students school troubled hispanic neighborhood take advanced placement calculus. moebius 1996 \u2013 topologists including young girl make contributions subway system facets reality argentina math film science fiction surreal feel. straw dogs 1971 \u2013 david sumner dustin hoffman american mathematical physicist moves england wife violently harassed locals. fermats room 2007 \u2013 three mathematicians one inventor invited house premise solving great enigma told use pseudonyms based famous historical mathematicians. good hunting 1997 \u2013 janitor genius hunting matt damon begins turn life around help psychologist robin williams fields medalwinning professor stellan skarsg\u00e5rd. oxford murders 2008 \u2013 student elijah wood finds mysterious killings oxford helped professor john hurt reveal math patterns used killer. tall story 1960 \u2013 college physics mathematics whiz also star basketball player partly devised equations making baskets. raising genius 2004 \u2013 film boy justin long locks bathroom work math equations shower wall. jurassic park 1993 \u2013 mathematician studying chaos theory jeff goldblum among invited theme park cloned dinosaurs order assess safety. 1994 \u2013 albert einstein walter matthau helps young man tim robbins pretend physicist order catch attention einsteins niece meg ryan. mirror two faces 1996 \u2013 math professor jeff bridges marries literature professor barbra streisand want different things relationship. secrets surface mathematical vision maryam mirzakhani 2020 \u2013 documentary film george csicsery fields medalist iranian national hero. enigma 2001 \u2013 story romantic psychological intrigue set bletchley park world war ii effort crack german enigma machine. must solve puzzles given host calls fermat order escape slowly closing walls room. mathematician biographical films biographical films based reallife mathematicians agora 2009 \u2013 life mathematician astronomer philosopher hypatia rachel weisz directed alejandro amen\u00e1bar. travelling salesman 2012 \u2013 us government hires four mathematicians solve powerful problem ever plague computer science p vs np problem. ensuing dispute complicated signs may inherited fathers mental illness burgeoning romance. girls fell love math 2017 \u2013 career profiles mathematicians sunyung alice chang fan chung. years later mona teaches subject best help students contend personal crises. mary tells grandmother wants solve problem mother working navierstokes existence smoothness problem. antonias line 1995 \u2013 genealogical line five generations women includes child prodigy th\u00e9r\u00e8se grows mathematician. lost world jurassic park 1997 \u2013 mathematician ian malcolm jeff goldblum travels auxiliary jurassic park site document dinosaurs. directed matthew brown n number portrait paul erd\u0151s 1993 \u2013 documentary directed george csicsery life hungarian mathematician paul erd\u0151s. brief history time 1991 \u2013 biographical documentary film physicist stephen hawking directed errol morris. theory everything 2014 \u2013 story life hardships faced theoretical physicist mathematician stephen hawking. moneyball 2011 \u2013 oakland athletics baseball teams general manager billy beane attempts assemble competitive team using statistics. hill dark side moon 1983 \u2013 drama film professor mathematics sofya kovalevskaya. cube 1997 \u2013 six people including leaven math student awake deathtrap based mathematical principles. marys grandmother evelyn lindsay duncan uncle different ideas raise. sofia kovalevskaya 1985 \u2013 epic film four episodes based true story mathematician sofya kovalevskaya.",
        "custom_approach": "The Theory of Everything (2014) \u2013 The story of the life and hardships faced by theoretical physicist and mathematician Stephen Hawking.Films where one or more mathematicians play the main role, but that are not otherwise about mathematics: It's My Turn (1980) \u2013 A mathematics professor (Jill Clayburgh) falls in love with her father's bride's son (Michael Douglas). X+Y (2014) A teenage mathematical prodigy has difficulty understanding people, but finds comfort in numbers.Biographical films based on real-life mathematicians: Agora (2009) \u2013 The life of the mathematician, astronomer, and philosopher Hypatia (Rachel Weisz), directed by Alejandro Amen\u00e1bar. Films where mathematics is central to the plot: 21 (2008) \u2013 A group of MIT current and former students, mostly mathematicians, and an algebra professor devise a card counting scheme for success at Las Vegas Strip blackjack tables. The Imitation Game (2014) \u2013 British mathematician Alan Turing (Benedict Cumberbatch), a pioneer in digital computing and artificial intelligence, is tasked with cracking Nazi Germany's Enigma code that would help the Allies win World War II. The Man Who Knew Infinity (2015) \u2013 The true story of Indian mathematical genius, Srinivasa Ramanujan (Dev Patel), who develops numerous properties of infinite series as a clerk in India before writing to Cambridge mathematicians who invite him to UK. A Serious Man (2009)Films where one or more of the members of the main cast is a mathematician: 21 Grams (2003) \u2013 An accident changes many lives, including that of a critically ill mathematics professor (Sean Penn). Gifted (2017) \u2013 Frank Adler (Chris Evans) is a single man raising a child prodigy\u2014his spirited young niece Mary (Mckenna Grace)\u2014in a coastal town in Florida after the death of her mother Diane, a mathematician. Proof (2005) \u2013 A former student (Jake Gyllenhaal) of a recently deceased, brilliant mathematician (Anthony Hopkins) finds a notebook in his office containing a proof of an important theorem, but the mathematician's daughter (Gwyneth Paltrow) claims it is hers. Counting from Infinity: Yitang Zhang and the Twin Prime Conjecture (2015) \u2013 A documentary film by George Paul Csicsery about Yitang Zhang, a lecturer at the University of New Hampshire, working in complete isolation and making an important breakthrough towards solving the Twin Prime Conjecture. An Invisible Sign (2011) \u2013 Mona Gray (Jessica Alba) gives up everything important to her in life, except mathematics, as part of a \"deal with the universe\" to help restore her father (a mathematician) to health. Hidden Figures (2016) \u2013 African-American mathematicians Katherine Johnson, Dorothy Vaughan, and Mary Jackson are featured in this film about the early years of the NASA Project Mercury and racial and sexual segregation. A Beautiful Mind (2001) \u2013 A fictional account based loosely on the life of mathematician John Nash (Russell Crowe), who made a breakthrough that wins him the Nobel Memorial Prize in Economic Sciences. Stand and Deliver (1988) \u2013 Based on the true story of math teacher Jaime Escalante, who inspired the students at a school in a troubled Hispanic neighborhood to take Advanced Placement Calculus. Moebius (1996) \u2013 Topologists including a young girl make contributions to the subway system and other facets of reality in Argentina in this math film with a science fiction and surreal feel. Straw Dogs (1971) \u2013 David Sumner (Dustin Hoffman) is an American mathematical physicist who moves to England, where he and his wife are violently harassed by locals. Fermat's Room (2007) \u2013 Three mathematicians and one inventor are invited to a house under the premise of solving a great enigma and told to use pseudonyms based on famous historical mathematicians. Good Will Hunting (1997) \u2013 Janitor and genius Will Hunting (Matt Damon) begins to turn his life around with the help of psychologist (Robin Williams) and a Fields Medal-winning professor (Stellan Skarsg\u00e5rd). The Oxford Murders (2008) \u2013 A Student (Elijah Wood) finds out about mysterious killings in Oxford and helped by a professor (John Hurt), they reveal the math patterns used by the killer. Tall Story (1960) \u2013 A college physics and mathematics whiz is also the star basketball player, partly because he has devised equations for making baskets. Raising Genius (2004) \u2013 The film is about a boy (Justin Long) who locks himself in the bathroom to work out math equations on the shower wall. Jurassic Park (1993) \u2013 A mathematician studying chaos theory (Jeff Goldblum) is among those invited to a theme park with cloned dinosaurs, in order to assess its safety. (1994) \u2013 Albert Einstein (Walter Matthau) helps a young man (Tim Robbins) pretend to be a physicist in order to catch the attention of Einstein's niece (Meg Ryan). The Mirror Has Two Faces (1996) \u2013 A math professor (Jeff Bridges) marries a literature professor (Barbra Streisand), but they want different things from the relationship. Secrets of the Surface The Mathematical Vision of Maryam Mirzakhani (2020) \u2013 A documentary film by George Csicsery about the Fields medalist and Iranian national hero. Enigma (2001) \u2013 A story of romantic and psychological intrigue set in Bletchley Park during the World War II effort to crack the German Enigma machine. They must solve puzzles given by the host, who calls himself \"Fermat\", in order to escape the slowly closing walls of the room. Travelling Salesman (2012) \u2013 The US government hires four mathematicians to solve the most powerful problem ever to plague computer science (P vs NP problem). The ensuing dispute is complicated by signs that she may have inherited her father's mental illness and a burgeoning romance. Girls who fell in love with Math (2017) \u2013 Career profiles of mathematicians Sun-Yung Alice Chang and Fan Chung. Years later, Mona teaches the subject, and does her best to help her students contend with their own personal crises. Mary tells her grandmother she wants to solve the problem her mother was working on, the Navier-Stokes existence and smoothness problem. Antonia's Line (1995) \u2013 A genealogical \"line\" of five generations of women includes a child prodigy, Th\u00e9r\u00e8se, who grows up to be a mathematician. The Lost World: Jurassic Park (1997) \u2013 Mathematician Ian Malcolm (Jeff Goldblum) travels to an auxiliary Jurassic Park site to document dinosaurs. Directed by Matthew Brown N Is a Number: A Portrait of Paul Erd\u0151s (1993) \u2013 A documentary directed by George Csicsery about the life of Hungarian mathematician Paul Erd\u0151s. A Brief History of Time (1991) \u2013 A biographical documentary film about the physicist Stephen Hawking, directed by Errol Morris. Moneyball (2011) \u2013 Oakland Athletics baseball team's general manager Billy Beane attempts to assemble a competitive team using statistics. A Hill on the Dark Side of the Moon (1983) \u2013 A drama film about the professor of mathematics, Sofya Kovalevskaya. Cube (1997) \u2013 Six people, including Leaven, a math student, awake in a deathtrap based on mathematical principles. Mary's grandmother Evelyn (Lindsay Duncan) and uncle have different ideas on how to raise her. Sofia Kovalevskaya (1985) \u2013 Epic film in four episodes, based on a true story of mathematician Sofya Kovalevskaya. Sneakers (1992) \u2013 An eclectic team is blackmailed into stealing a mathematician's code-breaking box. Infinity (1996) \u2013 A story about Nobel Prize-winning physicist Richard Feynman (Matthew Broderick). Cartesius (1973) - A miniseries on the life of Ren\u00e9 Descartes, directed by Roberto Rossellini. The Bank (2001) \u2013 A mathematician discovers a formula to predict fluctuations in the stock market. Pi (1998) \u2013 A mathematician searches for the number that underlies all of nature.",
        "combined_approach": "theory everything 2014 \u2013 story life hardships faced theoretical physicist mathematician stephen hawkingfilms one mathematicians play main role otherwise mathematics turn 1980 \u2013 mathematics professor jill clayburgh falls love fathers brides son michael douglas. xy 2014 teenage mathematical prodigy difficulty understanding people finds comfort numbersbiographical films based reallife mathematicians agora 2009 \u2013 life mathematician astronomer philosopher hypatia rachel weisz directed alejandro amen\u00e1bar. films mathematics central plot 21 2008 \u2013 group mit current former students mostly mathematicians algebra professor devise card counting scheme success las vegas strip blackjack tables. imitation game 2014 \u2013 british mathematician alan turing benedict cumberbatch pioneer digital computing artificial intelligence tasked cracking nazi germanys enigma code would help allies win world war ii. man knew infinity 2015 \u2013 true story indian mathematical genius srinivasa ramanujan dev patel develops numerous properties infinite series clerk india writing cambridge mathematicians invite uk. serious man 2009films one members main cast mathematician 21 grams 2003 \u2013 accident changes many lives including critically ill mathematics professor sean penn. gifted 2017 \u2013 frank adler chris evans single man raising child prodigy \u2014 spirited young niece mary mckenna grace \u2014 coastal town florida death mother diane mathematician. proof 2005 \u2013 former student jake gyllenhaal recently deceased brilliant mathematician anthony hopkins finds notebook office containing proof important theorem mathematicians daughter gwyneth paltrow claims. counting infinity yitang zhang twin prime conjecture 2015 \u2013 documentary film george paul csicsery yitang zhang lecturer university new hampshire working complete isolation making important breakthrough towards solving twin prime conjecture. invisible sign 2011 \u2013 mona gray jessica alba gives everything important life except mathematics part deal universe help restore father mathematician health. hidden figures 2016 \u2013 africanamerican mathematicians katherine johnson dorothy vaughan mary jackson featured film early years nasa project mercury racial sexual segregation. beautiful mind 2001 \u2013 fictional account based loosely life mathematician john nash russell crowe made breakthrough wins nobel memorial prize economic sciences. stand deliver 1988 \u2013 based true story math teacher jaime escalante inspired students school troubled hispanic neighborhood take advanced placement calculus. moebius 1996 \u2013 topologists including young girl make contributions subway system facets reality argentina math film science fiction surreal feel. straw dogs 1971 \u2013 david sumner dustin hoffman american mathematical physicist moves england wife violently harassed locals. fermats room 2007 \u2013 three mathematicians one inventor invited house premise solving great enigma told use pseudonyms based famous historical mathematicians. good hunting 1997 \u2013 janitor genius hunting matt damon begins turn life around help psychologist robin williams fields medalwinning professor stellan skarsg\u00e5rd. oxford murders 2008 \u2013 student elijah wood finds mysterious killings oxford helped professor john hurt reveal math patterns used killer. tall story 1960 \u2013 college physics mathematics whiz also star basketball player partly devised equations making baskets. raising genius 2004 \u2013 film boy justin long locks bathroom work math equations shower wall. jurassic park 1993 \u2013 mathematician studying chaos theory jeff goldblum among invited theme park cloned dinosaurs order assess safety. 1994 \u2013 albert einstein walter matthau helps young man tim robbins pretend physicist order catch attention einsteins niece meg ryan. mirror two faces 1996 \u2013 math professor jeff bridges marries literature professor barbra streisand want different things relationship. secrets surface mathematical vision maryam mirzakhani 2020 \u2013 documentary film george csicsery fields medalist iranian national hero. enigma 2001 \u2013 story romantic psychological intrigue set bletchley park world war ii effort crack german enigma machine. must solve puzzles given host calls fermat order escape slowly closing walls room. travelling salesman 2012 \u2013 us government hires four mathematicians solve powerful problem ever plague computer science p vs np problem. ensuing dispute complicated signs may inherited fathers mental illness burgeoning romance. girls fell love math 2017 \u2013 career profiles mathematicians sunyung alice chang fan chung. years later mona teaches subject best help students contend personal crises. mary tells grandmother wants solve problem mother working navierstokes existence smoothness problem. antonias line 1995 \u2013 genealogical line five generations women includes child prodigy th\u00e9r\u00e8se grows mathematician. lost world jurassic park 1997 \u2013 mathematician ian malcolm jeff goldblum travels auxiliary jurassic park site document dinosaurs. directed matthew brown n number portrait paul erd\u0151s 1993 \u2013 documentary directed george csicsery life hungarian mathematician paul erd\u0151s. brief history time 1991 \u2013 biographical documentary film physicist stephen hawking directed errol morris. moneyball 2011 \u2013 oakland athletics baseball teams general manager billy beane attempts assemble competitive team using statistics. hill dark side moon 1983 \u2013 drama film professor mathematics sofya kovalevskaya. cube 1997 \u2013 six people including leaven math student awake deathtrap based mathematical principles. marys grandmother evelyn lindsay duncan uncle different ideas raise. sofia kovalevskaya 1985 \u2013 epic film four episodes based true story mathematician sofya kovalevskaya. sneakers 1992 \u2013 eclectic team blackmailed stealing mathematicians codebreaking box. infinity 1996 \u2013 story nobel prizewinning physicist richard feynman matthew broderick. cartesius 1973 miniseries life ren\u00e9 descartes directed roberto rossellini. bank 2001 \u2013 mathematician discovers formula predict fluctuations stock market. pi 1998 \u2013 mathematician searches number underlies nature."
    }
]